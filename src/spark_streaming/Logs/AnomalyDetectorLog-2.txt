hed: foreachPartition at AnomalyDetector.java:69, took 2.016011 s
18/05/31 14:46:39 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 127.1 KB, free 354.6 MB)
18/05/31 14:46:39 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.5 MB)
18/05/31 14:46:39 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:46:39 INFO SparkContext: Created broadcast 30 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:39 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:39 INFO DAGScheduler: Got job 14 (foreachPartition at AnomalyDetector.java:69) with 1 output partitions
18/05/31 14:46:39 INFO DAGScheduler: Final stage: ResultStage 104 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:39 INFO DAGScheduler: Parents of final stage: List()
18/05/31 14:46:39 INFO DAGScheduler: Missing parents: List()
18/05/31 14:46:39 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[62] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:39 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 6.1 KB, free 354.5 MB)
18/05/31 14:46:39 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.5 MB)
18/05/31 14:46:39 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:46:39 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[62] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:39 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
18/05/31 14:46:39 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 6166 bytes)
18/05/31 14:46:39 INFO Executor: Running task 0.0 in stage 104.0 (TID 65)
18/05/31 14:46:39 INFO BlockManager: Found block rdd_62_0 locally
18/05/31 14:46:39 INFO Executor: Finished task 0.0 in stage 104.0 (TID 65). 1004 bytes result sent to driver
18/05/31 14:46:39 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 65) in 13 ms on localhost (executor driver) (1/1)
18/05/31 14:46:39 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
18/05/31 14:46:39 INFO DAGScheduler: ResultStage 104 (foreachPartition at AnomalyDetector.java:69) finished in 0.014 s
18/05/31 14:46:39 INFO DAGScheduler: Job 14 finished: foreachPartition at AnomalyDetector.java:69, took 0.017794 s
18/05/31 14:46:39 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 127.1 KB, free 354.4 MB)
18/05/31 14:46:39 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.4 MB)
18/05/31 14:46:39 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:46:39 INFO SparkContext: Created broadcast 32 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:39 INFO ReliableRDDCheckpointData: Done checkpointing RDD 62 to file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-62, new parent is RDD 213
18/05/31 14:46:39 INFO JobScheduler: Finished job streaming job 1527766900000 ms.0 from job set of time 1527766900000 ms
18/05/31 14:46:39 INFO JobScheduler: Total delay: 299.347 s for time 1527766900000 ms (execution: 2.071 s)
18/05/31 14:46:39 INFO JobScheduler: Starting job streaming job 1527766910000 ms.0 from job set of time 1527766910000 ms
18/05/31 14:46:39 INFO MapPartitionsRDD: Removing RDD 60 from persistence list
18/05/31 14:46:39 INFO JobGenerator: Checkpointing graph for time 1527766900000 ms
18/05/31 14:46:39 INFO DStreamGraph: Updating checkpoint data for time 1527766900000 ms
18/05/31 14:46:39 INFO BlockManager: Removing RDD 60
18/05/31 14:46:39 INFO DStreamGraph: Updated checkpoint data for time 1527766900000 ms
18/05/31 14:46:39 INFO CheckpointWriter: Submitted checkpoint of time 1527766900000 ms to writer queue
18/05/31 14:46:39 INFO CheckpointWriter: Saving checkpoint for time 1527766900000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767190000'
18/05/31 14:46:39 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:39 INFO DAGScheduler: Registering RDD 67 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 149 bytes
18/05/31 14:46:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 149 bytes
18/05/31 14:46:39 INFO DAGScheduler: Got job 15 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:39 INFO DAGScheduler: Final stage: ResultStage 108 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107, ShuffleMapStage 105, ShuffleMapStage 106)
18/05/31 14:46:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 105)
18/05/31 14:46:39 INFO DAGScheduler: Submitting ShuffleMapStage 105 (MapPartitionsRDD[67] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:39 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 4.6 KB, free 354.4 MB)
18/05/31 14:46:39 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.4 MB)
18/05/31 14:46:39 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:46:39 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 105 (MapPartitionsRDD[67] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:39 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks
18/05/31 14:46:39 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:39 INFO Executor: Running task 0.0 in stage 105.0 (TID 66)
18/05/31 14:46:39 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:39 INFO MemoryStore: Block rdd_67_0 stored as bytes in memory (estimated size 4.0 B, free 354.4 MB)
18/05/31 14:46:39 INFO BlockManagerInfo: Added rdd_67_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:39 INFO Executor: Finished task 0.0 in stage 105.0 (TID 66). 1708 bytes result sent to driver
18/05/31 14:46:39 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 66) in 7 ms on localhost (executor driver) (1/1)
18/05/31 14:46:39 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
18/05/31 14:46:39 INFO DAGScheduler: ShuffleMapStage 105 (mapToPair at AnomalyDetector.java:64) finished in 0.007 s
18/05/31 14:46:39 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:39 INFO DAGScheduler: running: Set()
18/05/31 14:46:39 INFO DAGScheduler: waiting: Set(ResultStage 108)
18/05/31 14:46:39 INFO CheckpointWriter: Checkpoint for time 1527766900000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767190000', took 6325 bytes and 15 ms
18/05/31 14:46:39 INFO DAGScheduler: failed: Set()
18/05/31 14:46:39 INFO DStreamGraph: Clearing checkpoint data for time 1527766900000 ms
18/05/31 14:46:39 INFO DStreamGraph: Cleared checkpoint data for time 1527766900000 ms
18/05/31 14:46:39 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:39 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766700000: 
18/05/31 14:46:39 INFO InputInfoTracker: remove old batch metadata: 
18/05/31 14:46:39 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[70] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:39 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 8.4 KB, free 354.4 MB)
18/05/31 14:46:39 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 4.3 KB, free 354.4 MB)
18/05/31 14:46:39 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.66.169.34:53539 (size: 4.3 KB, free: 354.6 MB)
18/05/31 14:46:39 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 108 (MapPartitionsRDD[70] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:39 INFO TaskSchedulerImpl: Adding task set 108.0 with 4 tasks
18/05/31 14:46:39 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:46:39 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 68, localhost, executor driver, partition 1, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:46:39 INFO TaskSetManager: Starting task 2.0 in stage 108.0 (TID 69, localhost, executor driver, partition 2, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:46:39 INFO TaskSetManager: Starting task 3.0 in stage 108.0 (TID 70, localhost, executor driver, partition 3, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:46:39 INFO Executor: Running task 1.0 in stage 108.0 (TID 68)
18/05/31 14:46:39 INFO Executor: Running task 2.0 in stage 108.0 (TID 69)
18/05/31 14:46:39 INFO Executor: Running task 3.0 in stage 108.0 (TID 70)
18/05/31 14:46:39 INFO Executor: Running task 0.0 in stage 108.0 (TID 67)
18/05/31 14:46:39 INFO BlockManager: Found block rdd_64_3 locally
18/05/31 14:46:39 INFO BlockManager: Found block rdd_64_1 locally
18/05/31 14:46:39 INFO BlockManager: Found block rdd_64_2 locally
18/05/31 14:46:39 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:39 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:39 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:46:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:46:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:39 INFO MemoryStore: Block rdd_69_1 stored as values in memory (estimated size 11.6 KB, free 354.4 MB)
18/05/31 14:46:39 INFO MemoryStore: Block rdd_69_3 stored as values in memory (estimated size 11.6 KB, free 354.4 MB)
18/05/31 14:46:39 INFO BlockManagerInfo: Added rdd_69_1 in memory on 10.66.169.34:53539 (size: 11.6 KB, free: 354.6 MB)
18/05/31 14:46:39 INFO BlockManagerInfo: Added rdd_69_3 in memory on 10.66.169.34:53539 (size: 11.6 KB, free: 354.6 MB)
18/05/31 14:46:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-49
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-50
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:39 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:39 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:39 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:39 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:39 WARN Executor: 1 block locks were not released by TID = 70:
[rdd_64_3]
18/05/31 14:46:39 WARN Executor: 1 block locks were not released by TID = 68:
[rdd_64_1]
18/05/31 14:46:39 INFO Executor: Finished task 1.0 in stage 108.0 (TID 68). 2359 bytes result sent to driver
18/05/31 14:46:39 INFO Executor: Finished task 3.0 in stage 108.0 (TID 70). 2359 bytes result sent to driver
18/05/31 14:46:39 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 68) in 10 ms on localhost (executor driver) (1/4)
18/05/31 14:46:39 INFO TaskSetManager: Finished task 3.0 in stage 108.0 (TID 70) in 9 ms on localhost (executor driver) (2/4)
18/05/31 14:46:39 INFO BlockManager: Found block rdd_64_0 locally
18/05/31 14:46:39 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:39 INFO MemoryStore: Block rdd_69_0 stored as values in memory (estimated size 11.6 KB, free 354.3 MB)
18/05/31 14:46:39 INFO BlockManagerInfo: Added rdd_69_0 in memory on 10.66.169.34:53539 (size: 11.6 KB, free: 354.6 MB)
18/05/31 14:46:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-51
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:39 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:39 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:39 WARN Executor: 1 block locks were not released by TID = 67:
[rdd_64_0]
18/05/31 14:46:39 INFO Executor: Finished task 0.0 in stage 108.0 (TID 67). 2359 bytes result sent to driver
18/05/31 14:46:39 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 67) in 17 ms on localhost (executor driver) (3/4)
18/05/31 14:46:40 INFO MappedDStream: Marking RDD 215 for time 1527767200000 ms for checkpointing
18/05/31 14:46:40 INFO JobScheduler: Added jobs for time 1527767200000 ms
18/05/31 14:46:40 INFO JobGenerator: Checkpointing graph for time 1527767200000 ms
18/05/31 14:46:40 INFO DStreamGraph: Updating checkpoint data for time 1527767200000 ms
18/05/31 14:46:40 INFO DStreamGraph: Updated checkpoint data for time 1527767200000 ms
18/05/31 14:46:40 INFO CheckpointWriter: Submitted checkpoint of time 1527767200000 ms to writer queue
18/05/31 14:46:40 INFO CheckpointWriter: Saving checkpoint for time 1527767200000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000'
18/05/31 14:46:40 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767120000
18/05/31 14:46:40 INFO CheckpointWriter: Checkpoint for time 1527767200000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000', took 6320 bytes and 14 ms
18/05/31 14:46:40 INFO MemoryStore: 7 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:46:40 INFO BlockManager: Dropping block rdd_54_3 from memory
18/05/31 14:46:40 INFO BlockManagerInfo: Removed rdd_54_3 on 10.66.169.34:53539 in memory (size: 9.4 KB, free: 354.6 MB)
18/05/31 14:46:40 INFO BlockManager: Dropping block rdd_54_1 from memory
18/05/31 14:46:40 INFO BlockManagerInfo: Removed rdd_54_1 on 10.66.169.34:53539 in memory (size: 9.4 KB, free: 354.6 MB)
18/05/31 14:46:40 INFO BlockManager: Dropping block rdd_54_0 from memory
18/05/31 14:46:40 INFO BlockManagerInfo: Removed rdd_54_0 on 10.66.169.34:53539 in memory (size: 9.4 KB, free: 354.6 MB)
18/05/31 14:46:40 INFO BlockManager: Dropping block broadcast_29_piece0 from memory
18/05/31 14:46:40 INFO BlockManager: Writing block broadcast_29_piece0 to disk
18/05/31 14:46:40 INFO BlockManagerInfo: Added broadcast_29_piece0 on disk on 10.66.169.34:53539 (size: 4.3 KB)
18/05/31 14:46:40 INFO BlockManager: Dropping block rdd_59_3 from memory
18/05/31 14:46:40 INFO BlockManagerInfo: Removed rdd_59_3 on 10.66.169.34:53539 in memory (size: 10.1 KB, free: 354.7 MB)
18/05/31 14:46:40 INFO BlockManager: Dropping block rdd_59_1 from memory
18/05/31 14:46:40 INFO BlockManagerInfo: Removed rdd_59_1 on 10.66.169.34:53539 in memory (size: 10.1 KB, free: 354.7 MB)
18/05/31 14:46:40 INFO BlockManager: Dropping block rdd_59_2 from memory
18/05/31 14:46:40 INFO BlockManagerInfo: Removed rdd_59_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:46:40 INFO MemoryStore: After dropping 7 blocks, free memory is 633.2 MB
18/05/31 14:46:41 INFO MemoryStore: Block rdd_69_2 stored as values in memory (estimated size 278.8 MB, free 354.4 MB)
18/05/31 14:46:41 INFO BlockManagerInfo: Added rdd_69_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:46:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-52
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:41 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:41 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:41 WARN Executor: 1 block locks were not released by TID = 69:
[rdd_64_2]
18/05/31 14:46:41 INFO Executor: Finished task 2.0 in stage 108.0 (TID 69). 2804 bytes result sent to driver
18/05/31 14:46:41 INFO TaskSetManager: Finished task 2.0 in stage 108.0 (TID 69) in 1706 ms on localhost (executor driver) (4/4)
18/05/31 14:46:41 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
18/05/31 14:46:41 INFO DAGScheduler: ResultStage 108 (foreachPartition at AnomalyDetector.java:69) finished in 1.708 s
18/05/31 14:46:41 INFO DAGScheduler: Job 15 finished: foreachPartition at AnomalyDetector.java:69, took 1.726211 s
18/05/31 14:46:41 INFO JobScheduler: Finished job streaming job 1527766910000 ms.0 from job set of time 1527766910000 ms
18/05/31 14:46:41 INFO JobScheduler: Total delay: 291.078 s for time 1527766910000 ms (execution: 1.731 s)
18/05/31 14:46:41 INFO MapPartitionsRDD: Removing RDD 65 from persistence list
18/05/31 14:46:41 INFO JobScheduler: Starting job streaming job 1527766920000 ms.0 from job set of time 1527766920000 ms
18/05/31 14:46:41 INFO BlockManager: Removing RDD 65
18/05/31 14:46:41 INFO JobGenerator: Checkpointing graph for time 1527766910000 ms
18/05/31 14:46:41 INFO DStreamGraph: Updating checkpoint data for time 1527766910000 ms
18/05/31 14:46:41 INFO DStreamGraph: Updated checkpoint data for time 1527766910000 ms
18/05/31 14:46:41 INFO CheckpointWriter: Submitted checkpoint of time 1527766910000 ms to writer queue
18/05/31 14:46:41 INFO CheckpointWriter: Saving checkpoint for time 1527766910000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000'
18/05/31 14:46:41 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:41 INFO DAGScheduler: Registering RDD 72 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 149 bytes
18/05/31 14:46:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 149 bytes
18/05/31 14:46:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 149 bytes
18/05/31 14:46:41 INFO DAGScheduler: Got job 16 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:41 INFO DAGScheduler: Final stage: ResultStage 113 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 111, ShuffleMapStage 112, ShuffleMapStage 109, ShuffleMapStage 110)
18/05/31 14:46:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 109)
18/05/31 14:46:41 INFO DAGScheduler: Submitting ShuffleMapStage 109 (MapPartitionsRDD[72] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:41 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 4.6 KB, free 354.4 MB)
18/05/31 14:46:41 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.4 MB)
18/05/31 14:46:41 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:46:41 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 109 (MapPartitionsRDD[72] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:41 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
18/05/31 14:46:41 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:41 INFO Executor: Running task 0.0 in stage 109.0 (TID 71)
18/05/31 14:46:41 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:41 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767130000
18/05/31 14:46:41 INFO MemoryStore: Block rdd_72_0 stored as bytes in memory (estimated size 4.0 B, free 354.4 MB)
18/05/31 14:46:41 INFO BlockManagerInfo: Added rdd_72_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:41 INFO CheckpointWriter: Checkpoint for time 1527766910000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000', took 6326 bytes and 28 ms
18/05/31 14:46:41 INFO DStreamGraph: Clearing checkpoint data for time 1527766910000 ms
18/05/31 14:46:41 INFO DStreamGraph: Cleared checkpoint data for time 1527766910000 ms
18/05/31 14:46:41 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:41 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766710000: 
18/05/31 14:46:41 INFO InputInfoTracker: remove old batch metadata: 
18/05/31 14:46:41 INFO Executor: Finished task 0.0 in stage 109.0 (TID 71). 1708 bytes result sent to driver
18/05/31 14:46:41 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 71) in 22 ms on localhost (executor driver) (1/1)
18/05/31 14:46:41 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
18/05/31 14:46:41 INFO DAGScheduler: ShuffleMapStage 109 (mapToPair at AnomalyDetector.java:64) finished in 0.023 s
18/05/31 14:46:41 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:41 INFO DAGScheduler: running: Set()
18/05/31 14:46:41 INFO DAGScheduler: waiting: Set(ResultStage 113)
18/05/31 14:46:41 INFO DAGScheduler: failed: Set()
18/05/31 14:46:41 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[75] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:41 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 8.6 KB, free 354.4 MB)
18/05/31 14:46:41 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 4.4 KB, free 354.4 MB)
18/05/31 14:46:41 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.66.169.34:53539 (size: 4.4 KB, free: 354.7 MB)
18/05/31 14:46:41 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 113 (MapPartitionsRDD[75] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:41 INFO TaskSchedulerImpl: Adding task set 113.0 with 4 tasks
18/05/31 14:46:41 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:46:41 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 73, localhost, executor driver, partition 1, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:46:41 INFO TaskSetManager: Starting task 2.0 in stage 113.0 (TID 74, localhost, executor driver, partition 2, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:46:41 INFO TaskSetManager: Starting task 3.0 in stage 113.0 (TID 75, localhost, executor driver, partition 3, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:46:41 INFO Executor: Running task 1.0 in stage 113.0 (TID 73)
18/05/31 14:46:41 INFO Executor: Running task 2.0 in stage 113.0 (TID 74)
18/05/31 14:46:41 INFO Executor: Running task 3.0 in stage 113.0 (TID 75)
18/05/31 14:46:41 INFO BlockManager: Found block rdd_69_1 locally
18/05/31 14:46:41 INFO BlockManager: Found block rdd_69_2 locally
18/05/31 14:46:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:46:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:46:41 INFO MemoryStore: Block rdd_74_1 stored as values in memory (estimated size 12.4 KB, free 354.4 MB)
18/05/31 14:46:41 INFO BlockManager: Found block rdd_69_3 locally
18/05/31 14:46:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:41 INFO BlockManagerInfo: Added rdd_74_1 in memory on 10.66.169.34:53539 (size: 12.4 KB, free: 354.6 MB)
18/05/31 14:46:41 INFO MemoryStore: Block rdd_74_3 stored as values in memory (estimated size 12.4 KB, free 354.3 MB)
18/05/31 14:46:41 INFO BlockManagerInfo: Added rdd_74_3 in memory on 10.66.169.34:53539 (size: 12.4 KB, free: 354.6 MB)
18/05/31 14:46:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-53
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:41 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:41 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:41 WARN Executor: 1 block locks were not released by TID = 73:
[rdd_69_1]
18/05/31 14:46:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-54
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:41 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:41 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:41 WARN Executor: 1 block locks were not released by TID = 75:
[rdd_69_3]
18/05/31 14:46:41 INFO Executor: Finished task 3.0 in stage 113.0 (TID 75). 2359 bytes result sent to driver
18/05/31 14:46:41 INFO Executor: Finished task 1.0 in stage 113.0 (TID 73). 2359 bytes result sent to driver
18/05/31 14:46:41 INFO TaskSetManager: Finished task 3.0 in stage 113.0 (TID 75) in 17 ms on localhost (executor driver) (1/4)
18/05/31 14:46:41 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 73) in 18 ms on localhost (executor driver) (2/4)
18/05/31 14:46:41 INFO Executor: Running task 0.0 in stage 113.0 (TID 72)
18/05/31 14:46:41 INFO BlockManager: Found block rdd_69_0 locally
18/05/31 14:46:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:41 INFO MemoryStore: Block rdd_74_0 stored as values in memory (estimated size 12.4 KB, free 354.3 MB)
18/05/31 14:46:41 INFO BlockManagerInfo: Added rdd_74_0 in memory on 10.66.169.34:53539 (size: 12.4 KB, free: 354.6 MB)
18/05/31 14:46:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-55
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:41 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:41 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:41 WARN Executor: 1 block locks were not released by TID = 72:
[rdd_69_0]
18/05/31 14:46:41 INFO Executor: Finished task 0.0 in stage 113.0 (TID 72). 2359 bytes result sent to driver
18/05/31 14:46:41 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 72) in 32 ms on localhost (executor driver) (3/4)
18/05/31 14:46:42 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 10.66.169.34:53539 on disk (size: 4.3 KB)
18/05/31 14:46:42 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 10.66.169.34:53539 in memory (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:46:42 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 354.6 MB)
18/05/31 14:46:42 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:46:42 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 10.66.169.34:53539 in memory (size: 4.3 KB, free: 354.6 MB)
18/05/31 14:46:42 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:46:42 INFO MemoryStore: 8 blocks selected for dropping (278.9 MB bytes)
18/05/31 14:46:42 INFO BlockManager: Dropping block rdd_59_0 from memory
18/05/31 14:46:42 INFO BlockManagerInfo: Removed rdd_59_0 on 10.66.169.34:53539 in memory (size: 10.1 KB, free: 354.7 MB)
18/05/31 14:46:42 INFO BlockManager: Dropping block rdd_62_0 from memory
18/05/31 14:46:42 INFO BlockManagerInfo: Removed rdd_62_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:42 INFO BlockManager: Dropping block broadcast_32 from memory
18/05/31 14:46:42 INFO BlockManager: Writing block broadcast_32 to disk
18/05/31 14:46:42 INFO BlockManager: Dropping block broadcast_32_piece0 from memory
18/05/31 14:46:42 INFO BlockManager: Writing block broadcast_32_piece0 to disk
18/05/31 14:46:42 INFO BlockManagerInfo: Added broadcast_32_piece0 on disk on 10.66.169.34:53539 (size: 14.3 KB)
18/05/31 14:46:42 INFO BlockManager: Dropping block rdd_67_0 from memory
18/05/31 14:46:42 INFO BlockManagerInfo: Removed rdd_67_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:42 INFO BlockManager: Dropping block rdd_64_3 from memory
18/05/31 14:46:42 INFO BlockManagerInfo: Removed rdd_64_3 on 10.66.169.34:53539 in memory (size: 10.9 KB, free: 354.7 MB)
18/05/31 14:46:42 INFO BlockManager: Dropping block rdd_64_1 from memory
18/05/31 14:46:42 INFO BlockManagerInfo: Removed rdd_64_1 on 10.66.169.34:53539 in memory (size: 10.9 KB, free: 354.7 MB)
18/05/31 14:46:42 INFO BlockManager: Dropping block rdd_64_2 from memory
18/05/31 14:46:42 INFO BlockManagerInfo: Removed rdd_64_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:46:42 INFO MemoryStore: After dropping 8 blocks, free memory is 633.4 MB
18/05/31 14:46:42 INFO MemoryStore: Block rdd_74_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:46:42 INFO BlockManagerInfo: Added rdd_74_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:46:42 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:42 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-56
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:42 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:42 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:42 WARN Executor: 1 block locks were not released by TID = 74:
[rdd_69_2]
18/05/31 14:46:42 INFO Executor: Finished task 2.0 in stage 113.0 (TID 74). 2927 bytes result sent to driver
18/05/31 14:46:42 INFO TaskSetManager: Finished task 2.0 in stage 113.0 (TID 74) in 1772 ms on localhost (executor driver) (4/4)
18/05/31 14:46:42 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
18/05/31 14:46:42 INFO DAGScheduler: ResultStage 113 (foreachPartition at AnomalyDetector.java:69) finished in 1.773 s
18/05/31 14:46:42 INFO DAGScheduler: Job 16 finished: foreachPartition at AnomalyDetector.java:69, took 1.811861 s
18/05/31 14:46:42 INFO JobScheduler: Finished job streaming job 1527766920000 ms.0 from job set of time 1527766920000 ms
18/05/31 14:46:42 INFO JobScheduler: Total delay: 282.899 s for time 1527766920000 ms (execution: 1.820 s)
18/05/31 14:46:42 INFO JobScheduler: Starting job streaming job 1527766930000 ms.0 from job set of time 1527766930000 ms
18/05/31 14:46:42 INFO MapPartitionsRDD: Removing RDD 70 from persistence list
18/05/31 14:46:42 INFO BlockManager: Removing RDD 70
18/05/31 14:46:42 INFO JobGenerator: Checkpointing graph for time 1527766920000 ms
18/05/31 14:46:42 INFO DStreamGraph: Updating checkpoint data for time 1527766920000 ms
18/05/31 14:46:42 INFO DStreamGraph: Updated checkpoint data for time 1527766920000 ms
18/05/31 14:46:42 INFO CheckpointWriter: Submitted checkpoint of time 1527766920000 ms to writer queue
18/05/31 14:46:42 INFO CheckpointWriter: Saving checkpoint for time 1527766920000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000'
18/05/31 14:46:42 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 149 bytes
18/05/31 14:46:42 INFO DAGScheduler: Registering RDD 77 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 149 bytes
18/05/31 14:46:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 149 bytes
18/05/31 14:46:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 149 bytes
18/05/31 14:46:42 INFO DAGScheduler: Got job 17 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:42 INFO DAGScheduler: Final stage: ResultStage 119 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 114, ShuffleMapStage 118, ShuffleMapStage 115, ShuffleMapStage 116)
18/05/31 14:46:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 115)
18/05/31 14:46:42 INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[77] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:42 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:46:42 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.7 MB)
18/05/31 14:46:42 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:46:42 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[77] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:42 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
18/05/31 14:46:42 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:42 INFO Executor: Running task 0.0 in stage 115.0 (TID 76)
18/05/31 14:46:42 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:42 INFO MemoryStore: Block rdd_77_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:46:42 INFO BlockManagerInfo: Added rdd_77_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:42 INFO Executor: Finished task 0.0 in stage 115.0 (TID 76). 1708 bytes result sent to driver
18/05/31 14:46:42 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 76) in 9 ms on localhost (executor driver) (1/1)
18/05/31 14:46:42 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
18/05/31 14:46:42 INFO DAGScheduler: ShuffleMapStage 115 (mapToPair at AnomalyDetector.java:64) finished in 0.010 s
18/05/31 14:46:42 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:42 INFO DAGScheduler: running: Set()
18/05/31 14:46:42 INFO DAGScheduler: waiting: Set(ResultStage 119)
18/05/31 14:46:42 INFO DAGScheduler: failed: Set()
18/05/31 14:46:42 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[80] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:42 INFO CheckpointWriter: Checkpoint for time 1527766920000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000', took 6328 bytes and 20 ms
18/05/31 14:46:42 INFO DStreamGraph: Clearing checkpoint data for time 1527766920000 ms
18/05/31 14:46:42 INFO DStreamGraph: Cleared checkpoint data for time 1527766920000 ms
18/05/31 14:46:42 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:42 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766720000: 
18/05/31 14:46:42 INFO InputInfoTracker: remove old batch metadata: 
18/05/31 14:46:42 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 8.9 KB, free 354.7 MB)
18/05/31 14:46:42 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.7 MB)
18/05/31 14:46:42 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.66.169.34:53539 (size: 4.5 KB, free: 354.7 MB)
18/05/31 14:46:42 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:42 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 119 (MapPartitionsRDD[80] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:42 INFO TaskSchedulerImpl: Adding task set 119.0 with 4 tasks
18/05/31 14:46:42 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:46:42 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 78, localhost, executor driver, partition 1, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:46:42 INFO TaskSetManager: Starting task 2.0 in stage 119.0 (TID 79, localhost, executor driver, partition 2, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:46:42 INFO TaskSetManager: Starting task 3.0 in stage 119.0 (TID 80, localhost, executor driver, partition 3, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:46:42 INFO Executor: Running task 0.0 in stage 119.0 (TID 77)
18/05/31 14:46:42 INFO Executor: Running task 1.0 in stage 119.0 (TID 78)
18/05/31 14:46:42 INFO Executor: Running task 2.0 in stage 119.0 (TID 79)
18/05/31 14:46:42 INFO Executor: Running task 3.0 in stage 119.0 (TID 80)
18/05/31 14:46:42 INFO BlockManager: Found block rdd_74_1 locally
18/05/31 14:46:42 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:42 INFO BlockManager: Found block rdd_74_0 locally
18/05/31 14:46:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:42 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:42 INFO BlockManager: Found block rdd_74_3 locally
18/05/31 14:46:42 INFO MemoryStore: Block rdd_79_1 stored as values in memory (estimated size 13.2 KB, free 354.7 MB)
18/05/31 14:46:42 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:42 INFO MemoryStore: Block rdd_79_0 stored as values in memory (estimated size 13.2 KB, free 354.6 MB)
18/05/31 14:46:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:42 INFO BlockManagerInfo: Added rdd_79_1 in memory on 10.66.169.34:53539 (size: 13.2 KB, free: 354.7 MB)
18/05/31 14:46:42 INFO BlockManagerInfo: Added rdd_79_0 in memory on 10.66.169.34:53539 (size: 13.2 KB, free: 354.7 MB)
18/05/31 14:46:42 INFO BlockManager: Found block rdd_74_2 locally
18/05/31 14:46:42 INFO MemoryStore: Block rdd_79_3 stored as values in memory (estimated size 13.2 KB, free 354.6 MB)
18/05/31 14:46:42 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:42 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:42 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:42 INFO BlockManagerInfo: Added rdd_79_3 in memory on 10.66.169.34:53539 (size: 13.2 KB, free: 354.6 MB)
18/05/31 14:46:42 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:42 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-58
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:42 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:42 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:42 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-57
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:42 WARN Executor: 1 block locks were not released by TID = 77:
[rdd_74_0]
18/05/31 14:46:42 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:42 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:42 WARN Executor: 1 block locks were not released by TID = 78:
[rdd_74_1]
18/05/31 14:46:42 INFO Executor: Finished task 0.0 in stage 119.0 (TID 77). 2359 bytes result sent to driver
18/05/31 14:46:42 INFO Executor: Finished task 1.0 in stage 119.0 (TID 78). 2359 bytes result sent to driver
18/05/31 14:46:42 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 77) in 15 ms on localhost (executor driver) (1/4)
18/05/31 14:46:42 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 78) in 15 ms on localhost (executor driver) (2/4)
18/05/31 14:46:42 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-59
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:42 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:42 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:42 WARN Executor: 1 block locks were not released by TID = 80:
[rdd_74_3]
18/05/31 14:46:42 INFO Executor: Finished task 3.0 in stage 119.0 (TID 80). 2359 bytes result sent to driver
18/05/31 14:46:42 INFO TaskSetManager: Finished task 3.0 in stage 119.0 (TID 80) in 17 ms on localhost (executor driver) (3/4)
18/05/31 14:46:43 INFO MemoryStore: 5 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:46:43 INFO BlockManager: Dropping block rdd_64_0 from memory
18/05/31 14:46:43 INFO BlockManagerInfo: Removed rdd_64_0 on 10.66.169.34:53539 in memory (size: 10.9 KB, free: 354.7 MB)
18/05/31 14:46:43 INFO BlockManager: Dropping block rdd_72_0 from memory
18/05/31 14:46:43 INFO BlockManagerInfo: Removed rdd_72_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:43 INFO BlockManager: Dropping block broadcast_36_piece0 from memory
18/05/31 14:46:43 INFO BlockManager: Writing block broadcast_36_piece0 to disk
18/05/31 14:46:43 INFO BlockManagerInfo: Added broadcast_36_piece0 on disk on 10.66.169.34:53539 (size: 4.4 KB)
18/05/31 14:46:43 INFO BlockManager: Dropping block rdd_69_1 from memory
18/05/31 14:46:43 INFO BlockManagerInfo: Removed rdd_69_1 on 10.66.169.34:53539 in memory (size: 11.6 KB, free: 354.7 MB)
18/05/31 14:46:43 INFO BlockManager: Dropping block rdd_69_2 from memory
18/05/31 14:46:43 INFO BlockManagerInfo: Removed rdd_69_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:46:43 INFO MemoryStore: After dropping 5 blocks, free memory is 633.4 MB
18/05/31 14:46:44 INFO MemoryStore: Block rdd_79_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:46:44 INFO BlockManagerInfo: Added rdd_79_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:46:44 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:44 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-60
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:44 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:44 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:44 WARN Executor: 1 block locks were not released by TID = 79:
[rdd_74_2]
18/05/31 14:46:44 INFO Executor: Finished task 2.0 in stage 119.0 (TID 79). 2710 bytes result sent to driver
18/05/31 14:46:44 INFO TaskSetManager: Finished task 2.0 in stage 119.0 (TID 79) in 1592 ms on localhost (executor driver) (4/4)
18/05/31 14:46:44 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
18/05/31 14:46:44 INFO DAGScheduler: ResultStage 119 (foreachPartition at AnomalyDetector.java:69) finished in 1.594 s
18/05/31 14:46:44 INFO DAGScheduler: Job 17 finished: foreachPartition at AnomalyDetector.java:69, took 1.616899 s
18/05/31 14:46:44 INFO JobScheduler: Finished job streaming job 1527766930000 ms.0 from job set of time 1527766930000 ms
18/05/31 14:46:44 INFO JobScheduler: Total delay: 274.519 s for time 1527766930000 ms (execution: 1.620 s)
18/05/31 14:46:44 INFO MapPartitionsRDD: Removing RDD 75 from persistence list
18/05/31 14:46:44 INFO JobScheduler: Starting job streaming job 1527766940000 ms.0 from job set of time 1527766940000 ms
18/05/31 14:46:44 INFO BlockManager: Removing RDD 75
18/05/31 14:46:44 INFO JobGenerator: Checkpointing graph for time 1527766930000 ms
18/05/31 14:46:44 INFO DStreamGraph: Updating checkpoint data for time 1527766930000 ms
18/05/31 14:46:44 INFO DStreamGraph: Updated checkpoint data for time 1527766930000 ms
18/05/31 14:46:44 INFO CheckpointWriter: Submitted checkpoint of time 1527766930000 ms to writer queue
18/05/31 14:46:44 INFO CheckpointWriter: Saving checkpoint for time 1527766930000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000'
18/05/31 14:46:44 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 149 bytes
18/05/31 14:46:44 INFO DAGScheduler: Registering RDD 82 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 149 bytes
18/05/31 14:46:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 149 bytes
18/05/31 14:46:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 149 bytes
18/05/31 14:46:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 149 bytes
18/05/31 14:46:44 INFO DAGScheduler: Got job 18 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:44 INFO DAGScheduler: Final stage: ResultStage 126 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121, ShuffleMapStage 125, ShuffleMapStage 122, ShuffleMapStage 123, ShuffleMapStage 120, ShuffleMapStage 124)
18/05/31 14:46:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 121)
18/05/31 14:46:44 INFO DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[82] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:44 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 4.6 KB, free 354.6 MB)
18/05/31 14:46:44 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.6 MB)
18/05/31 14:46:44 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:46:44 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[82] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:44 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
18/05/31 14:46:44 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:44 INFO Executor: Running task 0.0 in stage 121.0 (TID 81)
18/05/31 14:46:44 INFO CheckpointWriter: Checkpoint for time 1527766930000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000', took 6317 bytes and 19 ms
18/05/31 14:46:44 INFO DStreamGraph: Clearing checkpoint data for time 1527766930000 ms
18/05/31 14:46:44 INFO DStreamGraph: Cleared checkpoint data for time 1527766930000 ms
18/05/31 14:46:44 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:44 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766730000: 
18/05/31 14:46:44 INFO InputInfoTracker: remove old batch metadata: 
18/05/31 14:46:44 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:44 INFO MemoryStore: Block rdd_82_0 stored as bytes in memory (estimated size 4.0 B, free 354.6 MB)
18/05/31 14:46:44 INFO BlockManagerInfo: Added rdd_82_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:44 INFO Executor: Finished task 0.0 in stage 121.0 (TID 81). 1708 bytes result sent to driver
18/05/31 14:46:44 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 81) in 11 ms on localhost (executor driver) (1/1)
18/05/31 14:46:44 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
18/05/31 14:46:44 INFO DAGScheduler: ShuffleMapStage 121 (mapToPair at AnomalyDetector.java:64) finished in 0.011 s
18/05/31 14:46:44 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:44 INFO DAGScheduler: running: Set()
18/05/31 14:46:44 INFO DAGScheduler: waiting: Set(ResultStage 126)
18/05/31 14:46:44 INFO DAGScheduler: failed: Set()
18/05/31 14:46:44 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[85] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:44 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 9.2 KB, free 354.6 MB)
18/05/31 14:46:44 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.6 MB)
18/05/31 14:46:44 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.66.169.34:53539 (size: 4.5 KB, free: 354.7 MB)
18/05/31 14:46:44 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:44 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 126 (MapPartitionsRDD[85] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:44 INFO TaskSchedulerImpl: Adding task set 126.0 with 4 tasks
18/05/31 14:46:44 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:46:44 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 83, localhost, executor driver, partition 1, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:46:44 INFO TaskSetManager: Starting task 2.0 in stage 126.0 (TID 84, localhost, executor driver, partition 2, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:46:44 INFO TaskSetManager: Starting task 3.0 in stage 126.0 (TID 85, localhost, executor driver, partition 3, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:46:44 INFO Executor: Running task 1.0 in stage 126.0 (TID 83)
18/05/31 14:46:44 INFO Executor: Running task 2.0 in stage 126.0 (TID 84)
18/05/31 14:46:44 INFO Executor: Running task 3.0 in stage 126.0 (TID 85)
18/05/31 14:46:44 INFO BlockManager: Found block rdd_79_2 locally
18/05/31 14:46:44 INFO BlockManager: Found block rdd_79_3 locally
18/05/31 14:46:44 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:44 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:44 INFO MemoryStore: Block rdd_84_3 stored as values in memory (estimated size 13.9 KB, free 354.6 MB)
18/05/31 14:46:44 INFO BlockManagerInfo: Added rdd_84_3 in memory on 10.66.169.34:53539 (size: 13.9 KB, free: 354.7 MB)
18/05/31 14:46:44 INFO BlockManager: Found block rdd_79_1 locally
18/05/31 14:46:44 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:44 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:46:44 INFO MemoryStore: Block rdd_84_1 stored as values in memory (estimated size 13.9 KB, free 354.6 MB)
18/05/31 14:46:44 INFO BlockManagerInfo: Added rdd_84_1 in memory on 10.66.169.34:53539 (size: 13.9 KB, free: 354.6 MB)
18/05/31 14:46:44 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:44 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-61
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:44 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:44 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:44 WARN Executor: 1 block locks were not released by TID = 85:
[rdd_79_3]
18/05/31 14:46:44 INFO Executor: Finished task 3.0 in stage 126.0 (TID 85). 2359 bytes result sent to driver
18/05/31 14:46:44 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-62
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:44 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:44 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:44 INFO TaskSetManager: Finished task 3.0 in stage 126.0 (TID 85) in 13 ms on localhost (executor driver) (1/4)
18/05/31 14:46:44 WARN Executor: 1 block locks were not released by TID = 83:
[rdd_79_1]
18/05/31 14:46:44 INFO Executor: Finished task 1.0 in stage 126.0 (TID 83). 2359 bytes result sent to driver
18/05/31 14:46:44 INFO Executor: Running task 0.0 in stage 126.0 (TID 82)
18/05/31 14:46:44 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 83) in 15 ms on localhost (executor driver) (2/4)
18/05/31 14:46:44 INFO BlockManager: Found block rdd_79_0 locally
18/05/31 14:46:44 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:44 INFO MemoryStore: Block rdd_84_0 stored as values in memory (estimated size 13.9 KB, free 354.6 MB)
18/05/31 14:46:44 INFO BlockManagerInfo: Added rdd_84_0 in memory on 10.66.169.34:53539 (size: 13.9 KB, free: 354.6 MB)
18/05/31 14:46:44 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:44 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-63
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:44 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:44 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:44 WARN Executor: 1 block locks were not released by TID = 82:
[rdd_79_0]
18/05/31 14:46:44 INFO Executor: Finished task 0.0 in stage 126.0 (TID 82). 2359 bytes result sent to driver
18/05/31 14:46:44 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 82) in 23 ms on localhost (executor driver) (3/4)
18/05/31 14:46:45 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 10.66.169.34:53539 on disk (size: 4.4 KB)
18/05/31 14:46:45 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:46:45 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 10.66.169.34:53539 in memory (size: 4.5 KB, free: 354.6 MB)
18/05/31 14:46:45 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:46:45 INFO MemoryStore: 7 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:46:45 INFO BlockManager: Dropping block rdd_69_3 from memory
18/05/31 14:46:45 INFO BlockManagerInfo: Removed rdd_69_3 on 10.66.169.34:53539 in memory (size: 11.6 KB, free: 354.6 MB)
18/05/31 14:46:45 INFO BlockManager: Dropping block rdd_69_0 from memory
18/05/31 14:46:45 INFO BlockManagerInfo: Removed rdd_69_0 on 10.66.169.34:53539 in memory (size: 11.6 KB, free: 354.7 MB)
18/05/31 14:46:45 INFO BlockManager: Dropping block rdd_77_0 from memory
18/05/31 14:46:45 INFO BlockManagerInfo: Removed rdd_77_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:45 INFO BlockManager: Dropping block rdd_74_1 from memory
18/05/31 14:46:45 INFO BlockManagerInfo: Removed rdd_74_1 on 10.66.169.34:53539 in memory (size: 12.4 KB, free: 354.7 MB)
18/05/31 14:46:45 INFO BlockManager: Dropping block rdd_74_0 from memory
18/05/31 14:46:45 INFO BlockManagerInfo: Removed rdd_74_0 on 10.66.169.34:53539 in memory (size: 12.4 KB, free: 354.7 MB)
18/05/31 14:46:45 INFO BlockManager: Dropping block rdd_74_3 from memory
18/05/31 14:46:45 INFO BlockManagerInfo: Removed rdd_74_3 on 10.66.169.34:53539 in memory (size: 12.4 KB, free: 354.7 MB)
18/05/31 14:46:45 INFO BlockManager: Dropping block rdd_74_2 from memory
18/05/31 14:46:45 INFO BlockManagerInfo: Removed rdd_74_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:46:45 INFO MemoryStore: After dropping 7 blocks, free memory is 633.4 MB
18/05/31 14:46:46 INFO MemoryStore: Block rdd_84_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:46:46 INFO BlockManagerInfo: Added rdd_84_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:46:46 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:46 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-64
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:46 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:46 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:46 WARN Executor: 1 block locks were not released by TID = 84:
[rdd_79_2]
18/05/31 14:46:46 INFO Executor: Finished task 2.0 in stage 126.0 (TID 84). 2767 bytes result sent to driver
18/05/31 14:46:46 INFO TaskSetManager: Finished task 2.0 in stage 126.0 (TID 84) in 1709 ms on localhost (executor driver) (4/4)
18/05/31 14:46:46 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
18/05/31 14:46:46 INFO DAGScheduler: ResultStage 126 (foreachPartition at AnomalyDetector.java:69) finished in 1.711 s
18/05/31 14:46:46 INFO DAGScheduler: Job 18 finished: foreachPartition at AnomalyDetector.java:69, took 1.736763 s
18/05/31 14:46:46 INFO JobScheduler: Finished job streaming job 1527766940000 ms.0 from job set of time 1527766940000 ms
18/05/31 14:46:46 INFO JobScheduler: Total delay: 266.260 s for time 1527766940000 ms (execution: 1.740 s)
18/05/31 14:46:46 INFO MapPartitionsRDD: Removing RDD 80 from persistence list
18/05/31 14:46:46 INFO JobScheduler: Starting job streaming job 1527766950000 ms.0 from job set of time 1527766950000 ms
18/05/31 14:46:46 INFO BlockManager: Removing RDD 80
18/05/31 14:46:46 INFO JobGenerator: Checkpointing graph for time 1527766940000 ms
18/05/31 14:46:46 INFO DStreamGraph: Updating checkpoint data for time 1527766940000 ms
18/05/31 14:46:46 INFO DStreamGraph: Updated checkpoint data for time 1527766940000 ms
18/05/31 14:46:46 INFO CheckpointWriter: Submitted checkpoint of time 1527766940000 ms to writer queue
18/05/31 14:46:46 INFO CheckpointWriter: Saving checkpoint for time 1527766940000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000'
18/05/31 14:46:46 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 149 bytes
18/05/31 14:46:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 149 bytes
18/05/31 14:46:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 149 bytes
18/05/31 14:46:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 149 bytes
18/05/31 14:46:46 INFO DAGScheduler: Registering RDD 87 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 149 bytes
18/05/31 14:46:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 149 bytes
18/05/31 14:46:46 INFO DAGScheduler: Got job 19 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:46 INFO DAGScheduler: Final stage: ResultStage 134 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132, ShuffleMapStage 129, ShuffleMapStage 133, ShuffleMapStage 130, ShuffleMapStage 127, ShuffleMapStage 131, ShuffleMapStage 128)
18/05/31 14:46:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 131)
18/05/31 14:46:46 INFO DAGScheduler: Submitting ShuffleMapStage 131 (MapPartitionsRDD[87] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:46 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:46:46 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.7 MB)
18/05/31 14:46:46 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:46:46 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[87] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:46 INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks
18/05/31 14:46:46 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:46 INFO Executor: Running task 0.0 in stage 131.0 (TID 86)
18/05/31 14:46:46 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:46 INFO MemoryStore: Block rdd_87_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:46:46 INFO CheckpointWriter: Checkpoint for time 1527766940000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000', took 6322 bytes and 18 ms
18/05/31 14:46:46 INFO BlockManagerInfo: Added rdd_87_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:46 INFO DStreamGraph: Clearing checkpoint data for time 1527766940000 ms
18/05/31 14:46:46 INFO DStreamGraph: Cleared checkpoint data for time 1527766940000 ms
18/05/31 14:46:46 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:46 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766740000: 
18/05/31 14:46:46 INFO InputInfoTracker: remove old batch metadata: 
18/05/31 14:46:46 INFO Executor: Finished task 0.0 in stage 131.0 (TID 86). 1708 bytes result sent to driver
18/05/31 14:46:46 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 86) in 6 ms on localhost (executor driver) (1/1)
18/05/31 14:46:46 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
18/05/31 14:46:46 INFO DAGScheduler: ShuffleMapStage 131 (mapToPair at AnomalyDetector.java:64) finished in 0.006 s
18/05/31 14:46:46 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:46 INFO DAGScheduler: running: Set()
18/05/31 14:46:46 INFO DAGScheduler: waiting: Set(ResultStage 134)
18/05/31 14:46:46 INFO DAGScheduler: failed: Set()
18/05/31 14:46:46 INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[90] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:46 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 9.4 KB, free 354.7 MB)
18/05/31 14:46:46 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:46:46 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.66.169.34:53539 (size: 4.6 KB, free: 354.7 MB)
18/05/31 14:46:46 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 134 (MapPartitionsRDD[90] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:46 INFO TaskSchedulerImpl: Adding task set 134.0 with 4 tasks
18/05/31 14:46:46 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:46:46 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 88, localhost, executor driver, partition 1, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:46:46 INFO TaskSetManager: Starting task 2.0 in stage 134.0 (TID 89, localhost, executor driver, partition 2, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:46:46 INFO TaskSetManager: Starting task 3.0 in stage 134.0 (TID 90, localhost, executor driver, partition 3, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:46:46 INFO Executor: Running task 3.0 in stage 134.0 (TID 90)
18/05/31 14:46:46 INFO Executor: Running task 1.0 in stage 134.0 (TID 88)
18/05/31 14:46:46 INFO Executor: Running task 2.0 in stage 134.0 (TID 89)
18/05/31 14:46:46 INFO Executor: Running task 0.0 in stage 134.0 (TID 87)
18/05/31 14:46:46 INFO BlockManager: Found block rdd_84_3 locally
18/05/31 14:46:46 INFO BlockManager: Found block rdd_84_1 locally
18/05/31 14:46:46 INFO BlockManager: Found block rdd_84_2 locally
18/05/31 14:46:46 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:46 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:46 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:46:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:46 INFO MemoryStore: Block rdd_89_1 stored as values in memory (estimated size 14.7 KB, free 354.6 MB)
18/05/31 14:46:46 INFO MemoryStore: Block rdd_89_3 stored as values in memory (estimated size 14.7 KB, free 354.6 MB)
18/05/31 14:46:46 INFO BlockManagerInfo: Added rdd_89_1 in memory on 10.66.169.34:53539 (size: 14.7 KB, free: 354.7 MB)
18/05/31 14:46:46 INFO BlockManagerInfo: Added rdd_89_3 in memory on 10.66.169.34:53539 (size: 14.7 KB, free: 354.7 MB)
18/05/31 14:46:46 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:46 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:46 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-65
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:46 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-66
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:46 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:46 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:46 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:46 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:46 WARN Executor: 1 block locks were not released by TID = 90:
[rdd_84_3]
18/05/31 14:46:46 WARN Executor: 1 block locks were not released by TID = 88:
[rdd_84_1]
18/05/31 14:46:46 INFO Executor: Finished task 1.0 in stage 134.0 (TID 88). 2359 bytes result sent to driver
18/05/31 14:46:46 INFO Executor: Finished task 3.0 in stage 134.0 (TID 90). 2359 bytes result sent to driver
18/05/31 14:46:46 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 88) in 8 ms on localhost (executor driver) (1/4)
18/05/31 14:46:46 INFO TaskSetManager: Finished task 3.0 in stage 134.0 (TID 90) in 7 ms on localhost (executor driver) (2/4)
18/05/31 14:46:46 INFO BlockManager: Found block rdd_84_0 locally
18/05/31 14:46:46 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:46 INFO MemoryStore: Block rdd_89_0 stored as values in memory (estimated size 14.7 KB, free 354.6 MB)
18/05/31 14:46:46 INFO BlockManagerInfo: Added rdd_89_0 in memory on 10.66.169.34:53539 (size: 14.7 KB, free: 354.6 MB)
18/05/31 14:46:46 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:46 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-67
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:46 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:46 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:46 WARN Executor: 1 block locks were not released by TID = 87:
[rdd_84_0]
18/05/31 14:46:46 INFO Executor: Finished task 0.0 in stage 134.0 (TID 87). 2359 bytes result sent to driver
18/05/31 14:46:46 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 87) in 15 ms on localhost (executor driver) (3/4)
18/05/31 14:46:47 INFO MemoryStore: 3 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:46:47 INFO BlockManager: Dropping block rdd_82_0 from memory
18/05/31 14:46:47 INFO BlockManagerInfo: Removed rdd_82_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.6 MB)
18/05/31 14:46:47 INFO BlockManager: Dropping block broadcast_40_piece0 from memory
18/05/31 14:46:47 INFO BlockManager: Writing block broadcast_40_piece0 to disk
18/05/31 14:46:47 INFO BlockManagerInfo: Added broadcast_40_piece0 on disk on 10.66.169.34:53539 (size: 4.5 KB)
18/05/31 14:46:47 INFO BlockManager: Dropping block rdd_79_2 from memory
18/05/31 14:46:47 INFO BlockManagerInfo: Removed rdd_79_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:46:47 INFO MemoryStore: After dropping 3 blocks, free memory is 633.4 MB
18/05/31 14:46:47 INFO MemoryStore: Block rdd_89_2 stored as values in memory (estimated size 278.8 MB, free 354.6 MB)
18/05/31 14:46:47 INFO BlockManagerInfo: Added rdd_89_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.6 MB)
18/05/31 14:46:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-68
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:47 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:47 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:47 WARN Executor: 1 block locks were not released by TID = 89:
[rdd_84_2]
18/05/31 14:46:47 INFO Executor: Finished task 2.0 in stage 134.0 (TID 89). 2616 bytes result sent to driver
18/05/31 14:46:47 INFO TaskSetManager: Finished task 2.0 in stage 134.0 (TID 89) in 1565 ms on localhost (executor driver) (4/4)
18/05/31 14:46:47 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
18/05/31 14:46:47 INFO DAGScheduler: ResultStage 134 (foreachPartition at AnomalyDetector.java:69) finished in 1.567 s
18/05/31 14:46:47 INFO DAGScheduler: Job 19 finished: foreachPartition at AnomalyDetector.java:69, took 1.591621 s
18/05/31 14:46:47 INFO JobScheduler: Finished job streaming job 1527766950000 ms.0 from job set of time 1527766950000 ms
18/05/31 14:46:47 INFO JobScheduler: Total delay: 257.856 s for time 1527766950000 ms (execution: 1.595 s)
18/05/31 14:46:47 INFO JobScheduler: Starting job streaming job 1527766960000 ms.0 from job set of time 1527766960000 ms
18/05/31 14:46:47 INFO MapPartitionsRDD: Removing RDD 85 from persistence list
18/05/31 14:46:47 INFO BlockManager: Removing RDD 85
18/05/31 14:46:47 INFO JobGenerator: Checkpointing graph for time 1527766950000 ms
18/05/31 14:46:47 INFO DStreamGraph: Updating checkpoint data for time 1527766950000 ms
18/05/31 14:46:47 INFO DStreamGraph: Updated checkpoint data for time 1527766950000 ms
18/05/31 14:46:47 INFO CheckpointWriter: Submitted checkpoint of time 1527766950000 ms to writer queue
18/05/31 14:46:47 INFO CheckpointWriter: Saving checkpoint for time 1527766950000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000'
18/05/31 14:46:47 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 149 bytes
18/05/31 14:46:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 149 bytes
18/05/31 14:46:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 149 bytes
18/05/31 14:46:47 INFO DAGScheduler: Registering RDD 92 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 149 bytes
18/05/31 14:46:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 149 bytes
18/05/31 14:46:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 149 bytes
18/05/31 14:46:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 149 bytes
18/05/31 14:46:47 INFO DAGScheduler: Got job 20 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:47 INFO DAGScheduler: Final stage: ResultStage 143 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 135, ShuffleMapStage 139, ShuffleMapStage 136, ShuffleMapStage 140, ShuffleMapStage 137, ShuffleMapStage 141, ShuffleMapStage 138, ShuffleMapStage 142)
18/05/31 14:46:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 138)
18/05/31 14:46:47 INFO DAGScheduler: Submitting ShuffleMapStage 138 (MapPartitionsRDD[92] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:47 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 5.9 KB, free 354.6 MB)
18/05/31 14:46:47 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.6 MB)
18/05/31 14:46:47 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.6 MB)
18/05/31 14:46:47 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 138 (MapPartitionsRDD[92] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:47 INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks
18/05/31 14:46:47 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:47 INFO Executor: Running task 0.0 in stage 138.0 (TID 91)
18/05/31 14:46:47 INFO CheckpointWriter: Checkpoint for time 1527766950000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000', took 6306 bytes and 22 ms
18/05/31 14:46:47 INFO DStreamGraph: Clearing checkpoint data for time 1527766950000 ms
18/05/31 14:46:47 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:47 INFO DStreamGraph: Cleared checkpoint data for time 1527766950000 ms
18/05/31 14:46:47 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:47 INFO MemoryStore: Block rdd_92_0 stored as bytes in memory (estimated size 4.0 B, free 354.6 MB)
18/05/31 14:46:47 INFO BlockManagerInfo: Added rdd_92_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.6 MB)
18/05/31 14:46:47 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766750000: 
18/05/31 14:46:47 INFO InputInfoTracker: remove old batch metadata: 
18/05/31 14:46:47 INFO Executor: Finished task 0.0 in stage 138.0 (TID 91). 1708 bytes result sent to driver
18/05/31 14:46:47 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 91) in 8 ms on localhost (executor driver) (1/1)
18/05/31 14:46:47 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
18/05/31 14:46:47 INFO DAGScheduler: ShuffleMapStage 138 (mapToPair at AnomalyDetector.java:64) finished in 0.009 s
18/05/31 14:46:47 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:47 INFO DAGScheduler: running: Set()
18/05/31 14:46:47 INFO DAGScheduler: waiting: Set(ResultStage 143)
18/05/31 14:46:47 INFO DAGScheduler: failed: Set()
18/05/31 14:46:47 INFO DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[95] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:47 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 9.7 KB, free 354.6 MB)
18/05/31 14:46:47 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 4.6 KB, free 354.6 MB)
18/05/31 14:46:47 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.66.169.34:53539 (size: 4.6 KB, free: 354.6 MB)
18/05/31 14:46:47 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:47 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 143 (MapPartitionsRDD[95] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:47 INFO TaskSchedulerImpl: Adding task set 143.0 with 4 tasks
18/05/31 14:46:47 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:46:47 INFO TaskSetManager: Starting task 1.0 in stage 143.0 (TID 93, localhost, executor driver, partition 1, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:46:47 INFO TaskSetManager: Starting task 2.0 in stage 143.0 (TID 94, localhost, executor driver, partition 2, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:46:47 INFO TaskSetManager: Starting task 3.0 in stage 143.0 (TID 95, localhost, executor driver, partition 3, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:46:47 INFO Executor: Running task 0.0 in stage 143.0 (TID 92)
18/05/31 14:46:47 INFO Executor: Running task 1.0 in stage 143.0 (TID 93)
18/05/31 14:46:47 INFO Executor: Running task 2.0 in stage 143.0 (TID 94)
18/05/31 14:46:47 INFO Executor: Running task 3.0 in stage 143.0 (TID 95)
18/05/31 14:46:47 INFO BlockManager: Found block rdd_89_2 locally
18/05/31 14:46:47 INFO BlockManager: Found block rdd_89_0 locally
18/05/31 14:46:47 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:47 INFO BlockManager: Found block rdd_89_1 locally
18/05/31 14:46:47 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:47 INFO MemoryStore: Block rdd_94_1 stored as values in memory (estimated size 15.5 KB, free 354.6 MB)
18/05/31 14:46:47 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/05/31 14:46:47 INFO MemoryStore: Block rdd_94_0 stored as values in memory (estimated size 15.5 KB, free 354.6 MB)
18/05/31 14:46:47 INFO BlockManagerInfo: Added rdd_94_1 in memory on 10.66.169.34:53539 (size: 15.5 KB, free: 354.6 MB)
18/05/31 14:46:47 INFO BlockManagerInfo: Added rdd_94_0 in memory on 10.66.169.34:53539 (size: 15.5 KB, free: 354.6 MB)
18/05/31 14:46:47 INFO BlockManager: Found block rdd_89_3 locally
18/05/31 14:46:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:47 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:47 INFO MemoryStore: Block rdd_94_3 stored as values in memory (estimated size 15.5 KB, free 354.6 MB)
18/05/31 14:46:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:47 INFO BlockManagerInfo: Added rdd_94_3 in memory on 10.66.169.34:53539 (size: 15.5 KB, free: 354.6 MB)
18/05/31 14:46:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-69
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:47 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:47 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:47 WARN Executor: 1 block locks were not released by TID = 93:
[rdd_89_1]
18/05/31 14:46:47 INFO Executor: Finished task 1.0 in stage 143.0 (TID 93). 2359 bytes result sent to driver
18/05/31 14:46:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-71
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:47 INFO TaskSetManager: Finished task 1.0 in stage 143.0 (TID 93) in 19 ms on localhost (executor driver) (1/4)
18/05/31 14:46:47 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:47 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:47 WARN Executor: 1 block locks were not released by TID = 95:
[rdd_89_3]
18/05/31 14:46:47 INFO Executor: Finished task 3.0 in stage 143.0 (TID 95). 2359 bytes result sent to driver
18/05/31 14:46:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-70
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:47 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:47 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:47 WARN Executor: 1 block locks were not released by TID = 92:
[rdd_89_0]
18/05/31 14:46:47 INFO Executor: Finished task 0.0 in stage 143.0 (TID 92). 2359 bytes result sent to driver
18/05/31 14:46:47 INFO TaskSetManager: Finished task 3.0 in stage 143.0 (TID 95) in 23 ms on localhost (executor driver) (2/4)
18/05/31 14:46:47 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 92) in 26 ms on localhost (executor driver) (3/4)
18/05/31 14:46:48 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 10.66.169.34:53539 on disk (size: 4.5 KB)
18/05/31 14:46:48 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:46:48 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 10.66.169.34:53539 in memory (size: 4.6 KB, free: 354.6 MB)
18/05/31 14:46:48 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 354.6 MB)
18/05/31 14:46:48 INFO MemoryStore: 6 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:46:48 INFO BlockManager: Dropping block rdd_79_3 from memory
18/05/31 14:46:48 INFO BlockManagerInfo: Removed rdd_79_3 on 10.66.169.34:53539 in memory (size: 13.2 KB, free: 354.6 MB)
18/05/31 14:46:48 INFO BlockManager: Dropping block rdd_79_1 from memory
18/05/31 14:46:48 INFO BlockManagerInfo: Removed rdd_79_1 on 10.66.169.34:53539 in memory (size: 13.2 KB, free: 354.6 MB)
18/05/31 14:46:48 INFO BlockManager: Dropping block rdd_79_0 from memory
18/05/31 14:46:48 INFO BlockManagerInfo: Removed rdd_79_0 on 10.66.169.34:53539 in memory (size: 13.2 KB, free: 354.6 MB)
18/05/31 14:46:48 INFO BlockManager: Dropping block rdd_87_0 from memory
18/05/31 14:46:48 INFO BlockManagerInfo: Removed rdd_87_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.6 MB)
18/05/31 14:46:48 INFO BlockManager: Dropping block rdd_84_3 from memory
18/05/31 14:46:48 INFO BlockManagerInfo: Removed rdd_84_3 on 10.66.169.34:53539 in memory (size: 13.9 KB, free: 354.7 MB)
18/05/31 14:46:48 INFO BlockManager: Dropping block rdd_84_2 from memory
18/05/31 14:46:48 INFO BlockManagerInfo: Removed rdd_84_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:46:48 INFO MemoryStore: After dropping 6 blocks, free memory is 633.4 MB
18/05/31 14:46:49 INFO MemoryStore: Block rdd_94_2 stored as values in memory (estimated size 278.8 MB, free 354.6 MB)
18/05/31 14:46:49 INFO BlockManagerInfo: Added rdd_94_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:46:49 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:49 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-72
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:49 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:49 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:49 WARN Executor: 1 block locks were not released by TID = 94:
[rdd_89_2]
18/05/31 14:46:49 INFO Executor: Finished task 2.0 in stage 143.0 (TID 94). 2720 bytes result sent to driver
18/05/31 14:46:49 INFO TaskSetManager: Finished task 2.0 in stage 143.0 (TID 94) in 1679 ms on localhost (executor driver) (4/4)
18/05/31 14:46:49 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
18/05/31 14:46:49 INFO DAGScheduler: ResultStage 143 (foreachPartition at AnomalyDetector.java:69) finished in 1.680 s
18/05/31 14:46:49 INFO DAGScheduler: Job 20 finished: foreachPartition at AnomalyDetector.java:69, took 1.712646 s
18/05/31 14:46:49 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 127.1 KB, free 354.5 MB)
18/05/31 14:46:49 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.5 MB)
18/05/31 14:46:49 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:46:49 INFO SparkContext: Created broadcast 45 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:49 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:49 INFO DAGScheduler: Got job 21 (foreachPartition at AnomalyDetector.java:69) with 1 output partitions
18/05/31 14:46:49 INFO DAGScheduler: Final stage: ResultStage 144 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:49 INFO DAGScheduler: Parents of final stage: List()
18/05/31 14:46:49 INFO DAGScheduler: Missing parents: List()
18/05/31 14:46:49 INFO DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[92] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:49 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 6.1 KB, free 354.5 MB)
18/05/31 14:46:49 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.5 MB)
18/05/31 14:46:49 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.6 MB)
18/05/31 14:46:49 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[92] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:49 INFO TaskSchedulerImpl: Adding task set 144.0 with 1 tasks
18/05/31 14:46:49 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 6166 bytes)
18/05/31 14:46:49 INFO Executor: Running task 0.0 in stage 144.0 (TID 96)
18/05/31 14:46:49 INFO BlockManager: Found block rdd_92_0 locally
18/05/31 14:46:49 INFO Executor: Finished task 0.0 in stage 144.0 (TID 96). 1004 bytes result sent to driver
18/05/31 14:46:49 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 96) in 12 ms on localhost (executor driver) (1/1)
18/05/31 14:46:49 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
18/05/31 14:46:49 INFO DAGScheduler: ResultStage 144 (foreachPartition at AnomalyDetector.java:69) finished in 0.012 s
18/05/31 14:46:49 INFO DAGScheduler: Job 21 finished: foreachPartition at AnomalyDetector.java:69, took 0.015380 s
18/05/31 14:46:49 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 127.1 KB, free 354.4 MB)
18/05/31 14:46:49 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.4 MB)
18/05/31 14:46:49 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:46:49 INFO SparkContext: Created broadcast 47 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:49 INFO ReliableRDDCheckpointData: Done checkpointing RDD 92 to file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-92, new parent is RDD 219
18/05/31 14:46:49 INFO JobScheduler: Finished job streaming job 1527766960000 ms.0 from job set of time 1527766960000 ms
18/05/31 14:46:49 INFO JobScheduler: Total delay: 249.613 s for time 1527766960000 ms (execution: 1.757 s)
18/05/31 14:46:49 INFO JobScheduler: Starting job streaming job 1527766970000 ms.0 from job set of time 1527766970000 ms
18/05/31 14:46:49 INFO MapPartitionsRDD: Removing RDD 90 from persistence list
18/05/31 14:46:49 INFO BlockManager: Removing RDD 90
18/05/31 14:46:49 INFO JobGenerator: Checkpointing graph for time 1527766960000 ms
18/05/31 14:46:49 INFO DStreamGraph: Updating checkpoint data for time 1527766960000 ms
18/05/31 14:46:49 INFO DStreamGraph: Updated checkpoint data for time 1527766960000 ms
18/05/31 14:46:49 INFO CheckpointWriter: Submitted checkpoint of time 1527766960000 ms to writer queue
18/05/31 14:46:49 INFO CheckpointWriter: Saving checkpoint for time 1527766960000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000'
18/05/31 14:46:49 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 149 bytes
18/05/31 14:46:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 149 bytes
18/05/31 14:46:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 149 bytes
18/05/31 14:46:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 149 bytes
18/05/31 14:46:49 INFO DAGScheduler: Registering RDD 97 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 149 bytes
18/05/31 14:46:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 149 bytes
18/05/31 14:46:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 149 bytes
18/05/31 14:46:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 149 bytes
18/05/31 14:46:49 INFO DAGScheduler: Got job 22 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:49 INFO DAGScheduler: Final stage: ResultStage 154 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 153, ShuffleMapStage 150, ShuffleMapStage 147, ShuffleMapStage 151, ShuffleMapStage 152, ShuffleMapStage 148, ShuffleMapStage 145, ShuffleMapStage 149, ShuffleMapStage 146)
18/05/31 14:46:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 149)
18/05/31 14:46:49 INFO DAGScheduler: Submitting ShuffleMapStage 149 (MapPartitionsRDD[97] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:49 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 4.6 KB, free 354.4 MB)
18/05/31 14:46:49 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.3 MB)
18/05/31 14:46:49 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:46:49 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:49 INFO CheckpointWriter: Checkpoint for time 1527766960000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000', took 6325 bytes and 15 ms
18/05/31 14:46:49 INFO DStreamGraph: Clearing checkpoint data for time 1527766960000 ms
18/05/31 14:46:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 149 (MapPartitionsRDD[97] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:49 INFO DStreamGraph: Cleared checkpoint data for time 1527766960000 ms
18/05/31 14:46:49 INFO TaskSchedulerImpl: Adding task set 149.0 with 1 tasks
18/05/31 14:46:49 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:49 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766760000: 
18/05/31 14:46:49 INFO InputInfoTracker: remove old batch metadata: 
18/05/31 14:46:49 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:49 INFO Executor: Running task 0.0 in stage 149.0 (TID 97)
18/05/31 14:46:49 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:49 INFO MemoryStore: Block rdd_97_0 stored as bytes in memory (estimated size 4.0 B, free 354.3 MB)
18/05/31 14:46:49 INFO BlockManagerInfo: Added rdd_97_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.6 MB)
18/05/31 14:46:49 INFO Executor: Finished task 0.0 in stage 149.0 (TID 97). 1708 bytes result sent to driver
18/05/31 14:46:49 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 97) in 4 ms on localhost (executor driver) (1/1)
18/05/31 14:46:49 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
18/05/31 14:46:49 INFO DAGScheduler: ShuffleMapStage 149 (mapToPair at AnomalyDetector.java:64) finished in 0.005 s
18/05/31 14:46:49 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:49 INFO DAGScheduler: running: Set()
18/05/31 14:46:49 INFO DAGScheduler: waiting: Set(ResultStage 154)
18/05/31 14:46:49 INFO DAGScheduler: failed: Set()
18/05/31 14:46:49 INFO DAGScheduler: Submitting ResultStage 154 (MapPartitionsRDD[100] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:49 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 10.0 KB, free 354.3 MB)
18/05/31 14:46:49 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 4.7 KB, free 354.3 MB)
18/05/31 14:46:49 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.66.169.34:53539 (size: 4.7 KB, free: 354.6 MB)
18/05/31 14:46:49 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:49 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 154 (MapPartitionsRDD[100] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:49 INFO TaskSchedulerImpl: Adding task set 154.0 with 4 tasks
18/05/31 14:46:49 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:46:49 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 99, localhost, executor driver, partition 1, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:46:49 INFO TaskSetManager: Starting task 2.0 in stage 154.0 (TID 100, localhost, executor driver, partition 2, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:46:49 INFO TaskSetManager: Starting task 3.0 in stage 154.0 (TID 101, localhost, executor driver, partition 3, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:46:49 INFO Executor: Running task 1.0 in stage 154.0 (TID 99)
18/05/31 14:46:49 INFO Executor: Running task 2.0 in stage 154.0 (TID 100)
18/05/31 14:46:49 INFO Executor: Running task 3.0 in stage 154.0 (TID 101)
18/05/31 14:46:49 INFO BlockManager: Found block rdd_94_3 locally
18/05/31 14:46:49 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:49 INFO MemoryStore: Block rdd_99_3 stored as values in memory (estimated size 16.2 KB, free 354.3 MB)
18/05/31 14:46:49 INFO BlockManagerInfo: Added rdd_99_3 in memory on 10.66.169.34:53539 (size: 16.2 KB, free: 354.6 MB)
18/05/31 14:46:49 INFO BlockManager: Found block rdd_94_1 locally
18/05/31 14:46:49 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:49 INFO MemoryStore: Block rdd_99_1 stored as values in memory (estimated size 16.2 KB, free 354.3 MB)
18/05/31 14:46:49 INFO BlockManagerInfo: Added rdd_99_1 in memory on 10.66.169.34:53539 (size: 16.2 KB, free: 354.6 MB)
18/05/31 14:46:49 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:49 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:49 INFO BlockManager: Found block rdd_94_2 locally
18/05/31 14:46:49 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:49 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-73
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:49 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:49 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:49 WARN Executor: 1 block locks were not released by TID = 99:
[rdd_94_1]
18/05/31 14:46:49 INFO Executor: Finished task 1.0 in stage 154.0 (TID 99). 2359 bytes result sent to driver
18/05/31 14:46:49 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-74
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:49 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:49 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:49 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 99) in 12 ms on localhost (executor driver) (1/4)
18/05/31 14:46:49 WARN Executor: 1 block locks were not released by TID = 101:
[rdd_94_3]
18/05/31 14:46:49 INFO Executor: Finished task 3.0 in stage 154.0 (TID 101). 2359 bytes result sent to driver
18/05/31 14:46:49 INFO Executor: Running task 0.0 in stage 154.0 (TID 98)
18/05/31 14:46:49 INFO TaskSetManager: Finished task 3.0 in stage 154.0 (TID 101) in 12 ms on localhost (executor driver) (2/4)
18/05/31 14:46:49 INFO BlockManager: Found block rdd_94_0 locally
18/05/31 14:46:49 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:49 INFO MemoryStore: Block rdd_99_0 stored as values in memory (estimated size 16.2 KB, free 354.3 MB)
18/05/31 14:46:49 INFO BlockManagerInfo: Added rdd_99_0 in memory on 10.66.169.34:53539 (size: 16.2 KB, free: 354.6 MB)
18/05/31 14:46:49 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:49 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-75
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:49 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:49 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:49 WARN Executor: 1 block locks were not released by TID = 98:
[rdd_94_0]
18/05/31 14:46:49 INFO Executor: Finished task 0.0 in stage 154.0 (TID 98). 2359 bytes result sent to driver
18/05/31 14:46:49 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 98) in 24 ms on localhost (executor driver) (3/4)
18/05/31 14:46:50 INFO JobScheduler: Added jobs for time 1527767210000 ms
18/05/31 14:46:50 INFO JobGenerator: Checkpointing graph for time 1527767210000 ms
18/05/31 14:46:50 INFO DStreamGraph: Updating checkpoint data for time 1527767210000 ms
18/05/31 14:46:50 INFO DStreamGraph: Updated checkpoint data for time 1527767210000 ms
18/05/31 14:46:50 INFO CheckpointWriter: Submitted checkpoint of time 1527767210000 ms to writer queue
18/05/31 14:46:50 INFO CheckpointWriter: Saving checkpoint for time 1527767210000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000'
18/05/31 14:46:50 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767140000
18/05/31 14:46:50 INFO CheckpointWriter: Checkpoint for time 1527767210000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000', took 6319 bytes and 10 ms
18/05/31 14:46:50 INFO MemoryStore: 6 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:46:50 INFO BlockManager: Dropping block rdd_84_1 from memory
18/05/31 14:46:50 INFO BlockManagerInfo: Removed rdd_84_1 on 10.66.169.34:53539 in memory (size: 13.9 KB, free: 354.6 MB)
18/05/31 14:46:50 INFO BlockManager: Dropping block rdd_84_0 from memory
18/05/31 14:46:50 INFO BlockManagerInfo: Removed rdd_84_0 on 10.66.169.34:53539 in memory (size: 13.9 KB, free: 354.6 MB)
18/05/31 14:46:50 INFO BlockManager: Dropping block broadcast_44_piece0 from memory
18/05/31 14:46:50 INFO BlockManager: Writing block broadcast_44_piece0 to disk
18/05/31 14:46:50 INFO BlockManagerInfo: Added broadcast_44_piece0 on disk on 10.66.169.34:53539 (size: 4.6 KB)
18/05/31 14:46:50 INFO BlockManager: Dropping block broadcast_44 from memory
18/05/31 14:46:50 INFO BlockManager: Writing block broadcast_44 to disk
18/05/31 14:46:50 INFO BlockManager: Dropping block rdd_89_0 from memory
18/05/31 14:46:50 INFO BlockManagerInfo: Removed rdd_89_0 on 10.66.169.34:53539 in memory (size: 14.7 KB, free: 354.6 MB)
18/05/31 14:46:50 INFO BlockManager: Dropping block rdd_89_2 from memory
18/05/31 14:46:50 INFO BlockManagerInfo: Removed rdd_89_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:46:50 INFO MemoryStore: After dropping 6 blocks, free memory is 633.1 MB
18/05/31 14:46:51 INFO MemoryStore: Block rdd_99_2 stored as values in memory (estimated size 278.8 MB, free 354.3 MB)
18/05/31 14:46:51 INFO BlockManagerInfo: Added rdd_99_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.6 MB)
18/05/31 14:46:51 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:51 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-76
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:51 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:51 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:51 WARN Executor: 1 block locks were not released by TID = 100:
[rdd_94_2]
18/05/31 14:46:51 INFO Executor: Finished task 2.0 in stage 154.0 (TID 100). 2760 bytes result sent to driver
18/05/31 14:46:51 INFO TaskSetManager: Finished task 2.0 in stage 154.0 (TID 100) in 1618 ms on localhost (executor driver) (4/4)
18/05/31 14:46:51 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
18/05/31 14:46:51 INFO DAGScheduler: ResultStage 154 (foreachPartition at AnomalyDetector.java:69) finished in 1.619 s
18/05/31 14:46:51 INFO DAGScheduler: Job 22 finished: foreachPartition at AnomalyDetector.java:69, took 1.640295 s
18/05/31 14:46:51 INFO JobScheduler: Finished job streaming job 1527766970000 ms.0 from job set of time 1527766970000 ms
18/05/31 14:46:51 INFO JobScheduler: Total delay: 241.259 s for time 1527766970000 ms (execution: 1.646 s)
18/05/31 14:46:51 INFO MapPartitionsRDD: Removing RDD 95 from persistence list
18/05/31 14:46:51 INFO JobScheduler: Starting job streaming job 1527766980000 ms.0 from job set of time 1527766980000 ms
18/05/31 14:46:51 INFO BlockManager: Removing RDD 95
18/05/31 14:46:51 INFO JobGenerator: Checkpointing graph for time 1527766970000 ms
18/05/31 14:46:51 INFO DStreamGraph: Updating checkpoint data for time 1527766970000 ms
18/05/31 14:46:51 INFO DStreamGraph: Updated checkpoint data for time 1527766970000 ms
18/05/31 14:46:51 INFO CheckpointWriter: Submitted checkpoint of time 1527766970000 ms to writer queue
18/05/31 14:46:51 INFO CheckpointWriter: Saving checkpoint for time 1527766970000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000'
18/05/31 14:46:51 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:51 INFO DAGScheduler: Registering RDD 102 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 149 bytes
18/05/31 14:46:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 149 bytes
18/05/31 14:46:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 149 bytes
18/05/31 14:46:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 149 bytes
18/05/31 14:46:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 20 is 149 bytes
18/05/31 14:46:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 149 bytes
18/05/31 14:46:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 149 bytes
18/05/31 14:46:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 149 bytes
18/05/31 14:46:51 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 149 bytes
18/05/31 14:46:51 INFO DAGScheduler: Got job 23 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:51 INFO DAGScheduler: Final stage: ResultStage 165 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 161, ShuffleMapStage 157, ShuffleMapStage 158, ShuffleMapStage 155, ShuffleMapStage 162, ShuffleMapStage 159, ShuffleMapStage 156, ShuffleMapStage 163, ShuffleMapStage 160, ShuffleMapStage 164)
18/05/31 14:46:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 155)
18/05/31 14:46:51 INFO DAGScheduler: Submitting ShuffleMapStage 155 (MapPartitionsRDD[102] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:51 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 4.6 KB, free 354.3 MB)
18/05/31 14:46:51 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.3 MB)
18/05/31 14:46:51 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:46:51 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 155 (MapPartitionsRDD[102] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:51 INFO TaskSchedulerImpl: Adding task set 155.0 with 1 tasks
18/05/31 14:46:51 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:51 INFO Executor: Running task 0.0 in stage 155.0 (TID 102)
18/05/31 14:46:51 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:51 INFO MemoryStore: Block rdd_102_0 stored as bytes in memory (estimated size 4.0 B, free 354.3 MB)
18/05/31 14:46:51 INFO BlockManagerInfo: Added rdd_102_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.6 MB)
18/05/31 14:46:51 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767150000
18/05/31 14:46:51 INFO Executor: Finished task 0.0 in stage 155.0 (TID 102). 1708 bytes result sent to driver
18/05/31 14:46:51 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 102) in 8 ms on localhost (executor driver) (1/1)
18/05/31 14:46:51 INFO CheckpointWriter: Checkpoint for time 1527766970000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000', took 6318 bytes and 21 ms
18/05/31 14:46:51 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
18/05/31 14:46:51 INFO DStreamGraph: Clearing checkpoint data for time 1527766970000 ms
18/05/31 14:46:51 INFO DStreamGraph: Cleared checkpoint data for time 1527766970000 ms
18/05/31 14:46:51 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:51 INFO DAGScheduler: ShuffleMapStage 155 (mapToPair at AnomalyDetector.java:64) finished in 0.008 s
18/05/31 14:46:51 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:51 INFO DAGScheduler: running: Set()
18/05/31 14:46:51 INFO DAGScheduler: waiting: Set(ResultStage 165)
18/05/31 14:46:51 INFO DAGScheduler: failed: Set()
18/05/31 14:46:51 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766770000: 
18/05/31 14:46:51 INFO InputInfoTracker: remove old batch metadata: 
18/05/31 14:46:51 INFO DAGScheduler: Submitting ResultStage 165 (MapPartitionsRDD[105] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:51 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 10.5 KB, free 354.3 MB)
18/05/31 14:46:51 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 4.8 KB, free 354.3 MB)
18/05/31 14:46:51 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.66.169.34:53539 (size: 4.8 KB, free: 354.6 MB)
18/05/31 14:46:51 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:51 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 165 (MapPartitionsRDD[105] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:51 INFO TaskSchedulerImpl: Adding task set 165.0 with 4 tasks
18/05/31 14:46:51 INFO TaskSetManager: Starting task 0.0 in stage 165.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:46:51 INFO TaskSetManager: Starting task 1.0 in stage 165.0 (TID 104, localhost, executor driver, partition 1, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:46:51 INFO TaskSetManager: Starting task 2.0 in stage 165.0 (TID 105, localhost, executor driver, partition 2, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:46:51 INFO TaskSetManager: Starting task 3.0 in stage 165.0 (TID 106, localhost, executor driver, partition 3, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:46:51 INFO Executor: Running task 2.0 in stage 165.0 (TID 105)
18/05/31 14:46:51 INFO Executor: Running task 3.0 in stage 165.0 (TID 106)
18/05/31 14:46:51 INFO Executor: Running task 1.0 in stage 165.0 (TID 104)
18/05/31 14:46:51 INFO BlockManager: Found block rdd_99_2 locally
18/05/31 14:46:51 INFO BlockManager: Found block rdd_99_3 locally
18/05/31 14:46:51 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:51 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:51 INFO BlockManager: Found block rdd_99_1 locally
18/05/31 14:46:51 INFO Executor: Running task 0.0 in stage 165.0 (TID 103)
18/05/31 14:46:51 INFO MemoryStore: Block rdd_104_3 stored as values in memory (estimated size 17.0 KB, free 354.3 MB)
18/05/31 14:46:51 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:51 INFO BlockManagerInfo: Added rdd_104_3 in memory on 10.66.169.34:53539 (size: 17.0 KB, free: 354.6 MB)
18/05/31 14:46:51 INFO MemoryStore: Block rdd_104_1 stored as values in memory (estimated size 17.0 KB, free 354.3 MB)
18/05/31 14:46:51 INFO BlockManagerInfo: Added rdd_104_1 in memory on 10.66.169.34:53539 (size: 17.0 KB, free: 354.6 MB)
18/05/31 14:46:51 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:51 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:51 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 10.66.169.34:53539 on disk (size: 4.6 KB)
18/05/31 14:46:51 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-77
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:51 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:51 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:51 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:46:51 WARN Executor: 1 block locks were not released by TID = 106:
[rdd_99_3]
18/05/31 14:46:51 INFO Executor: Finished task 3.0 in stage 165.0 (TID 106). 2432 bytes result sent to driver
18/05/31 14:46:51 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 10.66.169.34:53539 in memory (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:46:51 INFO TaskSetManager: Finished task 3.0 in stage 165.0 (TID 106) in 66 ms on localhost (executor driver) (1/4)
18/05/31 14:46:51 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 354.6 MB)
18/05/31 14:46:51 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 10.66.169.34:53539 in memory (size: 4.7 KB, free: 354.6 MB)
18/05/31 14:46:51 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:46:51 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-78
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:51 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:51 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:51 WARN Executor: 1 block locks were not released by TID = 104:
[rdd_99_1]
18/05/31 14:46:51 INFO Executor: Finished task 1.0 in stage 165.0 (TID 104). 2432 bytes result sent to driver
18/05/31 14:46:51 INFO TaskSetManager: Finished task 1.0 in stage 165.0 (TID 104) in 71 ms on localhost (executor driver) (2/4)
18/05/31 14:46:51 INFO BlockManager: Found block rdd_99_0 locally
18/05/31 14:46:51 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:51 INFO MemoryStore: Block rdd_104_0 stored as values in memory (estimated size 17.0 KB, free 354.4 MB)
18/05/31 14:46:51 INFO BlockManagerInfo: Added rdd_104_0 in memory on 10.66.169.34:53539 (size: 17.0 KB, free: 354.6 MB)
18/05/31 14:46:51 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:51 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-79
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:51 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:51 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:51 WARN Executor: 1 block locks were not released by TID = 103:
[rdd_99_0]
18/05/31 14:46:51 INFO Executor: Finished task 0.0 in stage 165.0 (TID 103). 2359 bytes result sent to driver
18/05/31 14:46:51 INFO TaskSetManager: Finished task 0.0 in stage 165.0 (TID 103) in 83 ms on localhost (executor driver) (3/4)
18/05/31 14:46:52 INFO MemoryStore: 9 blocks selected for dropping (279.0 MB bytes)
18/05/31 14:46:52 INFO BlockManager: Dropping block rdd_89_1 from memory
18/05/31 14:46:52 INFO BlockManagerInfo: Removed rdd_89_1 on 10.66.169.34:53539 in memory (size: 14.7 KB, free: 354.6 MB)
18/05/31 14:46:52 INFO BlockManager: Dropping block rdd_89_3 from memory
18/05/31 14:46:52 INFO BlockManagerInfo: Removed rdd_89_3 on 10.66.169.34:53539 in memory (size: 14.7 KB, free: 354.6 MB)
18/05/31 14:46:52 INFO BlockManager: Dropping block rdd_92_0 from memory
18/05/31 14:46:52 INFO BlockManagerInfo: Removed rdd_92_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.6 MB)
18/05/31 14:46:52 INFO BlockManager: Dropping block broadcast_47 from memory
18/05/31 14:46:52 INFO BlockManager: Writing block broadcast_47 to disk
18/05/31 14:46:52 INFO BlockManager: Dropping block broadcast_47_piece0 from memory
18/05/31 14:46:52 INFO BlockManager: Writing block broadcast_47_piece0 to disk
18/05/31 14:46:52 INFO BlockManagerInfo: Added broadcast_47_piece0 on disk on 10.66.169.34:53539 (size: 14.3 KB)
18/05/31 14:46:52 INFO BlockManager: Dropping block rdd_97_0 from memory
18/05/31 14:46:52 INFO BlockManagerInfo: Removed rdd_97_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.6 MB)
18/05/31 14:46:52 INFO BlockManager: Dropping block rdd_94_3 from memory
18/05/31 14:46:52 INFO BlockManagerInfo: Removed rdd_94_3 on 10.66.169.34:53539 in memory (size: 15.5 KB, free: 354.6 MB)
18/05/31 14:46:52 INFO BlockManager: Dropping block rdd_94_1 from memory
18/05/31 14:46:52 INFO BlockManagerInfo: Removed rdd_94_1 on 10.66.169.34:53539 in memory (size: 15.5 KB, free: 354.7 MB)
18/05/31 14:46:52 INFO BlockManager: Dropping block rdd_94_2 from memory
18/05/31 14:46:52 INFO BlockManagerInfo: Removed rdd_94_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:46:52 INFO MemoryStore: After dropping 9 blocks, free memory is 633.4 MB
18/05/31 14:46:52 INFO MemoryStore: Block rdd_104_2 stored as values in memory (estimated size 278.8 MB, free 354.6 MB)
18/05/31 14:46:52 INFO BlockManagerInfo: Added rdd_104_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:46:52 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:52 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-80
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:52 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:52 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:52 WARN Executor: 1 block locks were not released by TID = 105:
[rdd_99_2]
18/05/31 14:46:52 INFO Executor: Finished task 2.0 in stage 165.0 (TID 105). 3061 bytes result sent to driver
18/05/31 14:46:52 INFO TaskSetManager: Finished task 2.0 in stage 165.0 (TID 105) in 1703 ms on localhost (executor driver) (4/4)
18/05/31 14:46:52 INFO TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool 
18/05/31 14:46:52 INFO DAGScheduler: ResultStage 165 (foreachPartition at AnomalyDetector.java:69) finished in 1.705 s
18/05/31 14:46:52 INFO DAGScheduler: Job 23 finished: foreachPartition at AnomalyDetector.java:69, took 1.728923 s
18/05/31 14:46:52 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 127.1 KB, free 354.5 MB)
18/05/31 14:46:53 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.5 MB)
18/05/31 14:46:53 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:46:53 INFO SparkContext: Created broadcast 52 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:53 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 149 bytes
18/05/31 14:46:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 149 bytes
18/05/31 14:46:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 149 bytes
18/05/31 14:46:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 149 bytes
18/05/31 14:46:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 149 bytes
18/05/31 14:46:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 20 is 149 bytes
18/05/31 14:46:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 149 bytes
18/05/31 14:46:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 149 bytes
18/05/31 14:46:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 149 bytes
18/05/31 14:46:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 149 bytes
18/05/31 14:46:53 INFO DAGScheduler: Got job 24 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:53 INFO DAGScheduler: Final stage: ResultStage 176 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 171, ShuffleMapStage 168, ShuffleMapStage 172, ShuffleMapStage 169, ShuffleMapStage 166, ShuffleMapStage 173, ShuffleMapStage 170, ShuffleMapStage 174, ShuffleMapStage 175, ShuffleMapStage 167)
18/05/31 14:46:53 INFO DAGScheduler: Missing parents: List()
18/05/31 14:46:53 INFO DAGScheduler: Submitting ResultStage 176 (MapWithStateRDD[104] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:53 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 10.0 KB, free 354.5 MB)
18/05/31 14:46:53 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.5 MB)
18/05/31 14:46:53 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 10.66.169.34:53539 (size: 4.5 KB, free: 354.6 MB)
18/05/31 14:46:53 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 176 (MapWithStateRDD[104] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:53 INFO TaskSchedulerImpl: Adding task set 176.0 with 4 tasks
18/05/31 14:46:53 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:46:53 INFO TaskSetManager: Starting task 1.0 in stage 176.0 (TID 108, localhost, executor driver, partition 1, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:46:53 INFO TaskSetManager: Starting task 2.0 in stage 176.0 (TID 109, localhost, executor driver, partition 2, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:46:53 INFO TaskSetManager: Starting task 3.0 in stage 176.0 (TID 110, localhost, executor driver, partition 3, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:46:53 INFO Executor: Running task 0.0 in stage 176.0 (TID 107)
18/05/31 14:46:53 INFO Executor: Running task 1.0 in stage 176.0 (TID 108)
18/05/31 14:46:53 INFO Executor: Running task 2.0 in stage 176.0 (TID 109)
18/05/31 14:46:53 INFO Executor: Running task 3.0 in stage 176.0 (TID 110)
18/05/31 14:46:53 INFO BlockManager: Found block rdd_104_1 locally
18/05/31 14:46:53 INFO BlockManager: Found block rdd_104_0 locally
18/05/31 14:46:53 INFO BlockManager: Found block rdd_104_3 locally
18/05/31 14:46:53 INFO BlockManager: Found block rdd_104_2 locally
18/05/31 14:46:53 INFO Executor: Finished task 0.0 in stage 176.0 (TID 107). 1085 bytes result sent to driver
18/05/31 14:46:53 INFO Executor: Finished task 1.0 in stage 176.0 (TID 108). 1085 bytes result sent to driver
18/05/31 14:46:53 INFO Executor: Finished task 3.0 in stage 176.0 (TID 110). 1085 bytes result sent to driver
18/05/31 14:46:53 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 107) in 21 ms on localhost (executor driver) (1/4)
18/05/31 14:46:53 INFO TaskSetManager: Finished task 3.0 in stage 176.0 (TID 110) in 21 ms on localhost (executor driver) (2/4)
18/05/31 14:46:53 INFO TaskSetManager: Finished task 1.0 in stage 176.0 (TID 108) in 21 ms on localhost (executor driver) (3/4)
18/05/31 14:46:54 INFO Executor: Finished task 2.0 in stage 176.0 (TID 109). 1085 bytes result sent to driver
18/05/31 14:46:54 INFO TaskSetManager: Finished task 2.0 in stage 176.0 (TID 109) in 1469 ms on localhost (executor driver) (4/4)
18/05/31 14:46:54 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool 
18/05/31 14:46:54 INFO DAGScheduler: ResultStage 176 (foreachPartition at AnomalyDetector.java:69) finished in 1.470 s
18/05/31 14:46:54 INFO DAGScheduler: Job 24 finished: foreachPartition at AnomalyDetector.java:69, took 1.478876 s
18/05/31 14:46:54 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 127.1 KB, free 354.4 MB)
18/05/31 14:46:54 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.4 MB)
18/05/31 14:46:54 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:46:54 INFO SparkContext: Created broadcast 54 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:54 INFO ReliableRDDCheckpointData: Done checkpointing RDD 104 to file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-104, new parent is RDD 225
18/05/31 14:46:54 INFO JobScheduler: Finished job streaming job 1527766980000 ms.0 from job set of time 1527766980000 ms
18/05/31 14:46:54 INFO JobScheduler: Total delay: 234.513 s for time 1527766980000 ms (execution: 3.254 s)
18/05/31 14:46:54 INFO MapPartitionsRDD: Removing RDD 100 from persistence list
18/05/31 14:46:54 INFO JobScheduler: Starting job streaming job 1527766990000 ms.0 from job set of time 1527766990000 ms
18/05/31 14:46:54 INFO BlockManager: Removing RDD 100
18/05/31 14:46:54 INFO JobGenerator: Checkpointing graph for time 1527766980000 ms
18/05/31 14:46:54 INFO DStreamGraph: Updating checkpoint data for time 1527766980000 ms
18/05/31 14:46:54 INFO DStreamGraph: Updated checkpoint data for time 1527766980000 ms
18/05/31 14:46:54 INFO CheckpointWriter: Submitted checkpoint of time 1527766980000 ms to writer queue
18/05/31 14:46:54 INFO CheckpointWriter: Saving checkpoint for time 1527766980000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000'
18/05/31 14:46:54 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:54 INFO DAGScheduler: Registering RDD 107 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:54 INFO DAGScheduler: Got job 25 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:54 INFO DAGScheduler: Final stage: ResultStage 178 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 177)
18/05/31 14:46:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 177)
18/05/31 14:46:54 INFO DAGScheduler: Submitting ShuffleMapStage 177 (MapPartitionsRDD[107] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:54 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 4.6 KB, free 354.3 MB)
18/05/31 14:46:54 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.3 MB)
18/05/31 14:46:54 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:46:54 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 177 (MapPartitionsRDD[107] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:54 INFO TaskSchedulerImpl: Adding task set 177.0 with 1 tasks
18/05/31 14:46:54 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:54 INFO Executor: Running task 0.0 in stage 177.0 (TID 111)
18/05/31 14:46:54 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:54 INFO MemoryStore: Block rdd_107_0 stored as bytes in memory (estimated size 4.0 B, free 354.3 MB)
18/05/31 14:46:54 INFO BlockManagerInfo: Added rdd_107_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.6 MB)
18/05/31 14:46:54 INFO Executor: Finished task 0.0 in stage 177.0 (TID 111). 1708 bytes result sent to driver
18/05/31 14:46:54 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 111) in 6 ms on localhost (executor driver) (1/1)
18/05/31 14:46:54 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool 
18/05/31 14:46:54 INFO DAGScheduler: ShuffleMapStage 177 (mapToPair at AnomalyDetector.java:64) finished in 0.006 s
18/05/31 14:46:54 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:54 INFO DAGScheduler: running: Set()
18/05/31 14:46:54 INFO DAGScheduler: waiting: Set(ResultStage 178)
18/05/31 14:46:54 INFO DAGScheduler: failed: Set()
18/05/31 14:46:54 INFO DAGScheduler: Submitting ResultStage 178 (MapPartitionsRDD[110] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:54 INFO CheckpointWriter: Checkpoint for time 1527766980000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000', took 6323 bytes and 15 ms
18/05/31 14:46:54 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 7.8 KB, free 354.3 MB)
18/05/31 14:46:54 INFO DStreamGraph: Clearing checkpoint data for time 1527766980000 ms
18/05/31 14:46:54 INFO DStreamGraph: Cleared checkpoint data for time 1527766980000 ms
18/05/31 14:46:54 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:54 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766780000: 
18/05/31 14:46:54 INFO InputInfoTracker: remove old batch metadata: 
18/05/31 14:46:54 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 4.2 KB, free 354.3 MB)
18/05/31 14:46:54 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 10.66.169.34:53539 (size: 4.2 KB, free: 354.6 MB)
18/05/31 14:46:54 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:54 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 178 (MapPartitionsRDD[110] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:54 INFO TaskSchedulerImpl: Adding task set 178.0 with 4 tasks
18/05/31 14:46:54 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:46:54 INFO TaskSetManager: Starting task 1.0 in stage 178.0 (TID 113, localhost, executor driver, partition 1, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:46:54 INFO TaskSetManager: Starting task 2.0 in stage 178.0 (TID 114, localhost, executor driver, partition 2, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:46:54 INFO TaskSetManager: Starting task 3.0 in stage 178.0 (TID 115, localhost, executor driver, partition 3, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:46:54 INFO Executor: Running task 1.0 in stage 178.0 (TID 113)
18/05/31 14:46:54 INFO Executor: Running task 3.0 in stage 178.0 (TID 115)
18/05/31 14:46:54 INFO Executor: Running task 2.0 in stage 178.0 (TID 114)
18/05/31 14:46:54 INFO Executor: Running task 0.0 in stage 178.0 (TID 112)
18/05/31 14:46:54 INFO BlockManager: Found block rdd_104_1 locally
18/05/31 14:46:54 INFO BlockManager: Found block rdd_104_2 locally
18/05/31 14:46:54 INFO BlockManager: Found block rdd_104_3 locally
18/05/31 14:46:54 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:54 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:54 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:54 INFO MemoryStore: Block rdd_109_3 stored as values in memory (estimated size 2.5 KB, free 354.3 MB)
18/05/31 14:46:54 INFO MemoryStore: Block rdd_109_1 stored as values in memory (estimated size 2.5 KB, free 354.3 MB)
18/05/31 14:46:54 INFO BlockManagerInfo: Added rdd_109_3 in memory on 10.66.169.34:53539 (size: 2.5 KB, free: 354.6 MB)
18/05/31 14:46:54 INFO BlockManagerInfo: Added rdd_109_1 in memory on 10.66.169.34:53539 (size: 2.5 KB, free: 354.6 MB)
18/05/31 14:46:54 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:54 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:54 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-81
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:54 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:54 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:54 WARN Executor: 1 block locks were not released by TID = 115:
[rdd_104_3]
18/05/31 14:46:54 INFO Executor: Finished task 3.0 in stage 178.0 (TID 115). 2359 bytes result sent to driver
18/05/31 14:46:54 INFO TaskSetManager: Finished task 3.0 in stage 178.0 (TID 115) in 8 ms on localhost (executor driver) (1/4)
18/05/31 14:46:54 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-82
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:54 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:54 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:54 WARN Executor: 1 block locks were not released by TID = 113:
[rdd_104_1]
18/05/31 14:46:54 INFO Executor: Finished task 1.0 in stage 178.0 (TID 113). 2359 bytes result sent to driver
18/05/31 14:46:54 INFO TaskSetManager: Finished task 1.0 in stage 178.0 (TID 113) in 11 ms on localhost (executor driver) (2/4)
18/05/31 14:46:54 INFO BlockManager: Found block rdd_104_0 locally
18/05/31 14:46:54 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:54 INFO MemoryStore: Block rdd_109_0 stored as values in memory (estimated size 2.5 KB, free 354.3 MB)
18/05/31 14:46:54 INFO BlockManagerInfo: Added rdd_109_0 in memory on 10.66.169.34:53539 (size: 2.5 KB, free: 354.6 MB)
18/05/31 14:46:54 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:54 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-83
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:54 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:54 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:54 WARN Executor: 1 block locks were not released by TID = 112:
[rdd_104_0]
18/05/31 14:46:54 INFO Executor: Finished task 0.0 in stage 178.0 (TID 112). 2359 bytes result sent to driver
18/05/31 14:46:54 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 112) in 22 ms on localhost (executor driver) (3/4)
18/05/31 14:46:55 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 10.66.169.34:53539 in memory (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:46:55 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 10.66.169.34:53539 in memory (size: 4.8 KB, free: 354.6 MB)
18/05/31 14:46:55 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 10.66.169.34:53539 in memory (size: 4.5 KB, free: 354.6 MB)
18/05/31 14:46:55 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:46:55 INFO MemoryStore: 3 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:46:55 INFO BlockManager: Dropping block rdd_94_0 from memory
18/05/31 14:46:55 INFO BlockManagerInfo: Removed rdd_94_0 on 10.66.169.34:53539 in memory (size: 15.5 KB, free: 354.6 MB)
18/05/31 14:46:55 INFO BlockManager: Dropping block rdd_102_0 from memory
18/05/31 14:46:55 INFO BlockManagerInfo: Removed rdd_102_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.6 MB)
18/05/31 14:46:55 INFO BlockManager: Dropping block rdd_99_2 from memory
18/05/31 14:46:55 INFO BlockManagerInfo: Removed rdd_99_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:46:55 INFO MemoryStore: After dropping 3 blocks, free memory is 633.3 MB
18/05/31 14:46:56 INFO MemoryStore: Block rdd_109_2 stored as values in memory (estimated size 278.8 MB, free 354.5 MB)
18/05/31 14:46:56 INFO BlockManagerInfo: Added rdd_109_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:46:56 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:56 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-84
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:56 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:56 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:56 WARN Executor: 1 block locks were not released by TID = 114:
[rdd_104_2]
18/05/31 14:46:56 INFO Executor: Finished task 2.0 in stage 178.0 (TID 114). 2579 bytes result sent to driver
18/05/31 14:46:56 INFO TaskSetManager: Finished task 2.0 in stage 178.0 (TID 114) in 1607 ms on localhost (executor driver) (4/4)
18/05/31 14:46:56 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool 
18/05/31 14:46:56 INFO DAGScheduler: ResultStage 178 (foreachPartition at AnomalyDetector.java:69) finished in 1.608 s
18/05/31 14:46:56 INFO DAGScheduler: Job 25 finished: foreachPartition at AnomalyDetector.java:69, took 1.623130 s
18/05/31 14:46:56 INFO JobScheduler: Finished job streaming job 1527766990000 ms.0 from job set of time 1527766990000 ms
18/05/31 14:46:56 INFO JobScheduler: Total delay: 226.141 s for time 1527766990000 ms (execution: 1.628 s)
18/05/31 14:46:56 INFO MapPartitionsRDD: Removing RDD 105 from persistence list
18/05/31 14:46:56 INFO JobScheduler: Starting job streaming job 1527767000000 ms.0 from job set of time 1527767000000 ms
18/05/31 14:46:56 INFO BlockManager: Removing RDD 105
18/05/31 14:46:56 INFO MapWithStateRDD: Removing RDD 9 from persistence list
18/05/31 14:46:56 INFO BlockManager: Removing RDD 9
18/05/31 14:46:56 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 149 bytes
18/05/31 14:46:56 INFO DAGScheduler: Registering RDD 112 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:56 INFO DAGScheduler: Got job 26 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:56 INFO DAGScheduler: Final stage: ResultStage 181 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 179, ShuffleMapStage 180)
18/05/31 14:46:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 180)
18/05/31 14:46:56 INFO DAGScheduler: Submitting ShuffleMapStage 180 (MapPartitionsRDD[112] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:56 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 4.6 KB, free 354.5 MB)
18/05/31 14:46:56 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.5 MB)
18/05/31 14:46:56 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:46:56 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 180 (MapPartitionsRDD[112] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:56 INFO TaskSchedulerImpl: Adding task set 180.0 with 1 tasks
18/05/31 14:46:56 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:56 INFO Executor: Running task 0.0 in stage 180.0 (TID 116)
18/05/31 14:46:56 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:56 INFO MapPartitionsRDD: Removing RDD 7 from persistence list
18/05/31 14:46:56 INFO MemoryStore: Block rdd_112_0 stored as bytes in memory (estimated size 4.0 B, free 354.5 MB)
18/05/31 14:46:56 INFO BlockManager: Removing RDD 7
18/05/31 14:46:56 INFO BlockManagerInfo: Added rdd_112_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:56 INFO KafkaRDD: Removing RDD 6 from persistence list
18/05/31 14:46:56 INFO BlockManager: Removing RDD 6
18/05/31 14:46:56 INFO JobGenerator: Checkpointing graph for time 1527766990000 ms
18/05/31 14:46:56 INFO DStreamGraph: Updating checkpoint data for time 1527766990000 ms
18/05/31 14:46:56 INFO DStreamGraph: Updated checkpoint data for time 1527766990000 ms
18/05/31 14:46:56 INFO Executor: Finished task 0.0 in stage 180.0 (TID 116). 1708 bytes result sent to driver
18/05/31 14:46:56 INFO CheckpointWriter: Submitted checkpoint of time 1527766990000 ms to writer queue
18/05/31 14:46:56 INFO CheckpointWriter: Saving checkpoint for time 1527766990000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000'
18/05/31 14:46:56 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 116) in 7 ms on localhost (executor driver) (1/1)
18/05/31 14:46:56 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool 
18/05/31 14:46:56 INFO DAGScheduler: ShuffleMapStage 180 (mapToPair at AnomalyDetector.java:64) finished in 0.007 s
18/05/31 14:46:56 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:56 INFO DAGScheduler: running: Set()
18/05/31 14:46:56 INFO DAGScheduler: waiting: Set(ResultStage 181)
18/05/31 14:46:56 INFO DAGScheduler: failed: Set()
18/05/31 14:46:56 INFO DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[115] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:56 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 8.1 KB, free 354.5 MB)
18/05/31 14:46:56 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 4.3 KB, free 354.5 MB)
18/05/31 14:46:56 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 10.66.169.34:53539 (size: 4.3 KB, free: 354.7 MB)
18/05/31 14:46:56 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:56 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 181 (MapPartitionsRDD[115] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:56 INFO TaskSchedulerImpl: Adding task set 181.0 with 4 tasks
18/05/31 14:46:56 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:46:56 INFO TaskSetManager: Starting task 1.0 in stage 181.0 (TID 118, localhost, executor driver, partition 1, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:46:56 INFO TaskSetManager: Starting task 2.0 in stage 181.0 (TID 119, localhost, executor driver, partition 2, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:46:56 INFO TaskSetManager: Starting task 3.0 in stage 181.0 (TID 120, localhost, executor driver, partition 3, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:46:56 INFO Executor: Running task 0.0 in stage 181.0 (TID 117)
18/05/31 14:46:56 INFO Executor: Running task 1.0 in stage 181.0 (TID 118)
18/05/31 14:46:56 INFO Executor: Running task 2.0 in stage 181.0 (TID 119)
18/05/31 14:46:56 INFO Executor: Running task 3.0 in stage 181.0 (TID 120)
18/05/31 14:46:56 INFO BlockManager: Found block rdd_109_2 locally
18/05/31 14:46:56 INFO BlockManager: Found block rdd_109_1 locally
18/05/31 14:46:56 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:56 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:56 INFO BlockManager: Found block rdd_109_3 locally
18/05/31 14:46:56 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:56 INFO MemoryStore: Block rdd_114_1 stored as values in memory (estimated size 3.2 KB, free 354.5 MB)
18/05/31 14:46:56 INFO BlockManager: Found block rdd_109_0 locally
18/05/31 14:46:56 INFO MemoryStore: Block rdd_114_3 stored as values in memory (estimated size 3.2 KB, free 354.5 MB)
18/05/31 14:46:56 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:46:56 INFO BlockManagerInfo: Added rdd_114_1 in memory on 10.66.169.34:53539 (size: 3.2 KB, free: 354.7 MB)
18/05/31 14:46:56 INFO MemoryStore: Block rdd_114_0 stored as values in memory (estimated size 3.2 KB, free 354.5 MB)
18/05/31 14:46:56 INFO BlockManagerInfo: Added rdd_114_3 in memory on 10.66.169.34:53539 (size: 3.2 KB, free: 354.6 MB)
18/05/31 14:46:56 INFO BlockManagerInfo: Added rdd_114_0 in memory on 10.66.169.34:53539 (size: 3.2 KB, free: 354.6 MB)
18/05/31 14:46:56 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:56 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:56 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:56 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-87
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:56 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:56 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:56 WARN Executor: 1 block locks were not released by TID = 117:
[rdd_109_0]
18/05/31 14:46:56 INFO Executor: Finished task 0.0 in stage 181.0 (TID 117). 2359 bytes result sent to driver
18/05/31 14:46:56 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-86
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:56 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:56 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:56 WARN Executor: 1 block locks were not released by TID = 120:
[rdd_109_3]
18/05/31 14:46:56 INFO Executor: Finished task 3.0 in stage 181.0 (TID 120). 2359 bytes result sent to driver
18/05/31 14:46:56 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 117) in 13 ms on localhost (executor driver) (1/4)
18/05/31 14:46:56 INFO TaskSetManager: Finished task 3.0 in stage 181.0 (TID 120) in 14 ms on localhost (executor driver) (2/4)
18/05/31 14:46:56 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-85
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:56 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:56 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:56 WARN Executor: 1 block locks were not released by TID = 118:
[rdd_109_1]
18/05/31 14:46:56 INFO Executor: Finished task 1.0 in stage 181.0 (TID 118). 2359 bytes result sent to driver
18/05/31 14:46:56 INFO CheckpointWriter: Checkpoint for time 1527766990000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000', took 6306 bytes and 27 ms
18/05/31 14:46:56 INFO DStreamGraph: Clearing checkpoint data for time 1527766990000 ms
18/05/31 14:46:56 INFO DStreamGraph: Cleared checkpoint data for time 1527766990000 ms
18/05/31 14:46:56 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:56 INFO TaskSetManager: Finished task 1.0 in stage 181.0 (TID 118) in 23 ms on localhost (executor driver) (3/4)
18/05/31 14:46:56 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766790000: 
18/05/31 14:46:56 INFO InputInfoTracker: remove old batch metadata: 
18/05/31 14:46:56 INFO MemoryStore: 9 blocks selected for dropping (279.0 MB bytes)
18/05/31 14:46:56 INFO BlockManager: Dropping block rdd_99_3 from memory
18/05/31 14:46:56 INFO BlockManagerInfo: Removed rdd_99_3 on 10.66.169.34:53539 in memory (size: 16.2 KB, free: 354.7 MB)
18/05/31 14:46:56 INFO BlockManager: Dropping block rdd_99_1 from memory
18/05/31 14:46:56 INFO BlockManagerInfo: Removed rdd_99_1 on 10.66.169.34:53539 in memory (size: 16.2 KB, free: 354.7 MB)
18/05/31 14:46:56 INFO BlockManager: Dropping block rdd_99_0 from memory
18/05/31 14:46:56 INFO BlockManagerInfo: Removed rdd_99_0 on 10.66.169.34:53539 in memory (size: 16.2 KB, free: 354.7 MB)
18/05/31 14:46:56 INFO BlockManager: Dropping block broadcast_54 from memory
18/05/31 14:46:56 INFO BlockManager: Writing block broadcast_54 to disk
18/05/31 14:46:56 INFO BlockManager: Dropping block broadcast_54_piece0 from memory
18/05/31 14:46:56 INFO BlockManager: Writing block broadcast_54_piece0 to disk
18/05/31 14:46:56 INFO BlockManagerInfo: Added broadcast_54_piece0 on disk on 10.66.169.34:53539 (size: 14.3 KB)
18/05/31 14:46:56 INFO BlockManager: Dropping block rdd_107_0 from memory
18/05/31 14:46:56 INFO BlockManagerInfo: Removed rdd_107_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:56 INFO BlockManager: Dropping block broadcast_56_piece0 from memory
18/05/31 14:46:56 INFO BlockManager: Writing block broadcast_56_piece0 to disk
18/05/31 14:46:56 INFO BlockManagerInfo: Added broadcast_56_piece0 on disk on 10.66.169.34:53539 (size: 4.2 KB)
18/05/31 14:46:56 INFO BlockManager: Dropping block rdd_104_1 from memory
18/05/31 14:46:56 INFO BlockManagerInfo: Removed rdd_104_1 on 10.66.169.34:53539 in memory (size: 17.0 KB, free: 354.7 MB)
18/05/31 14:46:56 INFO BlockManager: Dropping block rdd_104_2 from memory
18/05/31 14:46:56 INFO BlockManagerInfo: Removed rdd_104_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:46:56 INFO MemoryStore: After dropping 9 blocks, free memory is 633.5 MB
18/05/31 14:46:57 INFO MemoryStore: Block rdd_114_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:46:57 INFO BlockManagerInfo: Added rdd_114_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:46:57 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:57 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-88
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:57 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:57 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:57 WARN Executor: 1 block locks were not released by TID = 119:
[rdd_109_2]
18/05/31 14:46:57 INFO Executor: Finished task 2.0 in stage 181.0 (TID 119). 2910 bytes result sent to driver
18/05/31 14:46:57 INFO TaskSetManager: Finished task 2.0 in stage 181.0 (TID 119) in 1673 ms on localhost (executor driver) (4/4)
18/05/31 14:46:57 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool 
18/05/31 14:46:57 INFO DAGScheduler: ResultStage 181 (foreachPartition at AnomalyDetector.java:69) finished in 1.675 s
18/05/31 14:46:57 INFO DAGScheduler: Job 26 finished: foreachPartition at AnomalyDetector.java:69, took 1.690980 s
18/05/31 14:46:57 INFO JobScheduler: Finished job streaming job 1527767000000 ms.0 from job set of time 1527767000000 ms
18/05/31 14:46:57 INFO JobScheduler: Total delay: 217.835 s for time 1527767000000 ms (execution: 1.694 s)
18/05/31 14:46:57 INFO JobScheduler: Starting job streaming job 1527767010000 ms.0 from job set of time 1527767010000 ms
18/05/31 14:46:57 INFO MapPartitionsRDD: Removing RDD 110 from persistence list
18/05/31 14:46:57 INFO MapWithStateRDD: Removing RDD 14 from persistence list
18/05/31 14:46:57 INFO BlockManager: Removing RDD 110
18/05/31 14:46:57 INFO BlockManager: Removing RDD 14
18/05/31 14:46:57 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:57 INFO MapPartitionsRDD: Removing RDD 12 from persistence list
18/05/31 14:46:57 INFO BlockManager: Removing RDD 12
18/05/31 14:46:57 INFO DAGScheduler: Registering RDD 117 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:57 INFO KafkaRDD: Removing RDD 11 from persistence list
18/05/31 14:46:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 149 bytes
18/05/31 14:46:57 INFO BlockManager: Removing RDD 11
18/05/31 14:46:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 149 bytes
18/05/31 14:46:57 INFO JobGenerator: Checkpointing graph for time 1527767000000 ms
18/05/31 14:46:57 INFO DStreamGraph: Updating checkpoint data for time 1527767000000 ms
18/05/31 14:46:57 INFO DStreamGraph: Updated checkpoint data for time 1527767000000 ms
18/05/31 14:46:57 INFO DAGScheduler: Got job 27 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:57 INFO DAGScheduler: Final stage: ResultStage 185 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:57 INFO CheckpointWriter: Submitted checkpoint of time 1527767000000 ms to writer queue
18/05/31 14:46:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 183, ShuffleMapStage 184, ShuffleMapStage 182)
18/05/31 14:46:57 INFO CheckpointWriter: Saving checkpoint for time 1527767000000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000'
18/05/31 14:46:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 182)
18/05/31 14:46:57 INFO DAGScheduler: Submitting ShuffleMapStage 182 (MapPartitionsRDD[117] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:57 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:46:57 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.7 MB)
18/05/31 14:46:57 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:46:57 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 182 (MapPartitionsRDD[117] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:57 INFO TaskSchedulerImpl: Adding task set 182.0 with 1 tasks
18/05/31 14:46:57 INFO TaskSetManager: Starting task 0.0 in stage 182.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:57 INFO Executor: Running task 0.0 in stage 182.0 (TID 121)
18/05/31 14:46:57 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:57 INFO MemoryStore: Block rdd_117_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:46:57 INFO BlockManagerInfo: Added rdd_117_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:46:57 INFO Executor: Finished task 0.0 in stage 182.0 (TID 121). 1708 bytes result sent to driver
18/05/31 14:46:57 INFO TaskSetManager: Finished task 0.0 in stage 182.0 (TID 121) in 8 ms on localhost (executor driver) (1/1)
18/05/31 14:46:57 INFO TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool 
18/05/31 14:46:57 INFO DAGScheduler: ShuffleMapStage 182 (mapToPair at AnomalyDetector.java:64) finished in 0.009 s
18/05/31 14:46:57 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:57 INFO DAGScheduler: running: Set()
18/05/31 14:46:57 INFO DAGScheduler: waiting: Set(ResultStage 185)
18/05/31 14:46:57 INFO DAGScheduler: failed: Set()
18/05/31 14:46:57 INFO DAGScheduler: Submitting ResultStage 185 (MapPartitionsRDD[120] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:57 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 8.4 KB, free 354.7 MB)
18/05/31 14:46:57 INFO CheckpointWriter: Checkpoint for time 1527767000000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000', took 6276 bytes and 17 ms
18/05/31 14:46:57 INFO DStreamGraph: Clearing checkpoint data for time 1527767000000 ms
18/05/31 14:46:57 INFO DStreamGraph: Cleared checkpoint data for time 1527767000000 ms
18/05/31 14:46:57 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:57 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 4.3 KB, free 354.7 MB)
18/05/31 14:46:57 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766800000: 
18/05/31 14:46:57 INFO InputInfoTracker: remove old batch metadata: 1527766790000 ms
18/05/31 14:46:57 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 10.66.169.34:53539 (size: 4.3 KB, free: 354.7 MB)
18/05/31 14:46:57 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:57 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 185 (MapPartitionsRDD[120] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:57 INFO TaskSchedulerImpl: Adding task set 185.0 with 4 tasks
18/05/31 14:46:57 INFO TaskSetManager: Starting task 0.0 in stage 185.0 (TID 122, localhost, executor driver, partition 0, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:46:57 INFO TaskSetManager: Starting task 1.0 in stage 185.0 (TID 123, localhost, executor driver, partition 1, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:46:57 INFO TaskSetManager: Starting task 2.0 in stage 185.0 (TID 124, localhost, executor driver, partition 2, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:46:57 INFO TaskSetManager: Starting task 3.0 in stage 185.0 (TID 125, localhost, executor driver, partition 3, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:46:57 INFO Executor: Running task 2.0 in stage 185.0 (TID 124)
18/05/31 14:46:57 INFO Executor: Running task 3.0 in stage 185.0 (TID 125)
18/05/31 14:46:57 INFO Executor: Running task 1.0 in stage 185.0 (TID 123)
18/05/31 14:46:57 INFO Executor: Running task 0.0 in stage 185.0 (TID 122)
18/05/31 14:46:57 INFO BlockManager: Found block rdd_114_1 locally
18/05/31 14:46:57 INFO BlockManager: Found block rdd_114_3 locally
18/05/31 14:46:57 INFO BlockManager: Found block rdd_114_2 locally
18/05/31 14:46:57 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:57 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:57 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:57 INFO MemoryStore: Block rdd_119_3 stored as values in memory (estimated size 4.0 KB, free 354.7 MB)
18/05/31 14:46:57 INFO MemoryStore: Block rdd_119_1 stored as values in memory (estimated size 4.0 KB, free 354.7 MB)
18/05/31 14:46:57 INFO BlockManagerInfo: Added rdd_119_3 in memory on 10.66.169.34:53539 (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:46:57 INFO BlockManagerInfo: Added rdd_119_1 in memory on 10.66.169.34:53539 (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:46:57 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:57 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:57 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-89
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:57 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:57 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:57 WARN Executor: 1 block locks were not released by TID = 125:
[rdd_114_3]
18/05/31 14:46:57 INFO Executor: Finished task 3.0 in stage 185.0 (TID 125). 2359 bytes result sent to driver
18/05/31 14:46:57 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-90
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:57 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:57 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:57 WARN Executor: 1 block locks were not released by TID = 123:
[rdd_114_1]
18/05/31 14:46:57 INFO Executor: Finished task 1.0 in stage 185.0 (TID 123). 2359 bytes result sent to driver
18/05/31 14:46:57 INFO TaskSetManager: Finished task 3.0 in stage 185.0 (TID 125) in 10 ms on localhost (executor driver) (1/4)
18/05/31 14:46:57 INFO TaskSetManager: Finished task 1.0 in stage 185.0 (TID 123) in 10 ms on localhost (executor driver) (2/4)
18/05/31 14:46:57 INFO BlockManager: Found block rdd_114_0 locally
18/05/31 14:46:57 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:57 INFO MemoryStore: Block rdd_119_0 stored as values in memory (estimated size 4.0 KB, free 354.7 MB)
18/05/31 14:46:57 INFO BlockManagerInfo: Added rdd_119_0 in memory on 10.66.169.34:53539 (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:46:57 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:57 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-91
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:57 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:57 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:57 WARN Executor: 1 block locks were not released by TID = 122:
[rdd_114_0]
18/05/31 14:46:57 INFO Executor: Finished task 0.0 in stage 185.0 (TID 122). 2359 bytes result sent to driver
18/05/31 14:46:57 INFO TaskSetManager: Finished task 0.0 in stage 185.0 (TID 122) in 17 ms on localhost (executor driver) (3/4)
18/05/31 14:46:58 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 10.66.169.34:53539 on disk (size: 4.2 KB)
18/05/31 14:46:58 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:46:58 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 10.66.169.34:53539 in memory (size: 4.3 KB, free: 354.7 MB)
18/05/31 14:46:58 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:46:58 INFO MemoryStore: 4 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:46:58 INFO BlockManager: Dropping block rdd_104_3 from memory
18/05/31 14:46:58 INFO BlockManagerInfo: Removed rdd_104_3 on 10.66.169.34:53539 in memory (size: 17.0 KB, free: 354.7 MB)
18/05/31 14:46:58 INFO BlockManager: Dropping block rdd_104_0 from memory
18/05/31 14:46:58 INFO BlockManagerInfo: Removed rdd_104_0 on 10.66.169.34:53539 in memory (size: 17.0 KB, free: 354.8 MB)
18/05/31 14:46:58 INFO BlockManager: Dropping block rdd_112_0 from memory
18/05/31 14:46:58 INFO BlockManagerInfo: Removed rdd_112_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.8 MB)
18/05/31 14:46:58 INFO BlockManager: Dropping block rdd_109_2 from memory
18/05/31 14:46:58 INFO BlockManagerInfo: Removed rdd_109_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:46:58 INFO MemoryStore: After dropping 4 blocks, free memory is 633.5 MB
18/05/31 14:46:59 INFO MemoryStore: Block rdd_119_2 stored as values in memory (estimated size 278.8 MB, free 354.8 MB)
18/05/31 14:46:59 INFO BlockManagerInfo: Added rdd_119_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.8 MB)
18/05/31 14:46:59 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:59 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-92
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:59 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:59 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:59 WARN Executor: 1 block locks were not released by TID = 124:
[rdd_114_2]
18/05/31 14:46:59 INFO Executor: Finished task 2.0 in stage 185.0 (TID 124). 2626 bytes result sent to driver
18/05/31 14:46:59 INFO TaskSetManager: Finished task 2.0 in stage 185.0 (TID 124) in 1695 ms on localhost (executor driver) (4/4)
18/05/31 14:46:59 INFO TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool 
18/05/31 14:46:59 INFO DAGScheduler: ResultStage 185 (foreachPartition at AnomalyDetector.java:69) finished in 1.695 s
18/05/31 14:46:59 INFO DAGScheduler: Job 27 finished: foreachPartition at AnomalyDetector.java:69, took 1.716993 s
18/05/31 14:46:59 INFO JobScheduler: Finished job streaming job 1527767010000 ms.0 from job set of time 1527767010000 ms
18/05/31 14:46:59 INFO JobScheduler: Total delay: 209.558 s for time 1527767010000 ms (execution: 1.720 s)
18/05/31 14:46:59 INFO MapPartitionsRDD: Removing RDD 115 from persistence list
18/05/31 14:46:59 INFO JobScheduler: Starting job streaming job 1527767020000 ms.0 from job set of time 1527767020000 ms
18/05/31 14:46:59 INFO BlockManager: Removing RDD 115
18/05/31 14:46:59 INFO MapWithStateRDD: Removing RDD 19 from persistence list
18/05/31 14:46:59 INFO BlockManager: Removing RDD 19
18/05/31 14:46:59 INFO MapPartitionsRDD: Removing RDD 17 from persistence list
18/05/31 14:46:59 INFO BlockManager: Removing RDD 17
18/05/31 14:46:59 INFO KafkaRDD: Removing RDD 16 from persistence list
18/05/31 14:46:59 INFO JobGenerator: Checkpointing graph for time 1527767010000 ms
18/05/31 14:46:59 INFO BlockManager: Removing RDD 16
18/05/31 14:46:59 INFO DStreamGraph: Updating checkpoint data for time 1527767010000 ms
18/05/31 14:46:59 INFO DStreamGraph: Updated checkpoint data for time 1527767010000 ms
18/05/31 14:46:59 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:46:59 INFO DAGScheduler: Registering RDD 122 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:59 INFO CheckpointWriter: Saving checkpoint for time 1527767010000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000'
18/05/31 14:46:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 149 bytes
18/05/31 14:46:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 149 bytes
18/05/31 14:46:59 INFO CheckpointWriter: Submitted checkpoint of time 1527767010000 ms to writer queue
18/05/31 14:46:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 149 bytes
18/05/31 14:46:59 INFO DAGScheduler: Got job 28 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:46:59 INFO DAGScheduler: Final stage: ResultStage 190 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:46:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 186, ShuffleMapStage 187, ShuffleMapStage 188, ShuffleMapStage 189)
18/05/31 14:46:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 186)
18/05/31 14:46:59 INFO DAGScheduler: Submitting ShuffleMapStage 186 (MapPartitionsRDD[122] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:46:59 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 5.9 KB, free 354.7 MB)
18/05/31 14:46:59 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.7 MB)
18/05/31 14:46:59 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.8 MB)
18/05/31 14:46:59 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 186 (MapPartitionsRDD[122] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:46:59 INFO TaskSchedulerImpl: Adding task set 186.0 with 1 tasks
18/05/31 14:46:59 INFO TaskSetManager: Starting task 0.0 in stage 186.0 (TID 126, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:46:59 INFO Executor: Running task 0.0 in stage 186.0 (TID 126)
18/05/31 14:46:59 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:46:59 INFO MemoryStore: Block rdd_122_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:46:59 INFO BlockManagerInfo: Added rdd_122_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.8 MB)
18/05/31 14:46:59 INFO Executor: Finished task 0.0 in stage 186.0 (TID 126). 1708 bytes result sent to driver
18/05/31 14:46:59 INFO TaskSetManager: Finished task 0.0 in stage 186.0 (TID 126) in 8 ms on localhost (executor driver) (1/1)
18/05/31 14:46:59 INFO TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool 
18/05/31 14:46:59 INFO DAGScheduler: ShuffleMapStage 186 (mapToPair at AnomalyDetector.java:64) finished in 0.009 s
18/05/31 14:46:59 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:46:59 INFO DAGScheduler: running: Set()
18/05/31 14:46:59 INFO DAGScheduler: waiting: Set(ResultStage 190)
18/05/31 14:46:59 INFO DAGScheduler: failed: Set()
18/05/31 14:46:59 INFO DAGScheduler: Submitting ResultStage 190 (MapPartitionsRDD[125] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:46:59 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 8.6 KB, free 354.7 MB)
18/05/31 14:46:59 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 4.4 KB, free 354.7 MB)
18/05/31 14:46:59 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 10.66.169.34:53539 (size: 4.4 KB, free: 354.8 MB)
18/05/31 14:46:59 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:996
18/05/31 14:46:59 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 190 (MapPartitionsRDD[125] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:46:59 INFO TaskSchedulerImpl: Adding task set 190.0 with 4 tasks
18/05/31 14:46:59 INFO CheckpointWriter: Checkpoint for time 1527767010000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000', took 6267 bytes and 29 ms
18/05/31 14:46:59 INFO DStreamGraph: Clearing checkpoint data for time 1527767010000 ms
18/05/31 14:46:59 INFO TaskSetManager: Starting task 0.0 in stage 190.0 (TID 127, localhost, executor driver, partition 0, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:46:59 INFO DStreamGraph: Cleared checkpoint data for time 1527767010000 ms
18/05/31 14:46:59 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:46:59 INFO TaskSetManager: Starting task 1.0 in stage 190.0 (TID 128, localhost, executor driver, partition 1, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:46:59 INFO TaskSetManager: Starting task 2.0 in stage 190.0 (TID 129, localhost, executor driver, partition 2, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:46:59 INFO TaskSetManager: Starting task 3.0 in stage 190.0 (TID 130, localhost, executor driver, partition 3, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:46:59 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 1 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766810000: file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata/log-1527766741633-1527766801633
18/05/31 14:46:59 INFO Executor: Running task 0.0 in stage 190.0 (TID 127)
18/05/31 14:46:59 INFO Executor: Running task 1.0 in stage 190.0 (TID 128)
18/05/31 14:46:59 INFO Executor: Running task 3.0 in stage 190.0 (TID 130)
18/05/31 14:46:59 INFO Executor: Running task 2.0 in stage 190.0 (TID 129)
18/05/31 14:46:59 INFO InputInfoTracker: remove old batch metadata: 1527766800000 ms
18/05/31 14:46:59 INFO BlockManager: Found block rdd_119_0 locally
18/05/31 14:46:59 INFO BlockManager: Found block rdd_119_3 locally
18/05/31 14:46:59 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:46:59 INFO MemoryStore: Block rdd_124_3 stored as values in memory (estimated size 4.8 KB, free 354.7 MB)
18/05/31 14:46:59 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:46:59 INFO BlockManager: Found block rdd_119_1 locally
18/05/31 14:46:59 INFO MemoryStore: Block rdd_124_0 stored as values in memory (estimated size 4.8 KB, free 354.7 MB)
18/05/31 14:46:59 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:59 INFO BlockManagerInfo: Added rdd_124_3 in memory on 10.66.169.34:53539 (size: 4.8 KB, free: 354.8 MB)
18/05/31 14:46:59 INFO MemoryStore: Block rdd_124_1 stored as values in memory (estimated size 4.8 KB, free 354.7 MB)
18/05/31 14:46:59 INFO BlockManager: Found block rdd_119_2 locally
18/05/31 14:46:59 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Cleared log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766810000
18/05/31 14:46:59 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:46:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:46:59 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:59 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-93
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:59 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:59 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:59 INFO BlockManagerInfo: Added rdd_124_0 in memory on 10.66.169.34:53539 (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:46:59 INFO BlockManagerInfo: Added rdd_124_1 in memory on 10.66.169.34:53539 (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:46:59 WARN Executor: 1 block locks were not released by TID = 130:
[rdd_119_3]
18/05/31 14:46:59 INFO Executor: Finished task 3.0 in stage 190.0 (TID 130). 2359 bytes result sent to driver
18/05/31 14:46:59 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:59 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:59 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-94
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:59 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:59 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:59 WARN Executor: 1 block locks were not released by TID = 127:
[rdd_119_0]
18/05/31 14:46:59 INFO Executor: Finished task 0.0 in stage 190.0 (TID 127). 2359 bytes result sent to driver
18/05/31 14:46:59 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-95
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:46:59 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:46:59 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:46:59 WARN Executor: 1 block locks were not released by TID = 128:
[rdd_119_1]
18/05/31 14:46:59 INFO Executor: Finished task 1.0 in stage 190.0 (TID 128). 2359 bytes result sent to driver
18/05/31 14:46:59 INFO TaskSetManager: Finished task 3.0 in stage 190.0 (TID 130) in 18 ms on localhost (executor driver) (1/4)
18/05/31 14:46:59 INFO TaskSetManager: Finished task 0.0 in stage 190.0 (TID 127) in 23 ms on localhost (executor driver) (2/4)
18/05/31 14:46:59 INFO TaskSetManager: Finished task 1.0 in stage 190.0 (TID 128) in 22 ms on localhost (executor driver) (3/4)
18/05/31 14:47:00 INFO JobScheduler: Added jobs for time 1527767220000 ms
18/05/31 14:47:00 INFO JobGenerator: Checkpointing graph for time 1527767220000 ms
18/05/31 14:47:00 INFO DStreamGraph: Updating checkpoint data for time 1527767220000 ms
18/05/31 14:47:00 INFO DStreamGraph: Updated checkpoint data for time 1527767220000 ms
18/05/31 14:47:00 INFO CheckpointWriter: Submitted checkpoint of time 1527767220000 ms to writer queue
18/05/31 14:47:00 INFO CheckpointWriter: Saving checkpoint for time 1527767220000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000'
18/05/31 14:47:00 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767160000
18/05/31 14:47:00 INFO CheckpointWriter: Checkpoint for time 1527767220000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000', took 6265 bytes and 12 ms
18/05/31 14:47:00 INFO MemoryStore: 6 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:00 INFO BlockManager: Dropping block rdd_109_0 from memory
18/05/31 14:47:00 INFO BlockManagerInfo: Removed rdd_109_0 on 10.66.169.34:53539 in memory (size: 2.5 KB, free: 354.7 MB)
18/05/31 14:47:00 INFO BlockManager: Dropping block rdd_109_1 from memory
18/05/31 14:47:00 INFO BlockManagerInfo: Removed rdd_109_1 on 10.66.169.34:53539 in memory (size: 2.5 KB, free: 354.7 MB)
18/05/31 14:47:00 INFO BlockManager: Dropping block rdd_109_3 from memory
18/05/31 14:47:00 INFO BlockManagerInfo: Removed rdd_109_3 on 10.66.169.34:53539 in memory (size: 2.5 KB, free: 354.7 MB)
18/05/31 14:47:00 INFO BlockManager: Dropping block rdd_117_0 from memory
18/05/31 14:47:00 INFO BlockManagerInfo: Removed rdd_117_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:00 INFO BlockManager: Dropping block broadcast_60_piece0 from memory
18/05/31 14:47:00 INFO BlockManager: Writing block broadcast_60_piece0 to disk
18/05/31 14:47:00 INFO BlockManagerInfo: Added broadcast_60_piece0 on disk on 10.66.169.34:53539 (size: 4.3 KB)
18/05/31 14:47:00 INFO BlockManager: Dropping block rdd_114_2 from memory
18/05/31 14:47:00 INFO BlockManagerInfo: Removed rdd_114_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:00 INFO MemoryStore: After dropping 6 blocks, free memory is 633.5 MB
18/05/31 14:47:01 INFO MemoryStore: Block rdd_124_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:01 INFO BlockManagerInfo: Added rdd_124_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.8 MB)
18/05/31 14:47:01 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:01 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-96
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:01 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:01 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:01 WARN Executor: 1 block locks were not released by TID = 129:
[rdd_119_2]
18/05/31 14:47:01 INFO Executor: Finished task 2.0 in stage 190.0 (TID 129). 2757 bytes result sent to driver
18/05/31 14:47:01 INFO TaskSetManager: Finished task 2.0 in stage 190.0 (TID 129) in 1644 ms on localhost (executor driver) (4/4)
18/05/31 14:47:01 INFO TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool 
18/05/31 14:47:01 INFO DAGScheduler: ResultStage 190 (foreachPartition at AnomalyDetector.java:69) finished in 1.646 s
18/05/31 14:47:01 INFO DAGScheduler: Job 28 finished: foreachPartition at AnomalyDetector.java:69, took 1.674768 s
18/05/31 14:47:01 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 127.1 KB, free 354.6 MB)
18/05/31 14:47:01 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.6 MB)
18/05/31 14:47:01 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO SparkContext: Created broadcast 63 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:01 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:01 INFO DAGScheduler: Got job 29 (foreachPartition at AnomalyDetector.java:69) with 1 output partitions
18/05/31 14:47:01 INFO DAGScheduler: Final stage: ResultStage 191 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:01 INFO DAGScheduler: Parents of final stage: List()
18/05/31 14:47:01 INFO DAGScheduler: Missing parents: List()
18/05/31 14:47:01 INFO DAGScheduler: Submitting ResultStage 191 (MapPartitionsRDD[122] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:01 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 6.1 KB, free 354.6 MB)
18/05/31 14:47:01 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.6 MB)
18/05/31 14:47:01 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 191 (MapPartitionsRDD[122] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:01 INFO TaskSchedulerImpl: Adding task set 191.0 with 1 tasks
18/05/31 14:47:01 INFO TaskSetManager: Starting task 0.0 in stage 191.0 (TID 131, localhost, executor driver, partition 0, PROCESS_LOCAL, 6166 bytes)
18/05/31 14:47:01 INFO Executor: Running task 0.0 in stage 191.0 (TID 131)
18/05/31 14:47:01 INFO BlockManager: Found block rdd_122_0 locally
18/05/31 14:47:01 INFO Executor: Finished task 0.0 in stage 191.0 (TID 131). 1004 bytes result sent to driver
18/05/31 14:47:01 INFO TaskSetManager: Finished task 0.0 in stage 191.0 (TID 131) in 11 ms on localhost (executor driver) (1/1)
18/05/31 14:47:01 INFO TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool 
18/05/31 14:47:01 INFO DAGScheduler: ResultStage 191 (foreachPartition at AnomalyDetector.java:69) finished in 0.012 s
18/05/31 14:47:01 INFO DAGScheduler: Job 29 finished: foreachPartition at AnomalyDetector.java:69, took 0.014805 s
18/05/31 14:47:01 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 127.1 KB, free 354.5 MB)
18/05/31 14:47:01 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.4 MB)
18/05/31 14:47:01 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO SparkContext: Created broadcast 65 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:01 INFO ReliableRDDCheckpointData: Done checkpointing RDD 122 to file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-122, new parent is RDD 231
18/05/31 14:47:01 INFO JobScheduler: Finished job streaming job 1527767020000 ms.0 from job set of time 1527767020000 ms
18/05/31 14:47:01 INFO JobScheduler: Total delay: 201.283 s for time 1527767020000 ms (execution: 1.725 s)
18/05/31 14:47:01 INFO MapPartitionsRDD: Removing RDD 120 from persistence list
18/05/31 14:47:01 INFO JobScheduler: Starting job streaming job 1527767030000 ms.0 from job set of time 1527767030000 ms
18/05/31 14:47:01 INFO BlockManager: Removing RDD 120
18/05/31 14:47:01 INFO MapWithStateRDD: Removing RDD 24 from persistence list
18/05/31 14:47:01 INFO BlockManager: Removing RDD 24
18/05/31 14:47:01 INFO MapPartitionsRDD: Removing RDD 22 from persistence list
18/05/31 14:47:01 INFO KafkaRDD: Removing RDD 21 from persistence list
18/05/31 14:47:01 INFO BlockManager: Removing RDD 22
18/05/31 14:47:01 INFO BlockManager: Removing RDD 21
18/05/31 14:47:01 INFO JobGenerator: Checkpointing graph for time 1527767020000 ms
18/05/31 14:47:01 INFO DStreamGraph: Updating checkpoint data for time 1527767020000 ms
18/05/31 14:47:01 INFO DStreamGraph: Updated checkpoint data for time 1527767020000 ms
18/05/31 14:47:01 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:01 INFO CheckpointWriter: Submitted checkpoint of time 1527767020000 ms to writer queue
18/05/31 14:47:01 INFO CheckpointWriter: Saving checkpoint for time 1527767020000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000'
18/05/31 14:47:01 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 149 bytes
18/05/31 14:47:01 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 149 bytes
18/05/31 14:47:01 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 149 bytes
18/05/31 14:47:01 INFO DAGScheduler: Registering RDD 127 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:01 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 149 bytes
18/05/31 14:47:01 INFO DAGScheduler: Got job 30 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:01 INFO DAGScheduler: Final stage: ResultStage 197 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 194, ShuffleMapStage 195, ShuffleMapStage 192, ShuffleMapStage 196, ShuffleMapStage 193)
18/05/31 14:47:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 195)
18/05/31 14:47:01 INFO DAGScheduler: Submitting ShuffleMapStage 195 (MapPartitionsRDD[127] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:01 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 4.6 KB, free 354.4 MB)
18/05/31 14:47:01 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.4 MB)
18/05/31 14:47:01 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 195 (MapPartitionsRDD[127] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:01 INFO TaskSchedulerImpl: Adding task set 195.0 with 1 tasks
18/05/31 14:47:01 INFO TaskSetManager: Starting task 0.0 in stage 195.0 (TID 132, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:01 INFO Executor: Running task 0.0 in stage 195.0 (TID 132)
18/05/31 14:47:01 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:01 INFO MemoryStore: Block rdd_127_0 stored as bytes in memory (estimated size 4.0 B, free 354.4 MB)
18/05/31 14:47:01 INFO BlockManagerInfo: Added rdd_127_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:01 INFO Executor: Finished task 0.0 in stage 195.0 (TID 132). 1708 bytes result sent to driver
18/05/31 14:47:01 INFO TaskSetManager: Finished task 0.0 in stage 195.0 (TID 132) in 6 ms on localhost (executor driver) (1/1)
18/05/31 14:47:01 INFO TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool 
18/05/31 14:47:01 INFO DAGScheduler: ShuffleMapStage 195 (mapToPair at AnomalyDetector.java:64) finished in 0.006 s
18/05/31 14:47:01 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:01 INFO DAGScheduler: running: Set()
18/05/31 14:47:01 INFO DAGScheduler: waiting: Set(ResultStage 197)
18/05/31 14:47:01 INFO DAGScheduler: failed: Set()
18/05/31 14:47:01 INFO DAGScheduler: Submitting ResultStage 197 (MapPartitionsRDD[130] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:01 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 8.9 KB, free 354.4 MB)
18/05/31 14:47:01 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767170000
18/05/31 14:47:01 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.4 MB)
18/05/31 14:47:01 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 10.66.169.34:53539 (size: 4.5 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:01 INFO CheckpointWriter: Checkpoint for time 1527767020000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000', took 6231 bytes and 16 ms
18/05/31 14:47:01 INFO DStreamGraph: Clearing checkpoint data for time 1527767020000 ms
18/05/31 14:47:01 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 197 (MapPartitionsRDD[130] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:01 INFO TaskSchedulerImpl: Adding task set 197.0 with 4 tasks
18/05/31 14:47:01 INFO DStreamGraph: Cleared checkpoint data for time 1527767020000 ms
18/05/31 14:47:01 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:01 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766820000: 
18/05/31 14:47:01 INFO InputInfoTracker: remove old batch metadata: 1527766810000 ms
18/05/31 14:47:01 INFO TaskSetManager: Starting task 0.0 in stage 197.0 (TID 133, localhost, executor driver, partition 0, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:01 INFO TaskSetManager: Starting task 1.0 in stage 197.0 (TID 134, localhost, executor driver, partition 1, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:01 INFO TaskSetManager: Starting task 2.0 in stage 197.0 (TID 135, localhost, executor driver, partition 2, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:01 INFO TaskSetManager: Starting task 3.0 in stage 197.0 (TID 136, localhost, executor driver, partition 3, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:01 INFO Executor: Running task 0.0 in stage 197.0 (TID 133)
18/05/31 14:47:01 INFO Executor: Running task 1.0 in stage 197.0 (TID 134)
18/05/31 14:47:01 INFO Executor: Running task 2.0 in stage 197.0 (TID 135)
18/05/31 14:47:01 INFO Executor: Running task 3.0 in stage 197.0 (TID 136)
18/05/31 14:47:01 INFO BlockManager: Found block rdd_124_1 locally
18/05/31 14:47:01 INFO BlockManager: Found block rdd_124_3 locally
18/05/31 14:47:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:01 INFO MemoryStore: Block rdd_129_3 stored as values in memory (estimated size 5.5 KB, free 354.4 MB)
18/05/31 14:47:01 INFO BlockManager: Found block rdd_124_2 locally
18/05/31 14:47:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 45 ms
18/05/31 14:47:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 45 ms
18/05/31 14:47:01 INFO BlockManagerInfo: Added rdd_129_3 in memory on 10.66.169.34:53539 (size: 5.5 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO MemoryStore: Block rdd_129_1 stored as values in memory (estimated size 5.5 KB, free 354.4 MB)
18/05/31 14:47:01 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:01 INFO BlockManagerInfo: Added rdd_129_1 in memory on 10.66.169.34:53539 (size: 5.5 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:01 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-97
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:01 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:01 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:01 WARN Executor: 1 block locks were not released by TID = 136:
[rdd_124_3]
18/05/31 14:47:01 INFO Executor: Finished task 3.0 in stage 197.0 (TID 136). 2432 bytes result sent to driver
18/05/31 14:47:01 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-98
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:01 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:01 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:01 INFO TaskSetManager: Finished task 3.0 in stage 197.0 (TID 136) in 55 ms on localhost (executor driver) (1/4)
18/05/31 14:47:01 WARN Executor: 1 block locks were not released by TID = 134:
[rdd_124_1]
18/05/31 14:47:01 INFO Executor: Finished task 1.0 in stage 197.0 (TID 134). 2432 bytes result sent to driver
18/05/31 14:47:01 INFO TaskSetManager: Finished task 1.0 in stage 197.0 (TID 134) in 58 ms on localhost (executor driver) (2/4)
18/05/31 14:47:01 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 10.66.169.34:53539 on disk (size: 4.3 KB)
18/05/31 14:47:01 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 10.66.169.34:53539 in memory (size: 4.4 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 10.66.169.34:53539 in memory (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO BlockManager: Found block rdd_124_0 locally
18/05/31 14:47:01 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:01 INFO MemoryStore: Block rdd_129_0 stored as values in memory (estimated size 5.5 KB, free 354.6 MB)
18/05/31 14:47:01 INFO BlockManagerInfo: Added rdd_129_0 in memory on 10.66.169.34:53539 (size: 5.5 KB, free: 354.7 MB)
18/05/31 14:47:01 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:01 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-99
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:01 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:01 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:01 WARN Executor: 1 block locks were not released by TID = 133:
[rdd_124_0]
18/05/31 14:47:01 INFO Executor: Finished task 0.0 in stage 197.0 (TID 133). 2432 bytes result sent to driver
18/05/31 14:47:01 INFO TaskSetManager: Finished task 0.0 in stage 197.0 (TID 133) in 70 ms on localhost (executor driver) (3/4)
18/05/31 14:47:02 INFO MemoryStore: 7 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:02 INFO BlockManager: Dropping block rdd_114_3 from memory
18/05/31 14:47:02 INFO BlockManagerInfo: Removed rdd_114_3 on 10.66.169.34:53539 in memory (size: 3.2 KB, free: 354.7 MB)
18/05/31 14:47:02 INFO BlockManager: Dropping block rdd_114_1 from memory
18/05/31 14:47:02 INFO BlockManagerInfo: Removed rdd_114_1 on 10.66.169.34:53539 in memory (size: 3.2 KB, free: 354.7 MB)
18/05/31 14:47:02 INFO BlockManager: Dropping block rdd_114_0 from memory
18/05/31 14:47:02 INFO BlockManagerInfo: Removed rdd_114_0 on 10.66.169.34:53539 in memory (size: 3.2 KB, free: 354.7 MB)
18/05/31 14:47:02 INFO BlockManager: Dropping block rdd_119_0 from memory
18/05/31 14:47:02 INFO BlockManagerInfo: Removed rdd_119_0 on 10.66.169.34:53539 in memory (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:47:02 INFO BlockManager: Dropping block rdd_119_3 from memory
18/05/31 14:47:02 INFO BlockManagerInfo: Removed rdd_119_3 on 10.66.169.34:53539 in memory (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:47:02 INFO BlockManager: Dropping block rdd_119_1 from memory
18/05/31 14:47:02 INFO BlockManagerInfo: Removed rdd_119_1 on 10.66.169.34:53539 in memory (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:47:02 INFO BlockManager: Dropping block rdd_119_2 from memory
18/05/31 14:47:02 INFO BlockManagerInfo: Removed rdd_119_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:02 INFO MemoryStore: After dropping 7 blocks, free memory is 633.4 MB
18/05/31 14:47:03 INFO MemoryStore: Block rdd_129_2 stored as values in memory (estimated size 278.8 MB, free 354.6 MB)
18/05/31 14:47:03 INFO BlockManagerInfo: Added rdd_129_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:03 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:03 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-100
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:03 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:03 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:03 WARN Executor: 1 block locks were not released by TID = 135:
[rdd_124_2]
18/05/31 14:47:03 INFO Executor: Finished task 2.0 in stage 197.0 (TID 135). 2767 bytes result sent to driver
18/05/31 14:47:03 INFO TaskSetManager: Finished task 2.0 in stage 197.0 (TID 135) in 1708 ms on localhost (executor driver) (4/4)
18/05/31 14:47:03 INFO TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool 
18/05/31 14:47:03 INFO DAGScheduler: ResultStage 197 (foreachPartition at AnomalyDetector.java:69) finished in 1.709 s
18/05/31 14:47:03 INFO DAGScheduler: Job 30 finished: foreachPartition at AnomalyDetector.java:69, took 1.726393 s
18/05/31 14:47:03 INFO JobScheduler: Finished job streaming job 1527767030000 ms.0 from job set of time 1527767030000 ms
18/05/31 14:47:03 INFO JobScheduler: Total delay: 193.013 s for time 1527767030000 ms (execution: 1.730 s)
18/05/31 14:47:03 INFO MapPartitionsRDD: Removing RDD 125 from persistence list
18/05/31 14:47:03 INFO JobScheduler: Starting job streaming job 1527767040000 ms.0 from job set of time 1527767040000 ms
18/05/31 14:47:03 INFO BlockManager: Removing RDD 125
18/05/31 14:47:03 INFO MapWithStateRDD: Removing RDD 29 from persistence list
18/05/31 14:47:03 INFO BlockManager: Removing RDD 29
18/05/31 14:47:03 INFO MapPartitionsRDD: Removing RDD 27 from persistence list
18/05/31 14:47:03 INFO KafkaRDD: Removing RDD 26 from persistence list
18/05/31 14:47:03 INFO BlockManager: Removing RDD 27
18/05/31 14:47:03 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:03 INFO BlockManager: Removing RDD 26
18/05/31 14:47:03 INFO JobGenerator: Checkpointing graph for time 1527767030000 ms
18/05/31 14:47:03 INFO DStreamGraph: Updating checkpoint data for time 1527767030000 ms
18/05/31 14:47:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 149 bytes
18/05/31 14:47:03 INFO DStreamGraph: Updated checkpoint data for time 1527767030000 ms
18/05/31 14:47:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 149 bytes
18/05/31 14:47:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 149 bytes
18/05/31 14:47:03 INFO DAGScheduler: Registering RDD 132 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:03 INFO CheckpointWriter: Submitted checkpoint of time 1527767030000 ms to writer queue
18/05/31 14:47:03 INFO CheckpointWriter: Saving checkpoint for time 1527767030000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000'
18/05/31 14:47:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 149 bytes
18/05/31 14:47:03 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 149 bytes
18/05/31 14:47:03 INFO DAGScheduler: Got job 31 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:03 INFO DAGScheduler: Final stage: ResultStage 204 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 201, ShuffleMapStage 198, ShuffleMapStage 202, ShuffleMapStage 203, ShuffleMapStage 199, ShuffleMapStage 200)
18/05/31 14:47:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 201)
18/05/31 14:47:03 INFO DAGScheduler: Submitting ShuffleMapStage 201 (MapPartitionsRDD[132] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:03 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 4.6 KB, free 354.6 MB)
18/05/31 14:47:03 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.6 MB)
18/05/31 14:47:03 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:03 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 201 (MapPartitionsRDD[132] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:03 INFO TaskSchedulerImpl: Adding task set 201.0 with 1 tasks
18/05/31 14:47:03 INFO TaskSetManager: Starting task 0.0 in stage 201.0 (TID 137, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:03 INFO Executor: Running task 0.0 in stage 201.0 (TID 137)
18/05/31 14:47:03 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:03 INFO MemoryStore: Block rdd_132_0 stored as bytes in memory (estimated size 4.0 B, free 354.6 MB)
18/05/31 14:47:03 INFO BlockManagerInfo: Added rdd_132_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:03 INFO Executor: Finished task 0.0 in stage 201.0 (TID 137). 1708 bytes result sent to driver
18/05/31 14:47:03 INFO TaskSetManager: Finished task 0.0 in stage 201.0 (TID 137) in 7 ms on localhost (executor driver) (1/1)
18/05/31 14:47:03 INFO TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool 
18/05/31 14:47:03 INFO DAGScheduler: ShuffleMapStage 201 (mapToPair at AnomalyDetector.java:64) finished in 0.007 s
18/05/31 14:47:03 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:03 INFO DAGScheduler: running: Set()
18/05/31 14:47:03 INFO DAGScheduler: waiting: Set(ResultStage 204)
18/05/31 14:47:03 INFO DAGScheduler: failed: Set()
18/05/31 14:47:03 INFO DAGScheduler: Submitting ResultStage 204 (MapPartitionsRDD[135] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:03 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 9.2 KB, free 354.6 MB)
18/05/31 14:47:03 INFO CheckpointWriter: Checkpoint for time 1527767030000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000', took 6211 bytes and 16 ms
18/05/31 14:47:03 INFO DStreamGraph: Clearing checkpoint data for time 1527767030000 ms
18/05/31 14:47:03 INFO DStreamGraph: Cleared checkpoint data for time 1527767030000 ms
18/05/31 14:47:03 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:03 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766830000: 
18/05/31 14:47:03 INFO InputInfoTracker: remove old batch metadata: 1527766820000 ms
18/05/31 14:47:03 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.6 MB)
18/05/31 14:47:03 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 10.66.169.34:53539 (size: 4.5 KB, free: 354.7 MB)
18/05/31 14:47:03 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:03 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 204 (MapPartitionsRDD[135] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:03 INFO TaskSchedulerImpl: Adding task set 204.0 with 4 tasks
18/05/31 14:47:03 INFO TaskSetManager: Starting task 0.0 in stage 204.0 (TID 138, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:03 INFO TaskSetManager: Starting task 1.0 in stage 204.0 (TID 139, localhost, executor driver, partition 1, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:03 INFO TaskSetManager: Starting task 2.0 in stage 204.0 (TID 140, localhost, executor driver, partition 2, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:03 INFO TaskSetManager: Starting task 3.0 in stage 204.0 (TID 141, localhost, executor driver, partition 3, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:03 INFO Executor: Running task 0.0 in stage 204.0 (TID 138)
18/05/31 14:47:03 INFO Executor: Running task 2.0 in stage 204.0 (TID 140)
18/05/31 14:47:03 INFO Executor: Running task 1.0 in stage 204.0 (TID 139)
18/05/31 14:47:03 INFO Executor: Running task 3.0 in stage 204.0 (TID 141)
18/05/31 14:47:03 INFO BlockManager: Found block rdd_129_1 locally
18/05/31 14:47:03 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:03 INFO BlockManager: Found block rdd_129_2 locally
18/05/31 14:47:03 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:03 INFO BlockManager: Found block rdd_129_0 locally
18/05/31 14:47:03 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:03 INFO MemoryStore: Block rdd_134_0 stored as values in memory (estimated size 6.3 KB, free 354.6 MB)
18/05/31 14:47:03 INFO BlockManager: Found block rdd_129_3 locally
18/05/31 14:47:03 INFO BlockManagerInfo: Added rdd_134_0 in memory on 10.66.169.34:53539 (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:03 INFO MemoryStore: Block rdd_134_1 stored as values in memory (estimated size 6.3 KB, free 354.6 MB)
18/05/31 14:47:03 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:47:03 INFO BlockManagerInfo: Added rdd_134_1 in memory on 10.66.169.34:53539 (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:03 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:03 INFO MemoryStore: Block rdd_134_3 stored as values in memory (estimated size 6.3 KB, free 354.6 MB)
18/05/31 14:47:03 INFO BlockManagerInfo: Added rdd_134_3 in memory on 10.66.169.34:53539 (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:03 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:03 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:03 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-102
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:03 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:03 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:03 WARN Executor: 1 block locks were not released by TID = 139:
[rdd_129_1]
18/05/31 14:47:03 INFO Executor: Finished task 1.0 in stage 204.0 (TID 139). 2359 bytes result sent to driver
18/05/31 14:47:03 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-101
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:03 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:03 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:03 WARN Executor: 1 block locks were not released by TID = 138:
[rdd_129_0]
18/05/31 14:47:03 INFO Executor: Finished task 0.0 in stage 204.0 (TID 138). 2359 bytes result sent to driver
18/05/31 14:47:03 INFO TaskSetManager: Finished task 1.0 in stage 204.0 (TID 139) in 10 ms on localhost (executor driver) (1/4)
18/05/31 14:47:03 INFO TaskSetManager: Finished task 0.0 in stage 204.0 (TID 138) in 12 ms on localhost (executor driver) (2/4)
18/05/31 14:47:03 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-103
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:03 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:03 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:03 WARN Executor: 1 block locks were not released by TID = 141:
[rdd_129_3]
18/05/31 14:47:03 INFO Executor: Finished task 3.0 in stage 204.0 (TID 141). 2359 bytes result sent to driver
18/05/31 14:47:03 INFO TaskSetManager: Finished task 3.0 in stage 204.0 (TID 141) in 15 ms on localhost (executor driver) (3/4)
18/05/31 14:47:03 INFO MemoryStore: 8 blocks selected for dropping (278.9 MB bytes)
18/05/31 14:47:03 INFO BlockManager: Dropping block rdd_122_0 from memory
18/05/31 14:47:03 INFO BlockManagerInfo: Removed rdd_122_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:03 INFO BlockManager: Dropping block broadcast_65 from memory
18/05/31 14:47:03 INFO BlockManager: Writing block broadcast_65 to disk
18/05/31 14:47:03 INFO BlockManager: Dropping block broadcast_65_piece0 from memory
18/05/31 14:47:03 INFO BlockManager: Writing block broadcast_65_piece0 to disk
18/05/31 14:47:03 INFO BlockManagerInfo: Added broadcast_65_piece0 on disk on 10.66.169.34:53539 (size: 14.3 KB)
18/05/31 14:47:03 INFO BlockManager: Dropping block rdd_127_0 from memory
18/05/31 14:47:03 INFO BlockManagerInfo: Removed rdd_127_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:03 INFO BlockManager: Dropping block broadcast_67_piece0 from memory
18/05/31 14:47:03 INFO BlockManager: Writing block broadcast_67_piece0 to disk
18/05/31 14:47:03 INFO BlockManagerInfo: Added broadcast_67_piece0 on disk on 10.66.169.34:53539 (size: 4.5 KB)
18/05/31 14:47:03 INFO BlockManager: Dropping block rdd_124_1 from memory
18/05/31 14:47:03 INFO BlockManagerInfo: Removed rdd_124_1 on 10.66.169.34:53539 in memory (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:47:03 INFO BlockManager: Dropping block rdd_124_3 from memory
18/05/31 14:47:03 INFO BlockManagerInfo: Removed rdd_124_3 on 10.66.169.34:53539 in memory (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:47:03 INFO BlockManager: Dropping block rdd_124_2 from memory
18/05/31 14:47:03 INFO BlockManagerInfo: Removed rdd_124_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:03 INFO MemoryStore: After dropping 8 blocks, free memory is 633.5 MB
18/05/31 14:47:04 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 10.66.169.34:53539 on disk (size: 4.5 KB)
18/05/31 14:47:04 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 633.5 MB)
18/05/31 14:47:04 INFO MemoryStore: Block rdd_134_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:04 INFO BlockManagerInfo: Added rdd_134_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:04 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:04 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-104
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:04 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:04 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:04 WARN Executor: 1 block locks were not released by TID = 140:
[rdd_129_2]
18/05/31 14:47:04 INFO Executor: Finished task 2.0 in stage 204.0 (TID 140). 2936 bytes result sent to driver
18/05/31 14:47:04 INFO TaskSetManager: Finished task 2.0 in stage 204.0 (TID 140) in 1754 ms on localhost (executor driver) (4/4)
18/05/31 14:47:04 INFO TaskSchedulerImpl: Removed TaskSet 204.0, whose tasks have all completed, from pool 
18/05/31 14:47:04 INFO DAGScheduler: ResultStage 204 (foreachPartition at AnomalyDetector.java:69) finished in 1.754 s
18/05/31 14:47:04 INFO DAGScheduler: Job 31 finished: foreachPartition at AnomalyDetector.java:69, took 1.774749 s
18/05/31 14:47:04 INFO JobScheduler: Finished job streaming job 1527767040000 ms.0 from job set of time 1527767040000 ms
18/05/31 14:47:04 INFO JobScheduler: Total delay: 184.792 s for time 1527767040000 ms (execution: 1.778 s)
18/05/31 14:47:04 INFO MapPartitionsRDD: Removing RDD 130 from persistence list
18/05/31 14:47:04 INFO JobScheduler: Starting job streaming job 1527767050000 ms.0 from job set of time 1527767050000 ms
18/05/31 14:47:04 INFO BlockManager: Removing RDD 130
18/05/31 14:47:04 INFO MapWithStateRDD: Removing RDD 34 from persistence list
18/05/31 14:47:04 INFO BlockManager: Removing RDD 34
18/05/31 14:47:04 INFO MapPartitionsRDD: Removing RDD 32 from persistence list
18/05/31 14:47:04 INFO BlockManager: Removing RDD 32
18/05/31 14:47:04 INFO KafkaRDD: Removing RDD 31 from persistence list
18/05/31 14:47:04 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 149 bytes
18/05/31 14:47:04 INFO JobGenerator: Checkpointing graph for time 1527767040000 ms
18/05/31 14:47:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 149 bytes
18/05/31 14:47:04 INFO BlockManager: Removing RDD 31
18/05/31 14:47:04 INFO DStreamGraph: Updating checkpoint data for time 1527767040000 ms
18/05/31 14:47:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 149 bytes
18/05/31 14:47:04 INFO DStreamGraph: Updated checkpoint data for time 1527767040000 ms
18/05/31 14:47:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 149 bytes
18/05/31 14:47:04 INFO CheckpointWriter: Submitted checkpoint of time 1527767040000 ms to writer queue
18/05/31 14:47:04 INFO CheckpointWriter: Saving checkpoint for time 1527767040000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000'
18/05/31 14:47:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 149 bytes
18/05/31 14:47:04 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 149 bytes
18/05/31 14:47:04 INFO DAGScheduler: Registering RDD 137 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:04 INFO DAGScheduler: Got job 32 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:04 INFO DAGScheduler: Final stage: ResultStage 212 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 208, ShuffleMapStage 205, ShuffleMapStage 209, ShuffleMapStage 206, ShuffleMapStage 210, ShuffleMapStage 207, ShuffleMapStage 211)
18/05/31 14:47:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 211)
18/05/31 14:47:04 INFO DAGScheduler: Submitting ShuffleMapStage 211 (MapPartitionsRDD[137] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:04 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:47:04 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.7 MB)
18/05/31 14:47:04 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:04 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 211 (MapPartitionsRDD[137] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:04 INFO TaskSchedulerImpl: Adding task set 211.0 with 1 tasks
18/05/31 14:47:04 INFO TaskSetManager: Starting task 0.0 in stage 211.0 (TID 142, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:04 INFO Executor: Running task 0.0 in stage 211.0 (TID 142)
18/05/31 14:47:04 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:04 INFO MemoryStore: Block rdd_137_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:47:04 INFO BlockManagerInfo: Added rdd_137_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:04 INFO Executor: Finished task 0.0 in stage 211.0 (TID 142). 1708 bytes result sent to driver
18/05/31 14:47:04 INFO TaskSetManager: Finished task 0.0 in stage 211.0 (TID 142) in 7 ms on localhost (executor driver) (1/1)
18/05/31 14:47:04 INFO TaskSchedulerImpl: Removed TaskSet 211.0, whose tasks have all completed, from pool 
18/05/31 14:47:04 INFO DAGScheduler: ShuffleMapStage 211 (mapToPair at AnomalyDetector.java:64) finished in 0.008 s
18/05/31 14:47:04 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:04 INFO DAGScheduler: running: Set()
18/05/31 14:47:04 INFO DAGScheduler: waiting: Set(ResultStage 212)
18/05/31 14:47:04 INFO DAGScheduler: failed: Set()
18/05/31 14:47:04 INFO DAGScheduler: Submitting ResultStage 212 (MapPartitionsRDD[140] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:04 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 9.4 KB, free 354.7 MB)
18/05/31 14:47:04 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:47:04 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 10.66.169.34:53539 (size: 4.6 KB, free: 354.7 MB)
18/05/31 14:47:04 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:04 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 212 (MapPartitionsRDD[140] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:04 INFO TaskSchedulerImpl: Adding task set 212.0 with 4 tasks
18/05/31 14:47:04 INFO TaskSetManager: Starting task 0.0 in stage 212.0 (TID 143, localhost, executor driver, partition 0, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:04 INFO TaskSetManager: Starting task 1.0 in stage 212.0 (TID 144, localhost, executor driver, partition 1, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:04 INFO TaskSetManager: Starting task 2.0 in stage 212.0 (TID 145, localhost, executor driver, partition 2, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:04 INFO TaskSetManager: Starting task 3.0 in stage 212.0 (TID 146, localhost, executor driver, partition 3, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:04 INFO Executor: Running task 1.0 in stage 212.0 (TID 144)
18/05/31 14:47:04 INFO Executor: Running task 2.0 in stage 212.0 (TID 145)
18/05/31 14:47:04 INFO CheckpointWriter: Checkpoint for time 1527767040000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000', took 6181 bytes and 22 ms
18/05/31 14:47:04 INFO Executor: Running task 3.0 in stage 212.0 (TID 146)
18/05/31 14:47:04 INFO DStreamGraph: Clearing checkpoint data for time 1527767040000 ms
18/05/31 14:47:04 INFO BlockManager: Found block rdd_134_2 locally
18/05/31 14:47:04 INFO BlockManager: Found block rdd_134_1 locally
18/05/31 14:47:04 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:04 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:47:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:47:04 INFO DStreamCheckpointData: Deleted checkpoint file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-32' for time 1527766840000 ms
18/05/31 14:47:04 INFO MemoryStore: Block rdd_139_1 stored as values in memory (estimated size 7.1 KB, free 354.7 MB)
18/05/31 14:47:04 INFO DStreamGraph: Cleared checkpoint data for time 1527767040000 ms
18/05/31 14:47:04 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:04 INFO BlockManagerInfo: Added rdd_139_1 in memory on 10.66.169.34:53539 (size: 7.1 KB, free: 354.7 MB)
18/05/31 14:47:04 INFO BlockManager: Found block rdd_134_3 locally
18/05/31 14:47:04 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:04 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:04 INFO MemoryStore: Block rdd_139_3 stored as values in memory (estimated size 7.1 KB, free 354.7 MB)
18/05/31 14:47:04 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766840000: 
18/05/31 14:47:04 INFO InputInfoTracker: remove old batch metadata: 1527766830000 ms
18/05/31 14:47:04 INFO BlockManagerInfo: Added rdd_139_3 in memory on 10.66.169.34:53539 (size: 7.1 KB, free: 354.7 MB)
18/05/31 14:47:04 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:04 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-105
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:04 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:04 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:04 WARN Executor: 1 block locks were not released by TID = 144:
[rdd_134_1]
18/05/31 14:47:04 INFO Executor: Finished task 1.0 in stage 212.0 (TID 144). 2359 bytes result sent to driver
18/05/31 14:47:04 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-106
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:04 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:04 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:04 WARN Executor: 1 block locks were not released by TID = 146:
[rdd_134_3]
18/05/31 14:47:04 INFO Executor: Finished task 3.0 in stage 212.0 (TID 146). 2359 bytes result sent to driver
18/05/31 14:47:04 INFO TaskSetManager: Finished task 1.0 in stage 212.0 (TID 144) in 12 ms on localhost (executor driver) (1/4)
18/05/31 14:47:04 INFO Executor: Running task 0.0 in stage 212.0 (TID 143)
18/05/31 14:47:04 INFO TaskSetManager: Finished task 3.0 in stage 212.0 (TID 146) in 12 ms on localhost (executor driver) (2/4)
18/05/31 14:47:04 INFO BlockManager: Found block rdd_134_0 locally
18/05/31 14:47:04 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:04 INFO MemoryStore: Block rdd_139_0 stored as values in memory (estimated size 7.1 KB, free 354.7 MB)
18/05/31 14:47:04 INFO BlockManagerInfo: Added rdd_139_0 in memory on 10.66.169.34:53539 (size: 7.1 KB, free: 354.7 MB)
18/05/31 14:47:04 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:04 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-107
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:04 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:04 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:04 WARN Executor: 1 block locks were not released by TID = 143:
[rdd_134_0]
18/05/31 14:47:04 INFO Executor: Finished task 0.0 in stage 212.0 (TID 143). 2359 bytes result sent to driver
18/05/31 14:47:04 INFO TaskSetManager: Finished task 0.0 in stage 212.0 (TID 143) in 21 ms on localhost (executor driver) (3/4)
18/05/31 14:47:05 INFO MemoryStore: 6 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:05 INFO BlockManager: Dropping block rdd_124_0 from memory
18/05/31 14:47:05 INFO BlockManagerInfo: Removed rdd_124_0 on 10.66.169.34:53539 in memory (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:47:05 INFO BlockManager: Dropping block rdd_132_0 from memory
18/05/31 14:47:05 INFO BlockManagerInfo: Removed rdd_132_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:05 INFO BlockManager: Dropping block broadcast_69_piece0 from memory
18/05/31 14:47:05 INFO BlockManager: Writing block broadcast_69_piece0 to disk
18/05/31 14:47:05 INFO BlockManagerInfo: Added broadcast_69_piece0 on disk on 10.66.169.34:53539 (size: 4.5 KB)
18/05/31 14:47:05 INFO BlockManager: Dropping block broadcast_69 from memory
18/05/31 14:47:05 INFO BlockManager: Writing block broadcast_69 to disk
18/05/31 14:47:05 INFO BlockManager: Dropping block rdd_129_1 from memory
18/05/31 14:47:05 INFO BlockManagerInfo: Removed rdd_129_1 on 10.66.169.34:53539 in memory (size: 5.5 KB, free: 354.7 MB)
18/05/31 14:47:05 INFO BlockManager: Dropping block rdd_129_2 from memory
18/05/31 14:47:05 INFO BlockManagerInfo: Removed rdd_129_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:05 INFO MemoryStore: After dropping 6 blocks, free memory is 633.5 MB
18/05/31 14:47:06 INFO MemoryStore: Block rdd_139_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:06 INFO BlockManagerInfo: Added rdd_139_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:06 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:06 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-108
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:06 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:06 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:06 WARN Executor: 1 block locks were not released by TID = 145:
[rdd_134_2]
18/05/31 14:47:06 INFO Executor: Finished task 2.0 in stage 212.0 (TID 145). 2760 bytes result sent to driver
18/05/31 14:47:06 INFO TaskSetManager: Finished task 2.0 in stage 212.0 (TID 145) in 1661 ms on localhost (executor driver) (4/4)
18/05/31 14:47:06 INFO TaskSchedulerImpl: Removed TaskSet 212.0, whose tasks have all completed, from pool 
18/05/31 14:47:06 INFO DAGScheduler: ResultStage 212 (foreachPartition at AnomalyDetector.java:69) finished in 1.662 s
18/05/31 14:47:06 INFO DAGScheduler: Job 32 finished: foreachPartition at AnomalyDetector.java:69, took 1.686876 s
18/05/31 14:47:06 INFO JobScheduler: Finished job streaming job 1527767050000 ms.0 from job set of time 1527767050000 ms
18/05/31 14:47:06 INFO JobScheduler: Total delay: 176.483 s for time 1527767050000 ms (execution: 1.691 s)
18/05/31 14:47:06 INFO MapPartitionsRDD: Removing RDD 135 from persistence list
18/05/31 14:47:06 INFO JobScheduler: Starting job streaming job 1527767060000 ms.0 from job set of time 1527767060000 ms
18/05/31 14:47:06 INFO BlockManager: Removing RDD 135
18/05/31 14:47:06 INFO MapWithStateRDD: Removing RDD 39 from persistence list
18/05/31 14:47:06 INFO BlockManager: Removing RDD 39
18/05/31 14:47:06 INFO MapPartitionsRDD: Removing RDD 37 from persistence list
18/05/31 14:47:06 INFO BlockManager: Removing RDD 37
18/05/31 14:47:06 INFO KafkaRDD: Removing RDD 36 from persistence list
18/05/31 14:47:06 INFO BlockManager: Removing RDD 36
18/05/31 14:47:06 INFO JobGenerator: Checkpointing graph for time 1527767050000 ms
18/05/31 14:47:06 INFO DStreamGraph: Updating checkpoint data for time 1527767050000 ms
18/05/31 14:47:06 INFO DStreamGraph: Updated checkpoint data for time 1527767050000 ms
18/05/31 14:47:06 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:06 INFO CheckpointWriter: Submitted checkpoint of time 1527767050000 ms to writer queue
18/05/31 14:47:06 INFO CheckpointWriter: Saving checkpoint for time 1527767050000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000'
18/05/31 14:47:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 149 bytes
18/05/31 14:47:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 149 bytes
18/05/31 14:47:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 149 bytes
18/05/31 14:47:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 149 bytes
18/05/31 14:47:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 149 bytes
18/05/31 14:47:06 INFO DAGScheduler: Registering RDD 142 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 149 bytes
18/05/31 14:47:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 28 is 149 bytes
18/05/31 14:47:06 INFO DAGScheduler: Got job 33 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:06 INFO DAGScheduler: Final stage: ResultStage 221 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 215, ShuffleMapStage 219, ShuffleMapStage 216, ShuffleMapStage 220, ShuffleMapStage 213, ShuffleMapStage 217, ShuffleMapStage 214, ShuffleMapStage 218)
18/05/31 14:47:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 218)
18/05/31 14:47:06 INFO DAGScheduler: Submitting ShuffleMapStage 218 (MapPartitionsRDD[142] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:06 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:47:06 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.7 MB)
18/05/31 14:47:06 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:06 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 218 (MapPartitionsRDD[142] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:06 INFO TaskSchedulerImpl: Adding task set 218.0 with 1 tasks
18/05/31 14:47:06 INFO TaskSetManager: Starting task 0.0 in stage 218.0 (TID 147, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:06 INFO Executor: Running task 0.0 in stage 218.0 (TID 147)
18/05/31 14:47:06 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:06 INFO MemoryStore: Block rdd_142_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:47:06 INFO BlockManagerInfo: Added rdd_142_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:06 INFO Executor: Finished task 0.0 in stage 218.0 (TID 147). 1708 bytes result sent to driver
18/05/31 14:47:06 INFO CheckpointWriter: Checkpoint for time 1527767050000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000', took 6164 bytes and 15 ms
18/05/31 14:47:06 INFO TaskSetManager: Finished task 0.0 in stage 218.0 (TID 147) in 7 ms on localhost (executor driver) (1/1)
18/05/31 14:47:06 INFO TaskSchedulerImpl: Removed TaskSet 218.0, whose tasks have all completed, from pool 
18/05/31 14:47:06 INFO DStreamGraph: Clearing checkpoint data for time 1527767050000 ms
18/05/31 14:47:06 INFO DStreamGraph: Cleared checkpoint data for time 1527767050000 ms
18/05/31 14:47:06 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:06 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766850000: 
18/05/31 14:47:06 INFO DAGScheduler: ShuffleMapStage 218 (mapToPair at AnomalyDetector.java:64) finished in 0.008 s
18/05/31 14:47:06 INFO InputInfoTracker: remove old batch metadata: 1527766840000 ms
18/05/31 14:47:06 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:06 INFO DAGScheduler: running: Set()
18/05/31 14:47:06 INFO DAGScheduler: waiting: Set(ResultStage 221)
18/05/31 14:47:06 INFO DAGScheduler: failed: Set()
18/05/31 14:47:06 INFO DAGScheduler: Submitting ResultStage 221 (MapPartitionsRDD[145] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:06 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 9.7 KB, free 354.7 MB)
18/05/31 14:47:06 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:47:06 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 10.66.169.34:53539 (size: 4.6 KB, free: 354.7 MB)
18/05/31 14:47:06 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:06 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 221 (MapPartitionsRDD[145] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:06 INFO TaskSchedulerImpl: Adding task set 221.0 with 4 tasks
18/05/31 14:47:06 INFO TaskSetManager: Starting task 0.0 in stage 221.0 (TID 148, localhost, executor driver, partition 0, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:06 INFO TaskSetManager: Starting task 1.0 in stage 221.0 (TID 149, localhost, executor driver, partition 1, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:06 INFO TaskSetManager: Starting task 2.0 in stage 221.0 (TID 150, localhost, executor driver, partition 2, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:06 INFO TaskSetManager: Starting task 3.0 in stage 221.0 (TID 151, localhost, executor driver, partition 3, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:06 INFO Executor: Running task 2.0 in stage 221.0 (TID 150)
18/05/31 14:47:06 INFO Executor: Running task 1.0 in stage 221.0 (TID 149)
18/05/31 14:47:06 INFO Executor: Running task 3.0 in stage 221.0 (TID 151)
18/05/31 14:47:06 INFO BlockManager: Found block rdd_139_2 locally
18/05/31 14:47:06 INFO BlockManager: Found block rdd_139_3 locally
18/05/31 14:47:06 INFO BlockManager: Found block rdd_139_1 locally
18/05/31 14:47:06 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:06 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:06 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:06 INFO MemoryStore: Block rdd_144_3 stored as values in memory (estimated size 7.8 KB, free 354.7 MB)
18/05/31 14:47:06 INFO MemoryStore: Block rdd_144_1 stored as values in memory (estimated size 7.8 KB, free 354.7 MB)
18/05/31 14:47:06 INFO BlockManagerInfo: Added rdd_144_3 in memory on 10.66.169.34:53539 (size: 7.8 KB, free: 354.7 MB)
18/05/31 14:47:06 INFO BlockManagerInfo: Added rdd_144_1 in memory on 10.66.169.34:53539 (size: 7.8 KB, free: 354.7 MB)
18/05/31 14:47:06 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:06 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:06 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-110
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:06 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:06 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:06 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-109
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:06 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:06 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:06 WARN Executor: 1 block locks were not released by TID = 149:
[rdd_139_1]
18/05/31 14:47:06 WARN Executor: 1 block locks were not released by TID = 151:
[rdd_139_3]
18/05/31 14:47:06 INFO Executor: Finished task 3.0 in stage 221.0 (TID 151). 2359 bytes result sent to driver
18/05/31 14:47:06 INFO Executor: Finished task 1.0 in stage 221.0 (TID 149). 2359 bytes result sent to driver
18/05/31 14:47:06 INFO TaskSetManager: Finished task 3.0 in stage 221.0 (TID 151) in 7 ms on localhost (executor driver) (1/4)
18/05/31 14:47:06 INFO TaskSetManager: Finished task 1.0 in stage 221.0 (TID 149) in 8 ms on localhost (executor driver) (2/4)
18/05/31 14:47:06 INFO Executor: Running task 0.0 in stage 221.0 (TID 148)
18/05/31 14:47:06 INFO BlockManager: Found block rdd_139_0 locally
18/05/31 14:47:06 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:06 INFO MemoryStore: Block rdd_144_0 stored as values in memory (estimated size 7.8 KB, free 354.7 MB)
18/05/31 14:47:06 INFO BlockManagerInfo: Added rdd_144_0 in memory on 10.66.169.34:53539 (size: 7.8 KB, free: 354.7 MB)
18/05/31 14:47:06 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:06 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-111
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:06 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:06 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:06 WARN Executor: 1 block locks were not released by TID = 148:
[rdd_139_0]
18/05/31 14:47:06 INFO Executor: Finished task 0.0 in stage 221.0 (TID 148). 2359 bytes result sent to driver
18/05/31 14:47:06 INFO TaskSetManager: Finished task 0.0 in stage 221.0 (TID 148) in 18 ms on localhost (executor driver) (3/4)
18/05/31 14:47:07 INFO MemoryStore: 7 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:07 INFO BlockManager: Dropping block rdd_129_3 from memory
18/05/31 14:47:07 INFO BlockManagerInfo: Removed rdd_129_3 on 10.66.169.34:53539 in memory (size: 5.5 KB, free: 354.7 MB)
18/05/31 14:47:07 INFO BlockManager: Dropping block rdd_129_0 from memory
18/05/31 14:47:07 INFO BlockManagerInfo: Removed rdd_129_0 on 10.66.169.34:53539 in memory (size: 5.5 KB, free: 354.7 MB)
18/05/31 14:47:07 INFO BlockManager: Dropping block broadcast_70_piece0 from memory
18/05/31 14:47:07 INFO BlockManager: Writing block broadcast_70_piece0 to disk
18/05/31 14:47:07 INFO BlockManagerInfo: Added broadcast_70_piece0 on disk on 10.66.169.34:53539 (size: 2.8 KB)
18/05/31 14:47:07 INFO BlockManager: Dropping block broadcast_70 from memory
18/05/31 14:47:07 INFO BlockManager: Writing block broadcast_70 to disk
18/05/31 14:47:07 INFO BlockManager: Dropping block rdd_137_0 from memory
18/05/31 14:47:07 INFO BlockManagerInfo: Removed rdd_137_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:07 INFO BlockManager: Dropping block broadcast_71_piece0 from memory
18/05/31 14:47:07 INFO BlockManager: Writing block broadcast_71_piece0 to disk
18/05/31 14:47:07 INFO BlockManagerInfo: Added broadcast_71_piece0 on disk on 10.66.169.34:53539 (size: 4.6 KB)
18/05/31 14:47:07 INFO BlockManager: Dropping block rdd_134_2 from memory
18/05/31 14:47:07 INFO BlockManagerInfo: Removed rdd_134_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:07 INFO MemoryStore: After dropping 7 blocks, free memory is 633.5 MB
18/05/31 14:47:07 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 10.66.169.34:53539 on disk (size: 4.5 KB)
18/05/31 14:47:07 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 10.66.169.34:53539 on disk (size: 2.8 KB)
18/05/31 14:47:07 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 10.66.169.34:53539 on disk (size: 4.6 KB)
18/05/31 14:47:07 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 633.5 MB)
18/05/31 14:47:08 INFO MemoryStore: Block rdd_144_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:08 INFO BlockManagerInfo: Added rdd_144_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:08 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:08 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-112
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:08 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:08 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:08 WARN Executor: 1 block locks were not released by TID = 150:
[rdd_139_2]
18/05/31 14:47:08 INFO Executor: Finished task 2.0 in stage 221.0 (TID 150). 2889 bytes result sent to driver
18/05/31 14:47:08 INFO TaskSetManager: Finished task 2.0 in stage 221.0 (TID 150) in 1612 ms on localhost (executor driver) (4/4)
18/05/31 14:47:08 INFO TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool 
18/05/31 14:47:08 INFO DAGScheduler: ResultStage 221 (foreachPartition at AnomalyDetector.java:69) finished in 1.613 s
18/05/31 14:47:08 INFO DAGScheduler: Job 33 finished: foreachPartition at AnomalyDetector.java:69, took 1.633604 s
18/05/31 14:47:08 INFO JobScheduler: Finished job streaming job 1527767060000 ms.0 from job set of time 1527767060000 ms
18/05/31 14:47:08 INFO JobScheduler: Total delay: 168.120 s for time 1527767060000 ms (execution: 1.637 s)
18/05/31 14:47:08 INFO MapPartitionsRDD: Removing RDD 140 from persistence list
18/05/31 14:47:08 INFO JobScheduler: Starting job streaming job 1527767070000 ms.0 from job set of time 1527767070000 ms
18/05/31 14:47:08 INFO BlockManager: Removing RDD 140
18/05/31 14:47:08 INFO MapWithStateRDD: Removing RDD 44 from persistence list
18/05/31 14:47:08 INFO BlockManager: Removing RDD 44
18/05/31 14:47:08 INFO MapPartitionsRDD: Removing RDD 42 from persistence list
18/05/31 14:47:08 INFO BlockManager: Removing RDD 42
18/05/31 14:47:08 INFO KafkaRDD: Removing RDD 41 from persistence list
18/05/31 14:47:08 INFO BlockManager: Removing RDD 41
18/05/31 14:47:08 INFO JobGenerator: Checkpointing graph for time 1527767060000 ms
18/05/31 14:47:08 INFO DStreamGraph: Updating checkpoint data for time 1527767060000 ms
18/05/31 14:47:08 INFO DStreamGraph: Updated checkpoint data for time 1527767060000 ms
18/05/31 14:47:08 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:08 INFO CheckpointWriter: Submitted checkpoint of time 1527767060000 ms to writer queue
18/05/31 14:47:08 INFO CheckpointWriter: Saving checkpoint for time 1527767060000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000'
18/05/31 14:47:08 INFO DAGScheduler: Registering RDD 147 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 149 bytes
18/05/31 14:47:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 149 bytes
18/05/31 14:47:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 149 bytes
18/05/31 14:47:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 149 bytes
18/05/31 14:47:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 149 bytes
18/05/31 14:47:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 29 is 149 bytes
18/05/31 14:47:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 149 bytes
18/05/31 14:47:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 28 is 149 bytes
18/05/31 14:47:08 INFO DAGScheduler: Got job 34 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:08 INFO DAGScheduler: Final stage: ResultStage 231 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 230, ShuffleMapStage 222, ShuffleMapStage 223, ShuffleMapStage 227, ShuffleMapStage 224, ShuffleMapStage 228, ShuffleMapStage 225, ShuffleMapStage 229, ShuffleMapStage 226)
18/05/31 14:47:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 222)
18/05/31 14:47:08 INFO DAGScheduler: Submitting ShuffleMapStage 222 (MapPartitionsRDD[147] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:08 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:47:08 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.7 MB)
18/05/31 14:47:08 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:08 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 222 (MapPartitionsRDD[147] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:08 INFO TaskSchedulerImpl: Adding task set 222.0 with 1 tasks
18/05/31 14:47:08 INFO TaskSetManager: Starting task 0.0 in stage 222.0 (TID 152, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:08 INFO Executor: Running task 0.0 in stage 222.0 (TID 152)
18/05/31 14:47:08 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:08 INFO MemoryStore: Block rdd_147_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:47:08 INFO BlockManagerInfo: Added rdd_147_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:08 INFO Executor: Finished task 0.0 in stage 222.0 (TID 152). 1708 bytes result sent to driver
18/05/31 14:47:08 INFO CheckpointWriter: Checkpoint for time 1527767060000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000', took 6166 bytes and 20 ms
18/05/31 14:47:08 INFO DStreamGraph: Clearing checkpoint data for time 1527767060000 ms
18/05/31 14:47:08 INFO DStreamGraph: Cleared checkpoint data for time 1527767060000 ms
18/05/31 14:47:08 INFO TaskSetManager: Finished task 0.0 in stage 222.0 (TID 152) in 6 ms on localhost (executor driver) (1/1)
18/05/31 14:47:08 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:08 INFO TaskSchedulerImpl: Removed TaskSet 222.0, whose tasks have all completed, from pool 
18/05/31 14:47:08 INFO DAGScheduler: ShuffleMapStage 222 (mapToPair at AnomalyDetector.java:64) finished in 0.006 s
18/05/31 14:47:08 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:08 INFO DAGScheduler: running: Set()
18/05/31 14:47:08 INFO DAGScheduler: waiting: Set(ResultStage 231)
18/05/31 14:47:08 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766860000: 
18/05/31 14:47:08 INFO DAGScheduler: failed: Set()
18/05/31 14:47:08 INFO InputInfoTracker: remove old batch metadata: 1527766850000 ms
18/05/31 14:47:08 INFO DAGScheduler: Submitting ResultStage 231 (MapPartitionsRDD[150] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:08 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 10.0 KB, free 354.7 MB)
18/05/31 14:47:08 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.7 KB, free 354.7 MB)
18/05/31 14:47:08 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 10.66.169.34:53539 (size: 4.7 KB, free: 354.7 MB)
18/05/31 14:47:08 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:08 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 231 (MapPartitionsRDD[150] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:08 INFO TaskSchedulerImpl: Adding task set 231.0 with 4 tasks
18/05/31 14:47:08 INFO TaskSetManager: Starting task 0.0 in stage 231.0 (TID 153, localhost, executor driver, partition 0, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:08 INFO TaskSetManager: Starting task 1.0 in stage 231.0 (TID 154, localhost, executor driver, partition 1, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:08 INFO TaskSetManager: Starting task 2.0 in stage 231.0 (TID 155, localhost, executor driver, partition 2, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:08 INFO TaskSetManager: Starting task 3.0 in stage 231.0 (TID 156, localhost, executor driver, partition 3, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:08 INFO Executor: Running task 0.0 in stage 231.0 (TID 153)
18/05/31 14:47:08 INFO Executor: Running task 1.0 in stage 231.0 (TID 154)
18/05/31 14:47:08 INFO Executor: Running task 2.0 in stage 231.0 (TID 155)
18/05/31 14:47:08 INFO Executor: Running task 3.0 in stage 231.0 (TID 156)
18/05/31 14:47:08 INFO BlockManager: Found block rdd_144_0 locally
18/05/31 14:47:08 INFO BlockManager: Found block rdd_144_2 locally
18/05/31 14:47:08 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:08 INFO BlockManager: Found block rdd_144_1 locally
18/05/31 14:47:08 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:08 INFO MemoryStore: Block rdd_149_0 stored as values in memory (estimated size 8.6 KB, free 354.7 MB)
18/05/31 14:47:08 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:08 INFO MemoryStore: Block rdd_149_1 stored as values in memory (estimated size 8.6 KB, free 354.7 MB)
18/05/31 14:47:08 INFO BlockManagerInfo: Added rdd_149_0 in memory on 10.66.169.34:53539 (size: 8.6 KB, free: 354.7 MB)
18/05/31 14:47:08 INFO BlockManager: Found block rdd_144_3 locally
18/05/31 14:47:08 INFO BlockManagerInfo: Added rdd_149_1 in memory on 10.66.169.34:53539 (size: 8.6 KB, free: 354.7 MB)
18/05/31 14:47:08 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:08 INFO MemoryStore: Block rdd_149_3 stored as values in memory (estimated size 8.6 KB, free 354.7 MB)
18/05/31 14:47:08 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:08 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:08 INFO BlockManagerInfo: Added rdd_149_3 in memory on 10.66.169.34:53539 (size: 8.6 KB, free: 354.7 MB)
18/05/31 14:47:08 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:08 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-114
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:08 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:08 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:08 WARN Executor: 1 block locks were not released by TID = 154:
[rdd_144_1]
18/05/31 14:47:08 INFO Executor: Finished task 1.0 in stage 231.0 (TID 154). 2359 bytes result sent to driver
18/05/31 14:47:08 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-113
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:08 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:08 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:08 INFO TaskSetManager: Finished task 1.0 in stage 231.0 (TID 154) in 14 ms on localhost (executor driver) (1/4)
18/05/31 14:47:08 WARN Executor: 1 block locks were not released by TID = 153:
[rdd_144_0]
18/05/31 14:47:08 INFO Executor: Finished task 0.0 in stage 231.0 (TID 153). 2359 bytes result sent to driver
18/05/31 14:47:08 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-115
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:08 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:08 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:08 WARN Executor: 1 block locks were not released by TID = 156:
[rdd_144_3]
18/05/31 14:47:08 INFO TaskSetManager: Finished task 0.0 in stage 231.0 (TID 153) in 16 ms on localhost (executor driver) (2/4)
18/05/31 14:47:08 INFO Executor: Finished task 3.0 in stage 231.0 (TID 156). 2359 bytes result sent to driver
18/05/31 14:47:08 INFO TaskSetManager: Finished task 3.0 in stage 231.0 (TID 156) in 16 ms on localhost (executor driver) (3/4)
18/05/31 14:47:08 INFO MemoryStore: 6 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:08 INFO BlockManager: Dropping block rdd_134_1 from memory
18/05/31 14:47:08 INFO BlockManagerInfo: Removed rdd_134_1 on 10.66.169.34:53539 in memory (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:08 INFO BlockManager: Dropping block rdd_134_3 from memory
18/05/31 14:47:08 INFO BlockManagerInfo: Removed rdd_134_3 on 10.66.169.34:53539 in memory (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:08 INFO BlockManager: Dropping block rdd_134_0 from memory
18/05/31 14:47:08 INFO BlockManagerInfo: Removed rdd_134_0 on 10.66.169.34:53539 in memory (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:08 INFO BlockManager: Dropping block rdd_142_0 from memory
18/05/31 14:47:08 INFO BlockManagerInfo: Removed rdd_142_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:08 INFO BlockManager: Dropping block broadcast_73_piece0 from memory
18/05/31 14:47:08 INFO BlockManager: Writing block broadcast_73_piece0 to disk
18/05/31 14:47:08 INFO BlockManagerInfo: Added broadcast_73_piece0 on disk on 10.66.169.34:53539 (size: 4.6 KB)
18/05/31 14:47:08 INFO BlockManager: Dropping block rdd_139_2 from memory
18/05/31 14:47:08 INFO BlockManagerInfo: Removed rdd_139_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:08 INFO MemoryStore: After dropping 6 blocks, free memory is 633.4 MB
18/05/31 14:47:09 INFO MemoryStore: Block rdd_149_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:09 INFO BlockManagerInfo: Added rdd_149_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:09 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:09 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-116
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:09 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:09 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:09 WARN Executor: 1 block locks were not released by TID = 155:
[rdd_144_2]
18/05/31 14:47:09 INFO Executor: Finished task 2.0 in stage 231.0 (TID 155). 2757 bytes result sent to driver
18/05/31 14:47:09 INFO TaskSetManager: Finished task 2.0 in stage 231.0 (TID 155) in 1598 ms on localhost (executor driver) (4/4)
18/05/31 14:47:09 INFO TaskSchedulerImpl: Removed TaskSet 231.0, whose tasks have all completed, from pool 
18/05/31 14:47:09 INFO DAGScheduler: ResultStage 231 (foreachPartition at AnomalyDetector.java:69) finished in 1.600 s
18/05/31 14:47:09 INFO DAGScheduler: Job 34 finished: foreachPartition at AnomalyDetector.java:69, took 1.623860 s
18/05/31 14:47:09 INFO JobScheduler: Finished job streaming job 1527767070000 ms.0 from job set of time 1527767070000 ms
18/05/31 14:47:09 INFO JobScheduler: Total delay: 159.748 s for time 1527767070000 ms (execution: 1.628 s)
18/05/31 14:47:09 INFO MapPartitionsRDD: Removing RDD 145 from persistence list
18/05/31 14:47:09 INFO JobScheduler: Starting job streaming job 1527767080000 ms.0 from job set of time 1527767080000 ms
18/05/31 14:47:09 INFO BlockManager: Removing RDD 145
18/05/31 14:47:09 INFO MapWithStateRDD: Removing RDD 49 from persistence list
18/05/31 14:47:09 INFO BlockManager: Removing RDD 49
18/05/31 14:47:09 INFO MapPartitionsRDD: Removing RDD 47 from persistence list
18/05/31 14:47:09 INFO BlockManager: Removing RDD 47
18/05/31 14:47:09 INFO KafkaRDD: Removing RDD 46 from persistence list
18/05/31 14:47:09 INFO BlockManager: Removing RDD 46
18/05/31 14:47:09 INFO JobGenerator: Checkpointing graph for time 1527767070000 ms
18/05/31 14:47:09 INFO DStreamGraph: Updating checkpoint data for time 1527767070000 ms
18/05/31 14:47:09 INFO DStreamGraph: Updated checkpoint data for time 1527767070000 ms
18/05/31 14:47:09 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:09 INFO CheckpointWriter: Submitted checkpoint of time 1527767070000 ms to writer queue
18/05/31 14:47:09 INFO CheckpointWriter: Saving checkpoint for time 1527767070000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000'
18/05/31 14:47:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 30 is 149 bytes
18/05/31 14:47:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 149 bytes
18/05/31 14:47:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 149 bytes
18/05/31 14:47:09 INFO DAGScheduler: Registering RDD 152 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 149 bytes
18/05/31 14:47:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 149 bytes
18/05/31 14:47:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 149 bytes
18/05/31 14:47:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 29 is 149 bytes
18/05/31 14:47:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 149 bytes
18/05/31 14:47:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 28 is 149 bytes
18/05/31 14:47:09 INFO DAGScheduler: Got job 35 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:09 INFO DAGScheduler: Final stage: ResultStage 242 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 233, ShuffleMapStage 237, ShuffleMapStage 234, ShuffleMapStage 241, ShuffleMapStage 238, ShuffleMapStage 235, ShuffleMapStage 239, ShuffleMapStage 240, ShuffleMapStage 232, ShuffleMapStage 236)
18/05/31 14:47:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 235)
18/05/31 14:47:09 INFO DAGScheduler: Submitting ShuffleMapStage 235 (MapPartitionsRDD[152] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:09 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 5.9 KB, free 354.7 MB)
18/05/31 14:47:09 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.7 MB)
18/05/31 14:47:09 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:09 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 235 (MapPartitionsRDD[152] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:09 INFO TaskSchedulerImpl: Adding task set 235.0 with 1 tasks
18/05/31 14:47:09 INFO TaskSetManager: Starting task 0.0 in stage 235.0 (TID 157, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:09 INFO Executor: Running task 0.0 in stage 235.0 (TID 157)
18/05/31 14:47:09 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:09 INFO MemoryStore: Block rdd_152_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:47:09 INFO BlockManagerInfo: Added rdd_152_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:09 INFO Executor: Finished task 0.0 in stage 235.0 (TID 157). 1708 bytes result sent to driver
18/05/31 14:47:09 INFO CheckpointWriter: Checkpoint for time 1527767070000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000', took 6138 bytes and 17 ms
18/05/31 14:47:09 INFO TaskSetManager: Finished task 0.0 in stage 235.0 (TID 157) in 7 ms on localhost (executor driver) (1/1)
18/05/31 14:47:09 INFO DStreamGraph: Clearing checkpoint data for time 1527767070000 ms
18/05/31 14:47:09 INFO TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool 
18/05/31 14:47:09 INFO DStreamGraph: Cleared checkpoint data for time 1527767070000 ms
18/05/31 14:47:09 INFO DAGScheduler: ShuffleMapStage 235 (mapToPair at AnomalyDetector.java:64) finished in 0.007 s
18/05/31 14:47:09 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:09 INFO DAGScheduler: running: Set()
18/05/31 14:47:09 INFO DAGScheduler: waiting: Set(ResultStage 242)
18/05/31 14:47:09 INFO DAGScheduler: failed: Set()
18/05/31 14:47:09 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:09 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766870000: 
18/05/31 14:47:09 INFO InputInfoTracker: remove old batch metadata: 1527766860000 ms
18/05/31 14:47:09 INFO DAGScheduler: Submitting ResultStage 242 (MapPartitionsRDD[155] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:09 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 10.5 KB, free 354.7 MB)
18/05/31 14:47:09 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 4.8 KB, free 354.7 MB)
18/05/31 14:47:09 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 10.66.169.34:53539 (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:47:09 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:09 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 242 (MapPartitionsRDD[155] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:09 INFO TaskSchedulerImpl: Adding task set 242.0 with 4 tasks
18/05/31 14:47:09 INFO TaskSetManager: Starting task 0.0 in stage 242.0 (TID 158, localhost, executor driver, partition 0, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:47:09 INFO TaskSetManager: Starting task 1.0 in stage 242.0 (TID 159, localhost, executor driver, partition 1, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:47:09 INFO TaskSetManager: Starting task 2.0 in stage 242.0 (TID 160, localhost, executor driver, partition 2, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:47:09 INFO TaskSetManager: Starting task 3.0 in stage 242.0 (TID 161, localhost, executor driver, partition 3, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:47:09 INFO Executor: Running task 0.0 in stage 242.0 (TID 158)
18/05/31 14:47:09 INFO Executor: Running task 1.0 in stage 242.0 (TID 159)
18/05/31 14:47:09 INFO Executor: Running task 2.0 in stage 242.0 (TID 160)
18/05/31 14:47:09 INFO Executor: Running task 3.0 in stage 242.0 (TID 161)
18/05/31 14:47:09 INFO BlockManager: Found block rdd_149_0 locally
18/05/31 14:47:09 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:09 INFO BlockManager: Found block rdd_149_1 locally
18/05/31 14:47:09 INFO MemoryStore: Block rdd_154_0 stored as values in memory (estimated size 9.4 KB, free 354.7 MB)
18/05/31 14:47:09 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:47:09 INFO MemoryStore: Block rdd_154_1 stored as values in memory (estimated size 9.4 KB, free 354.6 MB)
18/05/31 14:47:09 INFO BlockManager: Found block rdd_149_2 locally
18/05/31 14:47:09 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:09 INFO BlockManagerInfo: Added rdd_154_0 in memory on 10.66.169.34:53539 (size: 9.4 KB, free: 354.7 MB)
18/05/31 14:47:09 INFO BlockManagerInfo: Added rdd_154_1 in memory on 10.66.169.34:53539 (size: 9.4 KB, free: 354.7 MB)
18/05/31 14:47:09 INFO BlockManager: Found block rdd_149_3 locally
18/05/31 14:47:09 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:09 INFO MemoryStore: Block rdd_154_3 stored as values in memory (estimated size 9.4 KB, free 354.6 MB)
18/05/31 14:47:09 INFO BlockManagerInfo: Added rdd_154_3 in memory on 10.66.169.34:53539 (size: 9.4 KB, free: 354.7 MB)
18/05/31 14:47:09 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:09 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:09 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-117
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:09 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:09 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:09 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-118
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:09 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:09 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:09 WARN Executor: 1 block locks were not released by TID = 161:
[rdd_149_3]
18/05/31 14:47:09 WARN Executor: 1 block locks were not released by TID = 159:
[rdd_149_1]
18/05/31 14:47:09 INFO Executor: Finished task 3.0 in stage 242.0 (TID 161). 2359 bytes result sent to driver
18/05/31 14:47:09 INFO Executor: Finished task 1.0 in stage 242.0 (TID 159). 2359 bytes result sent to driver
18/05/31 14:47:09 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:09 INFO TaskSetManager: Finished task 3.0 in stage 242.0 (TID 161) in 14 ms on localhost (executor driver) (1/4)
18/05/31 14:47:09 INFO TaskSetManager: Finished task 1.0 in stage 242.0 (TID 159) in 15 ms on localhost (executor driver) (2/4)
18/05/31 14:47:09 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-119
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:09 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:09 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:09 WARN Executor: 1 block locks were not released by TID = 158:
[rdd_149_0]
18/05/31 14:47:09 INFO Executor: Finished task 0.0 in stage 242.0 (TID 158). 2359 bytes result sent to driver
18/05/31 14:47:09 INFO TaskSetManager: Finished task 0.0 in stage 242.0 (TID 158) in 19 ms on localhost (executor driver) (3/4)
18/05/31 14:47:10 INFO JobScheduler: Added jobs for time 1527767230000 ms
18/05/31 14:47:10 INFO JobGenerator: Checkpointing graph for time 1527767230000 ms
18/05/31 14:47:10 INFO DStreamGraph: Updating checkpoint data for time 1527767230000 ms
18/05/31 14:47:10 INFO DStreamGraph: Updated checkpoint data for time 1527767230000 ms
18/05/31 14:47:10 INFO CheckpointWriter: Submitted checkpoint of time 1527767230000 ms to writer queue
18/05/31 14:47:10 INFO CheckpointWriter: Saving checkpoint for time 1527767230000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767230000'
18/05/31 14:47:10 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767180000.bk
18/05/31 14:47:10 INFO CheckpointWriter: Checkpoint for time 1527767230000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767230000', took 6153 bytes and 12 ms
18/05/31 14:47:10 INFO MemoryStore: 11 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:10 INFO BlockManager: Dropping block rdd_139_1 from memory
18/05/31 14:47:10 INFO BlockManagerInfo: Removed rdd_139_1 on 10.66.169.34:53539 in memory (size: 7.1 KB, free: 354.7 MB)
18/05/31 14:47:10 INFO BlockManager: Dropping block rdd_139_3 from memory
18/05/31 14:47:10 INFO BlockManagerInfo: Removed rdd_139_3 on 10.66.169.34:53539 in memory (size: 7.1 KB, free: 354.7 MB)
18/05/31 14:47:10 INFO BlockManager: Dropping block broadcast_73 from memory
18/05/31 14:47:10 INFO BlockManager: Writing block broadcast_73 to disk
18/05/31 14:47:10 INFO BlockManager: Dropping block rdd_139_0 from memory
18/05/31 14:47:10 INFO BlockManagerInfo: Removed rdd_139_0 on 10.66.169.34:53539 in memory (size: 7.1 KB, free: 354.7 MB)
18/05/31 14:47:10 INFO BlockManager: Dropping block broadcast_74_piece0 from memory
18/05/31 14:47:10 INFO BlockManager: Writing block broadcast_74_piece0 to disk
18/05/31 14:47:10 INFO BlockManagerInfo: Added broadcast_74_piece0 on disk on 10.66.169.34:53539 (size: 2.8 KB)
18/05/31 14:47:10 INFO BlockManager: Dropping block broadcast_74 from memory
18/05/31 14:47:10 INFO BlockManager: Writing block broadcast_74 to disk
18/05/31 14:47:10 INFO BlockManager: Dropping block rdd_147_0 from memory
18/05/31 14:47:10 INFO BlockManagerInfo: Removed rdd_147_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:10 INFO BlockManager: Dropping block broadcast_75_piece0 from memory
18/05/31 14:47:10 INFO BlockManager: Writing block broadcast_75_piece0 to disk
18/05/31 14:47:10 INFO BlockManagerInfo: Added broadcast_75_piece0 on disk on 10.66.169.34:53539 (size: 4.7 KB)
18/05/31 14:47:10 INFO BlockManager: Dropping block broadcast_75 from memory
18/05/31 14:47:10 INFO BlockManager: Writing block broadcast_75 to disk
18/05/31 14:47:10 INFO BlockManager: Dropping block rdd_144_0 from memory
18/05/31 14:47:10 INFO BlockManagerInfo: Removed rdd_144_0 on 10.66.169.34:53539 in memory (size: 7.8 KB, free: 354.7 MB)
18/05/31 14:47:10 INFO BlockManager: Dropping block rdd_144_2 from memory
18/05/31 14:47:10 INFO BlockManagerInfo: Removed rdd_144_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:10 INFO MemoryStore: After dropping 11 blocks, free memory is 633.5 MB
18/05/31 14:47:10 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 10.66.169.34:53539 on disk (size: 4.6 KB)
18/05/31 14:47:10 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 10.66.169.34:53539 on disk (size: 2.8 KB)
18/05/31 14:47:10 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 10.66.169.34:53539 on disk (size: 4.7 KB)
18/05/31 14:47:10 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 633.5 MB)
18/05/31 14:47:11 INFO MemoryStore: Block rdd_154_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:11 INFO BlockManagerInfo: Added rdd_154_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:11 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:11 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-120
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:11 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:11 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:11 WARN Executor: 1 block locks were not released by TID = 160:
[rdd_149_2]
18/05/31 14:47:11 INFO Executor: Finished task 2.0 in stage 242.0 (TID 160). 3087 bytes result sent to driver
18/05/31 14:47:11 INFO TaskSetManager: Finished task 2.0 in stage 242.0 (TID 160) in 1829 ms on localhost (executor driver) (4/4)
18/05/31 14:47:11 INFO TaskSchedulerImpl: Removed TaskSet 242.0, whose tasks have all completed, from pool 
18/05/31 14:47:11 INFO DAGScheduler: ResultStage 242 (foreachPartition at AnomalyDetector.java:69) finished in 1.831 s
18/05/31 14:47:11 INFO DAGScheduler: Job 35 finished: foreachPartition at AnomalyDetector.java:69, took 1.854943 s
18/05/31 14:47:11 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 127.1 KB, free 354.6 MB)
18/05/31 14:47:11 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.6 MB)
18/05/31 14:47:11 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:11 INFO SparkContext: Created broadcast 78 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:11 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:11 INFO DAGScheduler: Got job 36 (foreachPartition at AnomalyDetector.java:69) with 1 output partitions
18/05/31 14:47:11 INFO DAGScheduler: Final stage: ResultStage 243 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:11 INFO DAGScheduler: Parents of final stage: List()
18/05/31 14:47:11 INFO DAGScheduler: Missing parents: List()
18/05/31 14:47:11 INFO DAGScheduler: Submitting ResultStage 243 (MapPartitionsRDD[152] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:11 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 6.1 KB, free 354.6 MB)
18/05/31 14:47:11 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.6 MB)
18/05/31 14:47:11 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:11 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 243 (MapPartitionsRDD[152] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:11 INFO TaskSchedulerImpl: Adding task set 243.0 with 1 tasks
18/05/31 14:47:11 INFO TaskSetManager: Starting task 0.0 in stage 243.0 (TID 162, localhost, executor driver, partition 0, PROCESS_LOCAL, 6166 bytes)
18/05/31 14:47:11 INFO Executor: Running task 0.0 in stage 243.0 (TID 162)
18/05/31 14:47:11 INFO BlockManager: Found block rdd_152_0 locally
18/05/31 14:47:11 INFO Executor: Finished task 0.0 in stage 243.0 (TID 162). 1004 bytes result sent to driver
18/05/31 14:47:11 INFO DAGScheduler: ResultStage 243 (foreachPartition at AnomalyDetector.java:69) finished in 0.020 s
18/05/31 14:47:11 INFO TaskSetManager: Finished task 0.0 in stage 243.0 (TID 162) in 20 ms on localhost (executor driver) (1/1)
18/05/31 14:47:11 INFO TaskSchedulerImpl: Removed TaskSet 243.0, whose tasks have all completed, from pool 
18/05/31 14:47:11 INFO DAGScheduler: Job 36 finished: foreachPartition at AnomalyDetector.java:69, took 0.029059 s
18/05/31 14:47:11 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 127.1 KB, free 354.4 MB)
18/05/31 14:47:11 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.4 MB)
18/05/31 14:47:11 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:11 INFO SparkContext: Created broadcast 80 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:11 INFO ReliableRDDCheckpointData: Done checkpointing RDD 152 to file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-152, new parent is RDD 237
18/05/31 14:47:11 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 127.1 KB, free 354.3 MB)
18/05/31 14:47:11 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.3 MB)
18/05/31 14:47:11 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:11 INFO SparkContext: Created broadcast 81 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:11 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 30 is 149 bytes
18/05/31 14:47:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 149 bytes
18/05/31 14:47:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 149 bytes
18/05/31 14:47:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 31 is 149 bytes
18/05/31 14:47:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 149 bytes
18/05/31 14:47:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 149 bytes
18/05/31 14:47:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 149 bytes
18/05/31 14:47:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 29 is 149 bytes
18/05/31 14:47:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 149 bytes
18/05/31 14:47:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 28 is 149 bytes
18/05/31 14:47:11 INFO DAGScheduler: Got job 37 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:11 INFO DAGScheduler: Final stage: ResultStage 254 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 251, ShuffleMapStage 248, ShuffleMapStage 252, ShuffleMapStage 249, ShuffleMapStage 253, ShuffleMapStage 245, ShuffleMapStage 246, ShuffleMapStage 250, ShuffleMapStage 247, ShuffleMapStage 244)
18/05/31 14:47:11 INFO DAGScheduler: Missing parents: List()
18/05/31 14:47:11 INFO DAGScheduler: Submitting ResultStage 254 (MapWithStateRDD[154] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:11 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 10.0 KB, free 354.3 MB)
18/05/31 14:47:11 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.3 MB)
18/05/31 14:47:11 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 10.66.169.34:53539 (size: 4.5 KB, free: 354.7 MB)
18/05/31 14:47:11 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:11 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 254 (MapWithStateRDD[154] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:11 INFO TaskSchedulerImpl: Adding task set 254.0 with 4 tasks
18/05/31 14:47:11 INFO TaskSetManager: Starting task 0.0 in stage 254.0 (TID 163, localhost, executor driver, partition 0, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:47:11 INFO TaskSetManager: Starting task 1.0 in stage 254.0 (TID 164, localhost, executor driver, partition 1, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:47:11 INFO TaskSetManager: Starting task 2.0 in stage 254.0 (TID 165, localhost, executor driver, partition 2, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:47:11 INFO TaskSetManager: Starting task 3.0 in stage 254.0 (TID 166, localhost, executor driver, partition 3, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:47:11 INFO Executor: Running task 1.0 in stage 254.0 (TID 164)
18/05/31 14:47:11 INFO Executor: Running task 3.0 in stage 254.0 (TID 166)
18/05/31 14:47:11 INFO Executor: Running task 2.0 in stage 254.0 (TID 165)
18/05/31 14:47:11 INFO BlockManager: Found block rdd_154_1 locally
18/05/31 14:47:11 INFO BlockManager: Found block rdd_154_3 locally
18/05/31 14:47:11 INFO BlockManager: Found block rdd_154_2 locally
18/05/31 14:47:11 INFO Executor: Running task 0.0 in stage 254.0 (TID 163)
18/05/31 14:47:11 INFO BlockManager: Found block rdd_154_0 locally
18/05/31 14:47:11 INFO Executor: Finished task 3.0 in stage 254.0 (TID 166). 1085 bytes result sent to driver
18/05/31 14:47:11 INFO Executor: Finished task 1.0 in stage 254.0 (TID 164). 1085 bytes result sent to driver
18/05/31 14:47:11 INFO TaskSetManager: Finished task 3.0 in stage 254.0 (TID 166) in 26 ms on localhost (executor driver) (1/4)
18/05/31 14:47:11 INFO TaskSetManager: Finished task 1.0 in stage 254.0 (TID 164) in 28 ms on localhost (executor driver) (2/4)
18/05/31 14:47:11 INFO Executor: Finished task 0.0 in stage 254.0 (TID 163). 1085 bytes result sent to driver
18/05/31 14:47:11 INFO TaskSetManager: Finished task 0.0 in stage 254.0 (TID 163) in 116 ms on localhost (executor driver) (3/4)
18/05/31 14:47:14 INFO Executor: Finished task 2.0 in stage 254.0 (TID 165). 1085 bytes result sent to driver
18/05/31 14:47:14 INFO TaskSetManager: Finished task 2.0 in stage 254.0 (TID 165) in 3163 ms on localhost (executor driver) (4/4)
18/05/31 14:47:14 INFO TaskSchedulerImpl: Removed TaskSet 254.0, whose tasks have all completed, from pool 
18/05/31 14:47:14 INFO DAGScheduler: ResultStage 254 (foreachPartition at AnomalyDetector.java:69) finished in 3.165 s
18/05/31 14:47:14 INFO DAGScheduler: Job 37 finished: foreachPartition at AnomalyDetector.java:69, took 3.174869 s
18/05/31 14:47:14 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 127.1 KB, free 354.1 MB)
18/05/31 14:47:14 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.1 MB)
18/05/31 14:47:14 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:47:14 INFO SparkContext: Created broadcast 83 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:14 INFO ReliableRDDCheckpointData: Done checkpointing RDD 154 to file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-154, new parent is RDD 238
18/05/31 14:47:14 INFO JobScheduler: Finished job streaming job 1527767080000 ms.0 from job set of time 1527767080000 ms
18/05/31 14:47:14 INFO JobScheduler: Total delay: 154.961 s for time 1527767080000 ms (execution: 5.213 s)
18/05/31 14:47:14 INFO JobScheduler: Starting job streaming job 1527767090000 ms.0 from job set of time 1527767090000 ms
18/05/31 14:47:14 INFO MapPartitionsRDD: Removing RDD 150 from persistence list
18/05/31 14:47:14 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:14 INFO BlockManager: Removing RDD 150
18/05/31 14:47:14 INFO MapWithStateRDD: Removing RDD 54 from persistence list
18/05/31 14:47:14 INFO DAGScheduler: Registering RDD 157 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:14 INFO DAGScheduler: Got job 38 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:14 INFO DAGScheduler: Final stage: ResultStage 256 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 255)
18/05/31 14:47:14 INFO MapPartitionsRDD: Removing RDD 52 from persistence list
18/05/31 14:47:14 INFO BlockManager: Removing RDD 54
18/05/31 14:47:14 INFO BlockManager: Removing RDD 52
18/05/31 14:47:14 INFO KafkaRDD: Removing RDD 51 from persistence list
18/05/31 14:47:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 255)
18/05/31 14:47:14 INFO JobGenerator: Checkpointing graph for time 1527767080000 ms
18/05/31 14:47:14 INFO DStreamGraph: Updating checkpoint data for time 1527767080000 ms
18/05/31 14:47:14 INFO DStreamGraph: Updated checkpoint data for time 1527767080000 ms
18/05/31 14:47:14 INFO CheckpointWriter: Submitted checkpoint of time 1527767080000 ms to writer queue
18/05/31 14:47:14 INFO CheckpointWriter: Saving checkpoint for time 1527767080000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767230000'
18/05/31 14:47:14 INFO DAGScheduler: Submitting ShuffleMapStage 255 (MapPartitionsRDD[157] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:14 INFO BlockManager: Removing RDD 51
18/05/31 14:47:14 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 4.6 KB, free 354.1 MB)
18/05/31 14:47:14 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.1 MB)
18/05/31 14:47:14 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:47:14 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 255 (MapPartitionsRDD[157] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:14 INFO TaskSchedulerImpl: Adding task set 255.0 with 1 tasks
18/05/31 14:47:14 INFO TaskSetManager: Starting task 0.0 in stage 255.0 (TID 167, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:14 INFO Executor: Running task 0.0 in stage 255.0 (TID 167)
18/05/31 14:47:14 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:14 INFO MemoryStore: Block rdd_157_0 stored as bytes in memory (estimated size 4.0 B, free 354.1 MB)
18/05/31 14:47:14 INFO BlockManagerInfo: Added rdd_157_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.6 MB)
18/05/31 14:47:14 INFO Executor: Finished task 0.0 in stage 255.0 (TID 167). 1708 bytes result sent to driver
18/05/31 14:47:14 INFO TaskSetManager: Finished task 0.0 in stage 255.0 (TID 167) in 7 ms on localhost (executor driver) (1/1)
18/05/31 14:47:14 INFO TaskSchedulerImpl: Removed TaskSet 255.0, whose tasks have all completed, from pool 
18/05/31 14:47:14 INFO DAGScheduler: ShuffleMapStage 255 (mapToPair at AnomalyDetector.java:64) finished in 0.008 s
18/05/31 14:47:14 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:14 INFO DAGScheduler: running: Set()
18/05/31 14:47:14 INFO DAGScheduler: waiting: Set(ResultStage 256)
18/05/31 14:47:14 INFO DAGScheduler: failed: Set()
18/05/31 14:47:14 INFO DAGScheduler: Submitting ResultStage 256 (MapPartitionsRDD[160] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:14 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 7.8 KB, free 354.1 MB)
18/05/31 14:47:14 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767180000
18/05/31 14:47:14 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 4.2 KB, free 354.1 MB)
18/05/31 14:47:14 INFO CheckpointWriter: Checkpoint for time 1527767080000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767230000', took 6149 bytes and 27 ms
18/05/31 14:47:14 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 10.66.169.34:53539 (size: 4.2 KB, free: 354.6 MB)
18/05/31 14:47:14 INFO DStreamGraph: Clearing checkpoint data for time 1527767080000 ms
18/05/31 14:47:14 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 256 (MapPartitionsRDD[160] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:14 INFO TaskSchedulerImpl: Adding task set 256.0 with 4 tasks
18/05/31 14:47:15 INFO TaskSetManager: Starting task 0.0 in stage 256.0 (TID 168, localhost, executor driver, partition 0, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:47:15 INFO TaskSetManager: Starting task 1.0 in stage 256.0 (TID 169, localhost, executor driver, partition 1, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:47:15 INFO TaskSetManager: Starting task 2.0 in stage 256.0 (TID 170, localhost, executor driver, partition 2, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:47:15 INFO DStreamCheckpointData: Deleted checkpoint file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-54' for time 1527766880000 ms
18/05/31 14:47:15 INFO TaskSetManager: Starting task 3.0 in stage 256.0 (TID 171, localhost, executor driver, partition 3, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:47:15 INFO DStreamGraph: Cleared checkpoint data for time 1527767080000 ms
18/05/31 14:47:15 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:15 INFO Executor: Running task 0.0 in stage 256.0 (TID 168)
18/05/31 14:47:15 INFO Executor: Running task 2.0 in stage 256.0 (TID 170)
18/05/31 14:47:15 INFO Executor: Running task 1.0 in stage 256.0 (TID 169)
18/05/31 14:47:15 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766880000: 
18/05/31 14:47:15 INFO InputInfoTracker: remove old batch metadata: 1527766870000 ms
18/05/31 14:47:15 INFO Executor: Running task 3.0 in stage 256.0 (TID 171)
18/05/31 14:47:15 INFO BlockManager: Found block rdd_154_1 locally
18/05/31 14:47:15 INFO BlockManager: Found block rdd_154_2 locally
18/05/31 14:47:15 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:15 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:15 INFO MemoryStore: Block rdd_159_1 stored as values in memory (estimated size 10.1 KB, free 354.1 MB)
18/05/31 14:47:15 INFO BlockManager: Found block rdd_154_3 locally
18/05/31 14:47:15 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:15 INFO MemoryStore: Block rdd_159_3 stored as values in memory (estimated size 10.1 KB, free 354.1 MB)
18/05/31 14:47:15 INFO BlockManager: Found block rdd_154_0 locally
18/05/31 14:47:15 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:15 INFO MemoryStore: Block rdd_159_0 stored as values in memory (estimated size 10.1 KB, free 354.1 MB)
18/05/31 14:47:15 INFO BlockManagerInfo: Added rdd_159_1 in memory on 10.66.169.34:53539 (size: 10.1 KB, free: 354.6 MB)
18/05/31 14:47:15 INFO BlockManagerInfo: Added rdd_159_3 in memory on 10.66.169.34:53539 (size: 10.1 KB, free: 354.6 MB)
18/05/31 14:47:15 INFO BlockManagerInfo: Added rdd_159_0 in memory on 10.66.169.34:53539 (size: 10.1 KB, free: 354.6 MB)
18/05/31 14:47:15 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:15 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:15 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:15 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-122
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:15 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:15 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:15 WARN Executor: 1 block locks were not released by TID = 171:
[rdd_154_3]
18/05/31 14:47:15 INFO Executor: Finished task 3.0 in stage 256.0 (TID 171). 2359 bytes result sent to driver
18/05/31 14:47:15 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-123
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:15 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:15 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:15 WARN Executor: 1 block locks were not released by TID = 168:
[rdd_154_0]
18/05/31 14:47:15 INFO TaskSetManager: Finished task 3.0 in stage 256.0 (TID 171) in 26 ms on localhost (executor driver) (1/4)
18/05/31 14:47:15 INFO Executor: Finished task 0.0 in stage 256.0 (TID 168). 2359 bytes result sent to driver
18/05/31 14:47:15 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-121
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:15 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:15 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:15 WARN Executor: 1 block locks were not released by TID = 169:
[rdd_154_1]
18/05/31 14:47:15 INFO Executor: Finished task 1.0 in stage 256.0 (TID 169). 2359 bytes result sent to driver
18/05/31 14:47:15 INFO TaskSetManager: Finished task 0.0 in stage 256.0 (TID 168) in 28 ms on localhost (executor driver) (2/4)
18/05/31 14:47:15 INFO TaskSetManager: Finished task 1.0 in stage 256.0 (TID 169) in 29 ms on localhost (executor driver) (3/4)
18/05/31 14:47:16 INFO MemoryStore: 7 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:16 INFO BlockManager: Dropping block rdd_144_1 from memory
18/05/31 14:47:16 INFO BlockManagerInfo: Removed rdd_144_1 on 10.66.169.34:53539 in memory (size: 7.8 KB, free: 354.6 MB)
18/05/31 14:47:16 INFO BlockManager: Dropping block rdd_144_3 from memory
18/05/31 14:47:16 INFO BlockManagerInfo: Removed rdd_144_3 on 10.66.169.34:53539 in memory (size: 7.8 KB, free: 354.6 MB)
18/05/31 14:47:16 INFO BlockManager: Dropping block broadcast_77_piece0 from memory
18/05/31 14:47:16 INFO BlockManager: Writing block broadcast_77_piece0 to disk
18/05/31 14:47:16 INFO BlockManagerInfo: Added broadcast_77_piece0 on disk on 10.66.169.34:53539 (size: 4.8 KB)
18/05/31 14:47:16 INFO BlockManager: Dropping block broadcast_77 from memory
18/05/31 14:47:16 INFO BlockManager: Writing block broadcast_77 to disk
18/05/31 14:47:16 INFO BlockManager: Dropping block rdd_149_0 from memory
18/05/31 14:47:16 INFO BlockManagerInfo: Removed rdd_149_0 on 10.66.169.34:53539 in memory (size: 8.6 KB, free: 354.6 MB)
18/05/31 14:47:16 INFO BlockManager: Dropping block rdd_149_1 from memory
18/05/31 14:47:16 INFO BlockManagerInfo: Removed rdd_149_1 on 10.66.169.34:53539 in memory (size: 8.6 KB, free: 354.6 MB)
18/05/31 14:47:16 INFO BlockManager: Dropping block rdd_149_2 from memory
18/05/31 14:47:16 INFO BlockManagerInfo: Removed rdd_149_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:47:16 INFO MemoryStore: After dropping 7 blocks, free memory is 632.9 MB
18/05/31 14:47:16 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 633.4 MB)
18/05/31 14:47:16 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 10.66.169.34:53539 in memory (size: 14.3 KB, free: 633.4 MB)
18/05/31 14:47:16 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 10.66.169.34:53539 in memory (size: 4.5 KB, free: 633.4 MB)
18/05/31 14:47:16 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 633.4 MB)
18/05/31 14:47:16 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 10.66.169.34:53539 on disk (size: 4.8 KB)
18/05/31 14:47:16 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 10.66.169.34:53539 in memory (size: 14.3 KB, free: 633.4 MB)
18/05/31 14:47:16 INFO MemoryStore: Block rdd_159_2 stored as values in memory (estimated size 278.8 MB, free 354.4 MB)
18/05/31 14:47:16 INFO BlockManagerInfo: Added rdd_159_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:16 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:16 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-124
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:16 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:16 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:16 WARN Executor: 1 block locks were not released by TID = 170:
[rdd_154_2]
18/05/31 14:47:16 INFO Executor: Finished task 2.0 in stage 256.0 (TID 170). 2880 bytes result sent to driver
18/05/31 14:47:16 INFO TaskSetManager: Finished task 2.0 in stage 256.0 (TID 170) in 1993 ms on localhost (executor driver) (4/4)
18/05/31 14:47:16 INFO TaskSchedulerImpl: Removed TaskSet 256.0, whose tasks have all completed, from pool 
18/05/31 14:47:16 INFO DAGScheduler: ResultStage 256 (foreachPartition at AnomalyDetector.java:69) finished in 1.995 s
18/05/31 14:47:16 INFO DAGScheduler: Job 38 finished: foreachPartition at AnomalyDetector.java:69, took 2.030678 s
18/05/31 14:47:16 INFO JobScheduler: Finished job streaming job 1527767090000 ms.0 from job set of time 1527767090000 ms
18/05/31 14:47:16 INFO JobScheduler: Total delay: 146.995 s for time 1527767090000 ms (execution: 2.034 s)
18/05/31 14:47:16 INFO MapPartitionsRDD: Removing RDD 155 from persistence list
18/05/31 14:47:16 INFO JobScheduler: Starting job streaming job 1527767100000 ms.0 from job set of time 1527767100000 ms
18/05/31 14:47:16 INFO BlockManager: Removing RDD 155
18/05/31 14:47:16 INFO MapWithStateRDD: Removing RDD 59 from persistence list
18/05/31 14:47:16 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:17 INFO DAGScheduler: Registering RDD 162 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 149 bytes
18/05/31 14:47:17 INFO BlockManager: Removing RDD 59
18/05/31 14:47:17 INFO MapPartitionsRDD: Removing RDD 57 from persistence list
18/05/31 14:47:17 INFO DAGScheduler: Got job 39 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:17 INFO DAGScheduler: Final stage: ResultStage 259 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 257, ShuffleMapStage 258)
18/05/31 14:47:17 INFO BlockManager: Removing RDD 57
18/05/31 14:47:17 INFO KafkaRDD: Removing RDD 56 from persistence list
18/05/31 14:47:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 257)
18/05/31 14:47:17 INFO BlockManager: Removing RDD 56
18/05/31 14:47:17 INFO JobGenerator: Checkpointing graph for time 1527767090000 ms
18/05/31 14:47:17 INFO DStreamGraph: Updating checkpoint data for time 1527767090000 ms
18/05/31 14:47:17 INFO DStreamGraph: Updated checkpoint data for time 1527767090000 ms
18/05/31 14:47:17 INFO DAGScheduler: Submitting ShuffleMapStage 257 (MapPartitionsRDD[162] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:17 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 4.6 KB, free 354.4 MB)
18/05/31 14:47:17 INFO CheckpointWriter: Submitted checkpoint of time 1527767090000 ms to writer queue
18/05/31 14:47:17 INFO CheckpointWriter: Saving checkpoint for time 1527767090000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767230000'
18/05/31 14:47:17 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.4 MB)
18/05/31 14:47:17 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:17 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 257 (MapPartitionsRDD[162] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:17 INFO TaskSchedulerImpl: Adding task set 257.0 with 1 tasks
18/05/31 14:47:17 INFO TaskSetManager: Starting task 0.0 in stage 257.0 (TID 172, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:17 INFO Executor: Running task 0.0 in stage 257.0 (TID 172)
18/05/31 14:47:17 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:17 INFO MemoryStore: Block rdd_162_0 stored as bytes in memory (estimated size 4.0 B, free 354.4 MB)
18/05/31 14:47:17 INFO BlockManagerInfo: Added rdd_162_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:17 INFO Executor: Finished task 0.0 in stage 257.0 (TID 172). 1708 bytes result sent to driver
18/05/31 14:47:17 INFO TaskSetManager: Finished task 0.0 in stage 257.0 (TID 172) in 6 ms on localhost (executor driver) (1/1)
18/05/31 14:47:17 INFO TaskSchedulerImpl: Removed TaskSet 257.0, whose tasks have all completed, from pool 
18/05/31 14:47:17 INFO DAGScheduler: ShuffleMapStage 257 (mapToPair at AnomalyDetector.java:64) finished in 0.007 s
18/05/31 14:47:17 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:17 INFO DAGScheduler: running: Set()
18/05/31 14:47:17 INFO DAGScheduler: waiting: Set(ResultStage 259)
18/05/31 14:47:17 INFO DAGScheduler: failed: Set()
18/05/31 14:47:17 INFO DAGScheduler: Submitting ResultStage 259 (MapPartitionsRDD[165] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:17 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 8.1 KB, free 354.4 MB)
18/05/31 14:47:17 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 4.3 KB, free 354.4 MB)
18/05/31 14:47:17 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 10.66.169.34:53539 (size: 4.3 KB, free: 354.7 MB)
18/05/31 14:47:17 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 259 (MapPartitionsRDD[165] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:17 INFO TaskSchedulerImpl: Adding task set 259.0 with 4 tasks
18/05/31 14:47:17 INFO TaskSetManager: Starting task 0.0 in stage 259.0 (TID 173, localhost, executor driver, partition 0, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:47:17 INFO TaskSetManager: Starting task 1.0 in stage 259.0 (TID 174, localhost, executor driver, partition 1, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:47:17 INFO TaskSetManager: Starting task 2.0 in stage 259.0 (TID 175, localhost, executor driver, partition 2, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:47:17 INFO TaskSetManager: Starting task 3.0 in stage 259.0 (TID 176, localhost, executor driver, partition 3, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:47:17 INFO Executor: Running task 1.0 in stage 259.0 (TID 174)
18/05/31 14:47:17 INFO Executor: Running task 2.0 in stage 259.0 (TID 175)
18/05/31 14:47:17 INFO Executor: Running task 3.0 in stage 259.0 (TID 176)
18/05/31 14:47:17 INFO CheckpointWriter: Checkpoint for time 1527767090000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767230000', took 6136 bytes and 15 ms
18/05/31 14:47:17 INFO DStreamGraph: Clearing checkpoint data for time 1527767090000 ms
18/05/31 14:47:17 INFO DStreamGraph: Cleared checkpoint data for time 1527767090000 ms
18/05/31 14:47:17 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:17 INFO BlockManager: Found block rdd_159_3 locally
18/05/31 14:47:17 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:17 INFO BlockManager: Found block rdd_159_1 locally
18/05/31 14:47:17 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:47:17 INFO MemoryStore: Block rdd_164_3 stored as values in memory (estimated size 10.9 KB, free 354.4 MB)
18/05/31 14:47:17 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766890000: 
18/05/31 14:47:17 INFO InputInfoTracker: remove old batch metadata: 1527766880000 ms
18/05/31 14:47:17 INFO BlockManagerInfo: Added rdd_164_3 in memory on 10.66.169.34:53539 (size: 10.9 KB, free: 354.7 MB)
18/05/31 14:47:17 INFO MemoryStore: Block rdd_164_1 stored as values in memory (estimated size 10.9 KB, free 354.4 MB)
18/05/31 14:47:17 INFO BlockManager: Found block rdd_159_2 locally
18/05/31 14:47:17 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:17 INFO BlockManagerInfo: Added rdd_164_1 in memory on 10.66.169.34:53539 (size: 10.9 KB, free: 354.7 MB)
18/05/31 14:47:17 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:17 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:17 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-125
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:17 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:17 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:17 WARN Executor: 1 block locks were not released by TID = 176:
[rdd_159_3]
18/05/31 14:47:17 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-126
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:17 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:17 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:17 INFO Executor: Finished task 3.0 in stage 259.0 (TID 176). 2359 bytes result sent to driver
18/05/31 14:47:17 WARN Executor: 1 block locks were not released by TID = 174:
[rdd_159_1]
18/05/31 14:47:17 INFO Executor: Finished task 1.0 in stage 259.0 (TID 174). 2359 bytes result sent to driver
18/05/31 14:47:17 INFO TaskSetManager: Finished task 1.0 in stage 259.0 (TID 174) in 10 ms on localhost (executor driver) (1/4)
18/05/31 14:47:17 INFO TaskSetManager: Finished task 3.0 in stage 259.0 (TID 176) in 10 ms on localhost (executor driver) (2/4)
18/05/31 14:47:17 INFO Executor: Running task 0.0 in stage 259.0 (TID 173)
18/05/31 14:47:17 INFO BlockManager: Found block rdd_159_0 locally
18/05/31 14:47:17 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:17 INFO MemoryStore: Block rdd_164_0 stored as values in memory (estimated size 10.9 KB, free 354.4 MB)
18/05/31 14:47:17 INFO BlockManagerInfo: Added rdd_164_0 in memory on 10.66.169.34:53539 (size: 10.9 KB, free: 354.6 MB)
18/05/31 14:47:17 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:17 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-127
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:17 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:17 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:17 WARN Executor: 1 block locks were not released by TID = 173:
[rdd_159_0]
18/05/31 14:47:17 INFO Executor: Finished task 0.0 in stage 259.0 (TID 173). 2359 bytes result sent to driver
18/05/31 14:47:17 INFO TaskSetManager: Finished task 0.0 in stage 259.0 (TID 173) in 20 ms on localhost (executor driver) (3/4)
18/05/31 14:47:17 INFO MemoryStore: 11 blocks selected for dropping (279.1 MB bytes)
18/05/31 14:47:17 INFO BlockManager: Dropping block rdd_149_3 from memory
18/05/31 14:47:17 INFO BlockManagerInfo: Removed rdd_149_3 on 10.66.169.34:53539 in memory (size: 8.6 KB, free: 354.7 MB)
18/05/31 14:47:17 INFO BlockManager: Dropping block rdd_152_0 from memory
18/05/31 14:47:17 INFO BlockManagerInfo: Removed rdd_152_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:17 INFO BlockManager: Dropping block broadcast_80 from memory
18/05/31 14:47:17 INFO BlockManager: Writing block broadcast_80 to disk
18/05/31 14:47:17 INFO BlockManager: Dropping block broadcast_80_piece0 from memory
18/05/31 14:47:17 INFO BlockManager: Writing block broadcast_80_piece0 to disk
18/05/31 14:47:17 INFO BlockManagerInfo: Added broadcast_80_piece0 on disk on 10.66.169.34:53539 (size: 14.3 KB)
18/05/31 14:47:17 INFO BlockManager: Dropping block broadcast_83 from memory
18/05/31 14:47:17 INFO BlockManager: Writing block broadcast_83 to disk
18/05/31 14:47:17 INFO BlockManager: Dropping block broadcast_83_piece0 from memory
18/05/31 14:47:17 INFO BlockManager: Writing block broadcast_83_piece0 to disk
18/05/31 14:47:17 INFO BlockManagerInfo: Added broadcast_83_piece0 on disk on 10.66.169.34:53539 (size: 14.3 KB)
18/05/31 14:47:17 INFO BlockManager: Dropping block rdd_157_0 from memory
18/05/31 14:47:17 INFO BlockManagerInfo: Removed rdd_157_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:17 INFO BlockManager: Dropping block broadcast_85_piece0 from memory
18/05/31 14:47:17 INFO BlockManager: Writing block broadcast_85_piece0 to disk
18/05/31 14:47:17 INFO BlockManagerInfo: Added broadcast_85_piece0 on disk on 10.66.169.34:53539 (size: 4.2 KB)
18/05/31 14:47:17 INFO BlockManager: Dropping block broadcast_85 from memory
18/05/31 14:47:17 INFO BlockManager: Writing block broadcast_85 to disk
18/05/31 14:47:17 INFO BlockManager: Dropping block rdd_154_1 from memory
18/05/31 14:47:17 INFO BlockManagerInfo: Removed rdd_154_1 on 10.66.169.34:53539 in memory (size: 9.4 KB, free: 354.7 MB)
18/05/31 14:47:17 INFO BlockManager: Dropping block rdd_154_2 from memory
18/05/31 14:47:17 INFO BlockManagerInfo: Removed rdd_154_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:17 INFO MemoryStore: After dropping 11 blocks, free memory is 633.4 MB
18/05/31 14:47:18 INFO MemoryStore: Block rdd_164_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:18 INFO BlockManagerInfo: Added rdd_164_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:18 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:18 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-128
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:18 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:18 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:18 WARN Executor: 1 block locks were not released by TID = 175:
[rdd_159_2]
18/05/31 14:47:18 INFO Executor: Finished task 2.0 in stage 259.0 (TID 175). 3023 bytes result sent to driver
18/05/31 14:47:18 INFO TaskSetManager: Finished task 2.0 in stage 259.0 (TID 175) in 1729 ms on localhost (executor driver) (4/4)
18/05/31 14:47:18 INFO TaskSchedulerImpl: Removed TaskSet 259.0, whose tasks have all completed, from pool 
18/05/31 14:47:18 INFO DAGScheduler: ResultStage 259 (foreachPartition at AnomalyDetector.java:69) finished in 1.730 s
18/05/31 14:47:18 INFO DAGScheduler: Job 39 finished: foreachPartition at AnomalyDetector.java:69, took 1.747187 s
18/05/31 14:47:18 INFO JobScheduler: Finished job streaming job 1527767100000 ms.0 from job set of time 1527767100000 ms
18/05/31 14:47:18 INFO JobScheduler: Total delay: 138.746 s for time 1527767100000 ms (execution: 1.751 s)
18/05/31 14:47:18 INFO MapPartitionsRDD: Removing RDD 160 from persistence list
18/05/31 14:47:18 INFO JobScheduler: Starting job streaming job 1527767110000 ms.0 from job set of time 1527767110000 ms
18/05/31 14:47:18 INFO BlockManager: Removing RDD 160
18/05/31 14:47:18 INFO MapWithStateRDD: Removing RDD 64 from persistence list
18/05/31 14:47:18 INFO BlockManager: Removing RDD 64
18/05/31 14:47:18 INFO MapPartitionsRDD: Removing RDD 62 from persistence list
18/05/31 14:47:18 INFO BlockManager: Removing RDD 62
18/05/31 14:47:18 INFO KafkaRDD: Removing RDD 61 from persistence list
18/05/31 14:47:18 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:18 INFO JobGenerator: Checkpointing graph for time 1527767100000 ms
18/05/31 14:47:18 INFO DStreamGraph: Updating checkpoint data for time 1527767100000 ms
18/05/31 14:47:18 INFO BlockManager: Removing RDD 61
18/05/31 14:47:18 INFO DStreamGraph: Updated checkpoint data for time 1527767100000 ms
18/05/31 14:47:18 INFO DAGScheduler: Registering RDD 167 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:18 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 149 bytes
18/05/31 14:47:18 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 149 bytes
18/05/31 14:47:18 INFO CheckpointWriter: Submitted checkpoint of time 1527767100000 ms to writer queue
18/05/31 14:47:18 INFO CheckpointWriter: Saving checkpoint for time 1527767100000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767230000'
18/05/31 14:47:18 INFO DAGScheduler: Got job 40 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:18 INFO DAGScheduler: Final stage: ResultStage 263 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 260, ShuffleMapStage 261, ShuffleMapStage 262)
18/05/31 14:47:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 260)
18/05/31 14:47:18 INFO DAGScheduler: Submitting ShuffleMapStage 260 (MapPartitionsRDD[167] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:18 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:47:18 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.7 MB)
18/05/31 14:47:18 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:18 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 260 (MapPartitionsRDD[167] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:18 INFO TaskSchedulerImpl: Adding task set 260.0 with 1 tasks
18/05/31 14:47:18 INFO TaskSetManager: Starting task 0.0 in stage 260.0 (TID 177, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:18 INFO Executor: Running task 0.0 in stage 260.0 (TID 177)
18/05/31 14:47:18 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:18 INFO MemoryStore: Block rdd_167_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:47:18 INFO BlockManagerInfo: Added rdd_167_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:18 INFO Executor: Finished task 0.0 in stage 260.0 (TID 177). 1708 bytes result sent to driver
18/05/31 14:47:18 INFO TaskSetManager: Finished task 0.0 in stage 260.0 (TID 177) in 4 ms on localhost (executor driver) (1/1)
18/05/31 14:47:18 INFO TaskSchedulerImpl: Removed TaskSet 260.0, whose tasks have all completed, from pool 
18/05/31 14:47:18 INFO DAGScheduler: ShuffleMapStage 260 (mapToPair at AnomalyDetector.java:64) finished in 0.004 s
18/05/31 14:47:18 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:18 INFO DAGScheduler: running: Set()
18/05/31 14:47:18 INFO DAGScheduler: waiting: Set(ResultStage 263)
18/05/31 14:47:18 INFO DAGScheduler: failed: Set()
18/05/31 14:47:18 INFO DAGScheduler: Submitting ResultStage 263 (MapPartitionsRDD[170] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:18 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 8.4 KB, free 354.7 MB)
18/05/31 14:47:18 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 4.3 KB, free 354.7 MB)
18/05/31 14:47:18 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 10.66.169.34:53539 (size: 4.3 KB, free: 354.7 MB)
18/05/31 14:47:18 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:18 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 263 (MapPartitionsRDD[170] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:18 INFO TaskSchedulerImpl: Adding task set 263.0 with 4 tasks
18/05/31 14:47:18 INFO CheckpointWriter: Checkpoint for time 1527767100000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767230000', took 6121 bytes and 14 ms
18/05/31 14:47:18 INFO DStreamGraph: Clearing checkpoint data for time 1527767100000 ms
18/05/31 14:47:18 INFO TaskSetManager: Starting task 0.0 in stage 263.0 (TID 178, localhost, executor driver, partition 0, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:47:18 INFO TaskSetManager: Starting task 1.0 in stage 263.0 (TID 179, localhost, executor driver, partition 1, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:47:18 INFO TaskSetManager: Starting task 2.0 in stage 263.0 (TID 180, localhost, executor driver, partition 2, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:47:18 INFO TaskSetManager: Starting task 3.0 in stage 263.0 (TID 181, localhost, executor driver, partition 3, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:47:18 INFO DStreamCheckpointData: Deleted checkpoint file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-62' for time 1527766900000 ms
18/05/31 14:47:18 INFO DStreamGraph: Cleared checkpoint data for time 1527767100000 ms
18/05/31 14:47:18 INFO Executor: Running task 2.0 in stage 263.0 (TID 180)
18/05/31 14:47:18 INFO Executor: Running task 1.0 in stage 263.0 (TID 179)
18/05/31 14:47:18 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:18 INFO Executor: Running task 3.0 in stage 263.0 (TID 181)
18/05/31 14:47:18 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766900000: 
18/05/31 14:47:18 INFO InputInfoTracker: remove old batch metadata: 1527766890000 ms
18/05/31 14:47:18 INFO Executor: Running task 0.0 in stage 263.0 (TID 178)
18/05/31 14:47:18 INFO BlockManager: Found block rdd_164_2 locally
18/05/31 14:47:18 INFO BlockManager: Found block rdd_164_3 locally
18/05/31 14:47:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:18 INFO BlockManager: Found block rdd_164_1 locally
18/05/31 14:47:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:18 INFO MemoryStore: Block rdd_169_1 stored as values in memory (estimated size 11.6 KB, free 354.7 MB)
18/05/31 14:47:18 INFO MemoryStore: Block rdd_169_3 stored as values in memory (estimated size 11.6 KB, free 354.6 MB)
18/05/31 14:47:18 INFO BlockManagerInfo: Added rdd_169_1 in memory on 10.66.169.34:53539 (size: 11.6 KB, free: 354.7 MB)
18/05/31 14:47:18 INFO BlockManagerInfo: Added rdd_169_3 in memory on 10.66.169.34:53539 (size: 11.6 KB, free: 354.7 MB)
18/05/31 14:47:18 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:18 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:18 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-130
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:18 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:18 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:18 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-129
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:18 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:18 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:18 WARN Executor: 1 block locks were not released by TID = 181:
[rdd_164_3]
18/05/31 14:47:18 WARN Executor: 1 block locks were not released by TID = 179:
[rdd_164_1]
18/05/31 14:47:18 INFO Executor: Finished task 3.0 in stage 263.0 (TID 181). 2359 bytes result sent to driver
18/05/31 14:47:18 INFO Executor: Finished task 1.0 in stage 263.0 (TID 179). 2359 bytes result sent to driver
18/05/31 14:47:18 INFO TaskSetManager: Finished task 1.0 in stage 263.0 (TID 179) in 7 ms on localhost (executor driver) (1/4)
18/05/31 14:47:18 INFO TaskSetManager: Finished task 3.0 in stage 263.0 (TID 181) in 7 ms on localhost (executor driver) (2/4)
18/05/31 14:47:18 INFO BlockManager: Found block rdd_164_0 locally
18/05/31 14:47:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:18 INFO MemoryStore: Block rdd_169_0 stored as values in memory (estimated size 11.6 KB, free 354.6 MB)
18/05/31 14:47:18 INFO BlockManagerInfo: Added rdd_169_0 in memory on 10.66.169.34:53539 (size: 11.6 KB, free: 354.7 MB)
18/05/31 14:47:18 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:18 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-131
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:18 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:18 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:18 WARN Executor: 1 block locks were not released by TID = 178:
[rdd_164_0]
18/05/31 14:47:18 INFO Executor: Finished task 0.0 in stage 263.0 (TID 178). 2359 bytes result sent to driver
18/05/31 14:47:18 INFO TaskSetManager: Finished task 0.0 in stage 263.0 (TID 178) in 14 ms on localhost (executor driver) (3/4)
18/05/31 14:47:19 INFO MemoryStore: 9 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:19 INFO BlockManager: Dropping block rdd_154_3 from memory
18/05/31 14:47:19 INFO BlockManagerInfo: Removed rdd_154_3 on 10.66.169.34:53539 in memory (size: 9.4 KB, free: 354.7 MB)
18/05/31 14:47:19 INFO BlockManager: Dropping block rdd_154_0 from memory
18/05/31 14:47:19 INFO BlockManagerInfo: Removed rdd_154_0 on 10.66.169.34:53539 in memory (size: 9.4 KB, free: 354.7 MB)
18/05/31 14:47:19 INFO BlockManager: Dropping block broadcast_86_piece0 from memory
18/05/31 14:47:19 INFO BlockManager: Writing block broadcast_86_piece0 to disk
18/05/31 14:47:19 INFO BlockManagerInfo: Added broadcast_86_piece0 on disk on 10.66.169.34:53539 (size: 2.8 KB)
18/05/31 14:47:19 INFO BlockManager: Dropping block broadcast_86 from memory
18/05/31 14:47:19 INFO BlockManager: Writing block broadcast_86 to disk
18/05/31 14:47:19 INFO BlockManager: Dropping block rdd_162_0 from memory
18/05/31 14:47:19 INFO BlockManagerInfo: Removed rdd_162_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:19 INFO BlockManager: Dropping block broadcast_87_piece0 from memory
18/05/31 14:47:19 INFO BlockManager: Writing block broadcast_87_piece0 to disk
18/05/31 14:47:19 INFO BlockManagerInfo: Added broadcast_87_piece0 on disk on 10.66.169.34:53539 (size: 4.3 KB)
18/05/31 14:47:19 INFO BlockManager: Dropping block rdd_159_3 from memory
18/05/31 14:47:19 INFO BlockManagerInfo: Removed rdd_159_3 on 10.66.169.34:53539 in memory (size: 10.1 KB, free: 354.7 MB)
18/05/31 14:47:19 INFO BlockManager: Dropping block rdd_159_1 from memory
18/05/31 14:47:19 INFO BlockManagerInfo: Removed rdd_159_1 on 10.66.169.34:53539 in memory (size: 10.1 KB, free: 354.7 MB)
18/05/31 14:47:19 INFO BlockManager: Dropping block rdd_159_2 from memory
18/05/31 14:47:19 INFO BlockManagerInfo: Removed rdd_159_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:19 INFO MemoryStore: After dropping 9 blocks, free memory is 633.4 MB
18/05/31 14:47:20 INFO JobScheduler: Added jobs for time 1527767240000 ms
18/05/31 14:47:20 INFO JobGenerator: Checkpointing graph for time 1527767240000 ms
18/05/31 14:47:20 INFO DStreamGraph: Updating checkpoint data for time 1527767240000 ms
18/05/31 14:47:20 INFO DStreamGraph: Updated checkpoint data for time 1527767240000 ms
18/05/31 14:47:20 INFO CheckpointWriter: Submitted checkpoint of time 1527767240000 ms to writer queue
18/05/31 14:47:20 INFO CheckpointWriter: Saving checkpoint for time 1527767240000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000'
18/05/31 14:47:20 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767190000.bk
18/05/31 14:47:20 INFO CheckpointWriter: Checkpoint for time 1527767240000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000', took 6128 bytes and 13 ms
18/05/31 14:47:20 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 633.5 MB)
18/05/31 14:47:20 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 10.66.169.34:53539 on disk (size: 4.2 KB)
18/05/31 14:47:20 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 10.66.169.34:53539 on disk (size: 2.8 KB)
18/05/31 14:47:20 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 10.66.169.34:53539 on disk (size: 4.3 KB)
18/05/31 14:47:20 INFO MemoryStore: Block rdd_169_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:20 INFO BlockManagerInfo: Added rdd_169_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:20 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:20 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-132
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:20 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:20 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:20 WARN Executor: 1 block locks were not released by TID = 180:
[rdd_164_2]
18/05/31 14:47:20 INFO Executor: Finished task 2.0 in stage 263.0 (TID 180). 2983 bytes result sent to driver
18/05/31 14:47:20 INFO TaskSetManager: Finished task 2.0 in stage 263.0 (TID 180) in 1900 ms on localhost (executor driver) (4/4)
18/05/31 14:47:20 INFO TaskSchedulerImpl: Removed TaskSet 263.0, whose tasks have all completed, from pool 
18/05/31 14:47:20 INFO DAGScheduler: ResultStage 263 (foreachPartition at AnomalyDetector.java:69) finished in 1.901 s
18/05/31 14:47:20 INFO DAGScheduler: Job 40 finished: foreachPartition at AnomalyDetector.java:69, took 1.916019 s
18/05/31 14:47:20 INFO JobScheduler: Finished job streaming job 1527767110000 ms.0 from job set of time 1527767110000 ms
18/05/31 14:47:20 INFO JobScheduler: Total delay: 130.666 s for time 1527767110000 ms (execution: 1.920 s)
18/05/31 14:47:20 INFO MapPartitionsRDD: Removing RDD 165 from persistence list
18/05/31 14:47:20 INFO JobScheduler: Starting job streaming job 1527767120000 ms.0 from job set of time 1527767120000 ms
18/05/31 14:47:20 INFO BlockManager: Removing RDD 165
18/05/31 14:47:20 INFO MapWithStateRDD: Removing RDD 69 from persistence list
18/05/31 14:47:20 INFO BlockManager: Removing RDD 69
18/05/31 14:47:20 INFO MapPartitionsRDD: Removing RDD 67 from persistence list
18/05/31 14:47:20 INFO BlockManager: Removing RDD 67
18/05/31 14:47:20 INFO KafkaRDD: Removing RDD 66 from persistence list
18/05/31 14:47:20 INFO BlockManager: Removing RDD 66
18/05/31 14:47:20 INFO JobGenerator: Checkpointing graph for time 1527767110000 ms
18/05/31 14:47:20 INFO DStreamGraph: Updating checkpoint data for time 1527767110000 ms
18/05/31 14:47:20 INFO DStreamGraph: Updated checkpoint data for time 1527767110000 ms
18/05/31 14:47:20 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:20 INFO CheckpointWriter: Submitted checkpoint of time 1527767110000 ms to writer queue
18/05/31 14:47:20 INFO CheckpointWriter: Saving checkpoint for time 1527767110000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000'
18/05/31 14:47:20 INFO DAGScheduler: Registering RDD 172 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 149 bytes
18/05/31 14:47:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 149 bytes
18/05/31 14:47:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 149 bytes
18/05/31 14:47:20 INFO DAGScheduler: Got job 41 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:20 INFO DAGScheduler: Final stage: ResultStage 268 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 266, ShuffleMapStage 267, ShuffleMapStage 264, ShuffleMapStage 265)
18/05/31 14:47:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 264)
18/05/31 14:47:20 INFO DAGScheduler: Submitting ShuffleMapStage 264 (MapPartitionsRDD[172] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:20 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:47:20 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.7 MB)
18/05/31 14:47:20 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:20 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 264 (MapPartitionsRDD[172] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:20 INFO TaskSchedulerImpl: Adding task set 264.0 with 1 tasks
18/05/31 14:47:20 INFO TaskSetManager: Starting task 0.0 in stage 264.0 (TID 182, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:20 INFO Executor: Running task 0.0 in stage 264.0 (TID 182)
18/05/31 14:47:20 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:20 INFO MemoryStore: Block rdd_172_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:47:20 INFO BlockManagerInfo: Added rdd_172_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:20 INFO Executor: Finished task 0.0 in stage 264.0 (TID 182). 1708 bytes result sent to driver
18/05/31 14:47:20 INFO TaskSetManager: Finished task 0.0 in stage 264.0 (TID 182) in 6 ms on localhost (executor driver) (1/1)
18/05/31 14:47:20 INFO TaskSchedulerImpl: Removed TaskSet 264.0, whose tasks have all completed, from pool 
18/05/31 14:47:20 INFO DAGScheduler: ShuffleMapStage 264 (mapToPair at AnomalyDetector.java:64) finished in 0.006 s
18/05/31 14:47:20 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:20 INFO DAGScheduler: running: Set()
18/05/31 14:47:20 INFO DAGScheduler: waiting: Set(ResultStage 268)
18/05/31 14:47:20 INFO DAGScheduler: failed: Set()
18/05/31 14:47:20 INFO DAGScheduler: Submitting ResultStage 268 (MapPartitionsRDD[175] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:20 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 8.6 KB, free 354.7 MB)
18/05/31 14:47:20 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 4.4 KB, free 354.7 MB)
18/05/31 14:47:20 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 10.66.169.34:53539 (size: 4.4 KB, free: 354.7 MB)
18/05/31 14:47:20 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 268 (MapPartitionsRDD[175] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:20 INFO TaskSchedulerImpl: Adding task set 268.0 with 4 tasks
18/05/31 14:47:20 INFO TaskSetManager: Starting task 0.0 in stage 268.0 (TID 183, localhost, executor driver, partition 0, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:47:20 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767190000
18/05/31 14:47:20 INFO TaskSetManager: Starting task 1.0 in stage 268.0 (TID 184, localhost, executor driver, partition 1, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:47:20 INFO TaskSetManager: Starting task 2.0 in stage 268.0 (TID 185, localhost, executor driver, partition 2, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:47:20 INFO CheckpointWriter: Checkpoint for time 1527767110000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000', took 6127 bytes and 18 ms
18/05/31 14:47:20 INFO TaskSetManager: Starting task 3.0 in stage 268.0 (TID 186, localhost, executor driver, partition 3, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:47:20 INFO DStreamGraph: Clearing checkpoint data for time 1527767110000 ms
18/05/31 14:47:20 INFO DStreamGraph: Cleared checkpoint data for time 1527767110000 ms
18/05/31 14:47:20 INFO Executor: Running task 1.0 in stage 268.0 (TID 184)
18/05/31 14:47:20 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:20 INFO Executor: Running task 2.0 in stage 268.0 (TID 185)
18/05/31 14:47:20 INFO Executor: Running task 3.0 in stage 268.0 (TID 186)
18/05/31 14:47:20 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766910000: 
18/05/31 14:47:20 INFO InputInfoTracker: remove old batch metadata: 1527766900000 ms
18/05/31 14:47:20 INFO BlockManager: Found block rdd_169_3 locally
18/05/31 14:47:20 INFO BlockManager: Found block rdd_169_2 locally
18/05/31 14:47:20 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:20 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:20 INFO BlockManager: Found block rdd_169_1 locally
18/05/31 14:47:20 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:20 INFO MemoryStore: Block rdd_174_1 stored as values in memory (estimated size 12.4 KB, free 354.7 MB)
18/05/31 14:47:20 INFO BlockManagerInfo: Added rdd_174_1 in memory on 10.66.169.34:53539 (size: 12.4 KB, free: 354.7 MB)
18/05/31 14:47:20 INFO MemoryStore: Block rdd_174_3 stored as values in memory (estimated size 12.4 KB, free 354.6 MB)
18/05/31 14:47:20 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:20 INFO BlockManagerInfo: Added rdd_174_3 in memory on 10.66.169.34:53539 (size: 12.4 KB, free: 354.7 MB)
18/05/31 14:47:20 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:20 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-133
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:20 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:20 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:20 WARN Executor: 1 block locks were not released by TID = 184:
[rdd_169_1]
18/05/31 14:47:20 INFO Executor: Finished task 1.0 in stage 268.0 (TID 184). 2359 bytes result sent to driver
18/05/31 14:47:20 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-134
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:20 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:20 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:20 INFO TaskSetManager: Finished task 1.0 in stage 268.0 (TID 184) in 12 ms on localhost (executor driver) (1/4)
18/05/31 14:47:20 WARN Executor: 1 block locks were not released by TID = 186:
[rdd_169_3]
18/05/31 14:47:20 INFO Executor: Finished task 3.0 in stage 268.0 (TID 186). 2359 bytes result sent to driver
18/05/31 14:47:20 INFO TaskSetManager: Finished task 3.0 in stage 268.0 (TID 186) in 15 ms on localhost (executor driver) (2/4)
18/05/31 14:47:20 INFO Executor: Running task 0.0 in stage 268.0 (TID 183)
18/05/31 14:47:20 INFO BlockManager: Found block rdd_169_0 locally
18/05/31 14:47:20 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:20 INFO MemoryStore: Block rdd_174_0 stored as values in memory (estimated size 12.4 KB, free 354.6 MB)
18/05/31 14:47:20 INFO BlockManagerInfo: Added rdd_174_0 in memory on 10.66.169.34:53539 (size: 12.4 KB, free: 354.7 MB)
18/05/31 14:47:20 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:20 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-135
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:20 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:20 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:20 WARN Executor: 1 block locks were not released by TID = 183:
[rdd_169_0]
18/05/31 14:47:20 INFO Executor: Finished task 0.0 in stage 268.0 (TID 183). 2359 bytes result sent to driver
18/05/31 14:47:20 INFO TaskSetManager: Finished task 0.0 in stage 268.0 (TID 183) in 24 ms on localhost (executor driver) (3/4)
18/05/31 14:47:21 INFO MemoryStore: 4 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:21 INFO BlockManager: Dropping block rdd_159_0 from memory
18/05/31 14:47:21 INFO BlockManagerInfo: Removed rdd_159_0 on 10.66.169.34:53539 in memory (size: 10.1 KB, free: 354.7 MB)
18/05/31 14:47:21 INFO BlockManager: Dropping block rdd_167_0 from memory
18/05/31 14:47:21 INFO BlockManagerInfo: Removed rdd_167_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:21 INFO BlockManager: Dropping block broadcast_89_piece0 from memory
18/05/31 14:47:21 INFO BlockManager: Writing block broadcast_89_piece0 to disk
18/05/31 14:47:21 INFO BlockManagerInfo: Added broadcast_89_piece0 on disk on 10.66.169.34:53539 (size: 4.3 KB)
18/05/31 14:47:21 INFO BlockManager: Dropping block rdd_164_2 from memory
18/05/31 14:47:21 INFO BlockManagerInfo: Removed rdd_164_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:47:21 INFO MemoryStore: After dropping 4 blocks, free memory is 633.4 MB
18/05/31 14:47:22 INFO MemoryStore: Block rdd_174_2 stored as values in memory (estimated size 278.8 MB, free 354.6 MB)
18/05/31 14:47:22 INFO BlockManagerInfo: Added rdd_174_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:22 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:22 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-136
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:22 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:22 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:22 WARN Executor: 1 block locks were not released by TID = 185:
[rdd_169_2]
18/05/31 14:47:22 INFO Executor: Finished task 2.0 in stage 268.0 (TID 185). 2663 bytes result sent to driver
18/05/31 14:47:22 INFO TaskSetManager: Finished task 2.0 in stage 268.0 (TID 185) in 1683 ms on localhost (executor driver) (4/4)
18/05/31 14:47:22 INFO TaskSchedulerImpl: Removed TaskSet 268.0, whose tasks have all completed, from pool 
18/05/31 14:47:22 INFO DAGScheduler: ResultStage 268 (foreachPartition at AnomalyDetector.java:69) finished in 1.684 s
18/05/31 14:47:22 INFO DAGScheduler: Job 41 finished: foreachPartition at AnomalyDetector.java:69, took 1.701664 s
18/05/31 14:47:22 INFO JobScheduler: Finished job streaming job 1527767120000 ms.0 from job set of time 1527767120000 ms
18/05/31 14:47:22 INFO JobScheduler: Total delay: 122.373 s for time 1527767120000 ms (execution: 1.706 s)
18/05/31 14:47:22 INFO MapPartitionsRDD: Removing RDD 170 from persistence list
18/05/31 14:47:22 INFO JobScheduler: Starting job streaming job 1527767130000 ms.0 from job set of time 1527767130000 ms
18/05/31 14:47:22 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:22 INFO BlockManager: Removing RDD 170
18/05/31 14:47:22 INFO MapWithStateRDD: Removing RDD 74 from persistence list
18/05/31 14:47:22 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 149 bytes
18/05/31 14:47:22 INFO DAGScheduler: Registering RDD 177 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:22 INFO BlockManager: Removing RDD 74
18/05/31 14:47:22 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 149 bytes
18/05/31 14:47:22 INFO MapPartitionsRDD: Removing RDD 72 from persistence list
18/05/31 14:47:22 INFO BlockManager: Removing RDD 72
18/05/31 14:47:22 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 149 bytes
18/05/31 14:47:22 INFO KafkaRDD: Removing RDD 71 from persistence list
18/05/31 14:47:22 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 149 bytes
18/05/31 14:47:22 INFO DAGScheduler: Got job 42 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:22 INFO DAGScheduler: Final stage: ResultStage 274 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 269, ShuffleMapStage 273, ShuffleMapStage 270, ShuffleMapStage 271, ShuffleMapStage 272)
18/05/31 14:47:22 INFO JobGenerator: Checkpointing graph for time 1527767120000 ms
18/05/31 14:47:22 INFO BlockManager: Removing RDD 71
18/05/31 14:47:22 INFO DStreamGraph: Updating checkpoint data for time 1527767120000 ms
18/05/31 14:47:22 INFO DStreamGraph: Updated checkpoint data for time 1527767120000 ms
18/05/31 14:47:22 INFO CheckpointWriter: Submitted checkpoint of time 1527767120000 ms to writer queue
18/05/31 14:47:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 270)
18/05/31 14:47:22 INFO CheckpointWriter: Saving checkpoint for time 1527767120000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000'
18/05/31 14:47:22 INFO DAGScheduler: Submitting ShuffleMapStage 270 (MapPartitionsRDD[177] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:22 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 4.6 KB, free 354.6 MB)
18/05/31 14:47:22 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.6 MB)
18/05/31 14:47:22 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:22 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 270 (MapPartitionsRDD[177] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:22 INFO TaskSchedulerImpl: Adding task set 270.0 with 1 tasks
18/05/31 14:47:22 INFO TaskSetManager: Starting task 0.0 in stage 270.0 (TID 187, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:22 INFO Executor: Running task 0.0 in stage 270.0 (TID 187)
18/05/31 14:47:22 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:22 INFO MemoryStore: Block rdd_177_0 stored as bytes in memory (estimated size 4.0 B, free 354.6 MB)
18/05/31 14:47:22 INFO BlockManagerInfo: Added rdd_177_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:22 INFO Executor: Finished task 0.0 in stage 270.0 (TID 187). 1708 bytes result sent to driver
18/05/31 14:47:22 INFO TaskSetManager: Finished task 0.0 in stage 270.0 (TID 187) in 8 ms on localhost (executor driver) (1/1)
18/05/31 14:47:22 INFO TaskSchedulerImpl: Removed TaskSet 270.0, whose tasks have all completed, from pool 
18/05/31 14:47:22 INFO DAGScheduler: ShuffleMapStage 270 (mapToPair at AnomalyDetector.java:64) finished in 0.009 s
18/05/31 14:47:22 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:22 INFO DAGScheduler: running: Set()
18/05/31 14:47:22 INFO DAGScheduler: waiting: Set(ResultStage 274)
18/05/31 14:47:22 INFO DAGScheduler: failed: Set()
18/05/31 14:47:22 INFO DAGScheduler: Submitting ResultStage 274 (MapPartitionsRDD[180] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:22 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 8.9 KB, free 354.6 MB)
18/05/31 14:47:22 INFO CheckpointWriter: Checkpoint for time 1527767120000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000', took 6126 bytes and 20 ms
18/05/31 14:47:22 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.6 MB)
18/05/31 14:47:22 INFO DStreamGraph: Clearing checkpoint data for time 1527767120000 ms
18/05/31 14:47:22 INFO DStreamGraph: Cleared checkpoint data for time 1527767120000 ms
18/05/31 14:47:22 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:22 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 10.66.169.34:53539 (size: 4.5 KB, free: 354.7 MB)
18/05/31 14:47:22 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 274 (MapPartitionsRDD[180] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:22 INFO TaskSchedulerImpl: Adding task set 274.0 with 4 tasks
18/05/31 14:47:22 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 1 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766920000: file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata/log-1527766851351-1527766911351
18/05/31 14:47:22 INFO InputInfoTracker: remove old batch metadata: 1527766910000 ms
18/05/31 14:47:22 INFO TaskSetManager: Starting task 0.0 in stage 274.0 (TID 188, localhost, executor driver, partition 0, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:22 INFO TaskSetManager: Starting task 1.0 in stage 274.0 (TID 189, localhost, executor driver, partition 1, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:22 INFO TaskSetManager: Starting task 2.0 in stage 274.0 (TID 190, localhost, executor driver, partition 2, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:22 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Cleared log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766920000
18/05/31 14:47:22 INFO TaskSetManager: Starting task 3.0 in stage 274.0 (TID 191, localhost, executor driver, partition 3, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:22 INFO Executor: Running task 0.0 in stage 274.0 (TID 188)
18/05/31 14:47:22 INFO Executor: Running task 1.0 in stage 274.0 (TID 189)
18/05/31 14:47:22 INFO Executor: Running task 2.0 in stage 274.0 (TID 190)
18/05/31 14:47:22 INFO Executor: Running task 3.0 in stage 274.0 (TID 191)
18/05/31 14:47:22 INFO BlockManager: Found block rdd_174_2 locally
18/05/31 14:47:22 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:47:22 INFO BlockManager: Found block rdd_174_0 locally
18/05/31 14:47:22 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:47:22 INFO MemoryStore: Block rdd_179_0 stored as values in memory (estimated size 13.2 KB, free 354.6 MB)
18/05/31 14:47:22 INFO BlockManager: Found block rdd_174_3 locally
18/05/31 14:47:22 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:22 INFO MemoryStore: Block rdd_179_3 stored as values in memory (estimated size 13.2 KB, free 354.6 MB)
18/05/31 14:47:22 INFO BlockManagerInfo: Added rdd_179_0 in memory on 10.66.169.34:53539 (size: 13.2 KB, free: 354.7 MB)
18/05/31 14:47:22 INFO BlockManagerInfo: Added rdd_179_3 in memory on 10.66.169.34:53539 (size: 13.2 KB, free: 354.6 MB)
18/05/31 14:47:22 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:22 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:22 INFO BlockManager: Found block rdd_174_1 locally
18/05/31 14:47:22 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:22 INFO MemoryStore: Block rdd_179_1 stored as values in memory (estimated size 13.2 KB, free 354.6 MB)
18/05/31 14:47:22 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-137
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:22 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:22 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:22 WARN Executor: 1 block locks were not released by TID = 188:
[rdd_174_0]
18/05/31 14:47:22 INFO Executor: Finished task 0.0 in stage 274.0 (TID 188). 2359 bytes result sent to driver
18/05/31 14:47:22 INFO BlockManagerInfo: Added rdd_179_1 in memory on 10.66.169.34:53539 (size: 13.2 KB, free: 354.6 MB)
18/05/31 14:47:22 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:22 INFO TaskSetManager: Finished task 0.0 in stage 274.0 (TID 188) in 21 ms on localhost (executor driver) (1/4)
18/05/31 14:47:22 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-138
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:22 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:22 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:22 WARN Executor: 1 block locks were not released by TID = 191:
[rdd_174_3]
18/05/31 14:47:22 INFO Executor: Finished task 3.0 in stage 274.0 (TID 191). 2359 bytes result sent to driver
18/05/31 14:47:22 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-139
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:22 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:22 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:22 WARN Executor: 1 block locks were not released by TID = 189:
[rdd_174_1]
18/05/31 14:47:22 INFO Executor: Finished task 1.0 in stage 274.0 (TID 189). 2359 bytes result sent to driver
18/05/31 14:47:22 INFO TaskSetManager: Finished task 3.0 in stage 274.0 (TID 191) in 25 ms on localhost (executor driver) (2/4)
18/05/31 14:47:22 INFO TaskSetManager: Finished task 1.0 in stage 274.0 (TID 189) in 26 ms on localhost (executor driver) (3/4)
18/05/31 14:47:23 INFO MemoryStore: 10 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:23 INFO BlockManager: Dropping block rdd_164_3 from memory
18/05/31 14:47:23 INFO BlockManagerInfo: Removed rdd_164_3 on 10.66.169.34:53539 in memory (size: 10.9 KB, free: 354.6 MB)
18/05/31 14:47:23 INFO BlockManager: Dropping block rdd_164_1 from memory
18/05/31 14:47:23 INFO BlockManagerInfo: Removed rdd_164_1 on 10.66.169.34:53539 in memory (size: 10.9 KB, free: 354.6 MB)
18/05/31 14:47:23 INFO BlockManager: Dropping block broadcast_89 from memory
18/05/31 14:47:23 INFO BlockManager: Writing block broadcast_89 to disk
18/05/31 14:47:23 INFO BlockManager: Dropping block rdd_164_0 from memory
18/05/31 14:47:23 INFO BlockManagerInfo: Removed rdd_164_0 on 10.66.169.34:53539 in memory (size: 10.9 KB, free: 354.7 MB)
18/05/31 14:47:23 INFO BlockManager: Dropping block broadcast_90_piece0 from memory
18/05/31 14:47:23 INFO BlockManager: Writing block broadcast_90_piece0 to disk
18/05/31 14:47:23 INFO BlockManagerInfo: Added broadcast_90_piece0 on disk on 10.66.169.34:53539 (size: 2.8 KB)
18/05/31 14:47:23 INFO BlockManager: Dropping block broadcast_90 from memory
18/05/31 14:47:23 INFO BlockManager: Writing block broadcast_90 to disk
18/05/31 14:47:23 INFO BlockManager: Dropping block rdd_172_0 from memory
18/05/31 14:47:23 INFO BlockManagerInfo: Removed rdd_172_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:23 INFO BlockManager: Dropping block broadcast_91_piece0 from memory
18/05/31 14:47:23 INFO BlockManager: Writing block broadcast_91_piece0 to disk
18/05/31 14:47:23 INFO BlockManagerInfo: Added broadcast_91_piece0 on disk on 10.66.169.34:53539 (size: 4.4 KB)
18/05/31 14:47:23 INFO BlockManager: Dropping block rdd_169_3 from memory
18/05/31 14:47:23 INFO BlockManagerInfo: Removed rdd_169_3 on 10.66.169.34:53539 in memory (size: 11.6 KB, free: 354.7 MB)
18/05/31 14:47:23 INFO BlockManager: Dropping block rdd_169_2 from memory
18/05/31 14:47:23 INFO BlockManagerInfo: Removed rdd_169_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:47:23 INFO MemoryStore: After dropping 10 blocks, free memory is 633.4 MB
18/05/31 14:47:23 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 10.66.169.34:53539 on disk (size: 4.3 KB)
18/05/31 14:47:23 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 10.66.169.34:53539 on disk (size: 2.8 KB)
18/05/31 14:47:23 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 10.66.169.34:53539 on disk (size: 4.4 KB)
18/05/31 14:47:23 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 633.4 MB)
18/05/31 14:47:24 INFO MemoryStore: Block rdd_179_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:24 INFO BlockManagerInfo: Added rdd_179_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:24 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:24 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-140
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:24 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:24 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:24 WARN Executor: 1 block locks were not released by TID = 190:
[rdd_174_2]
18/05/31 14:47:24 INFO Executor: Finished task 2.0 in stage 274.0 (TID 190). 3035 bytes result sent to driver
18/05/31 14:47:24 INFO TaskSetManager: Finished task 2.0 in stage 274.0 (TID 190) in 1757 ms on localhost (executor driver) (4/4)
18/05/31 14:47:24 INFO TaskSchedulerImpl: Removed TaskSet 274.0, whose tasks have all completed, from pool 
18/05/31 14:47:24 INFO DAGScheduler: ResultStage 274 (foreachPartition at AnomalyDetector.java:69) finished in 1.758 s
18/05/31 14:47:24 INFO DAGScheduler: Job 42 finished: foreachPartition at AnomalyDetector.java:69, took 1.789801 s
18/05/31 14:47:24 INFO JobScheduler: Finished job streaming job 1527767130000 ms.0 from job set of time 1527767130000 ms
18/05/31 14:47:24 INFO JobScheduler: Total delay: 114.168 s for time 1527767130000 ms (execution: 1.793 s)
18/05/31 14:47:24 INFO MapPartitionsRDD: Removing RDD 175 from persistence list
18/05/31 14:47:24 INFO JobScheduler: Starting job streaming job 1527767140000 ms.0 from job set of time 1527767140000 ms
18/05/31 14:47:24 INFO BlockManager: Removing RDD 175
18/05/31 14:47:24 INFO MapWithStateRDD: Removing RDD 79 from persistence list
18/05/31 14:47:24 INFO BlockManager: Removing RDD 79
18/05/31 14:47:24 INFO MapPartitionsRDD: Removing RDD 77 from persistence list
18/05/31 14:47:24 INFO BlockManager: Removing RDD 77
18/05/31 14:47:24 INFO KafkaRDD: Removing RDD 76 from persistence list
18/05/31 14:47:24 INFO BlockManager: Removing RDD 76
18/05/31 14:47:24 INFO JobGenerator: Checkpointing graph for time 1527767130000 ms
18/05/31 14:47:24 INFO DStreamGraph: Updating checkpoint data for time 1527767130000 ms
18/05/31 14:47:24 INFO DStreamGraph: Updated checkpoint data for time 1527767130000 ms
18/05/31 14:47:24 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:24 INFO CheckpointWriter: Submitted checkpoint of time 1527767130000 ms to writer queue
18/05/31 14:47:24 INFO DAGScheduler: Registering RDD 182 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:24 INFO CheckpointWriter: Saving checkpoint for time 1527767130000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000'
18/05/31 14:47:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 149 bytes
18/05/31 14:47:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 149 bytes
18/05/31 14:47:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 149 bytes
18/05/31 14:47:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 149 bytes
18/05/31 14:47:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 149 bytes
18/05/31 14:47:24 INFO DAGScheduler: Got job 43 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:24 INFO DAGScheduler: Final stage: ResultStage 281 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 277, ShuffleMapStage 278, ShuffleMapStage 275, ShuffleMapStage 279, ShuffleMapStage 276, ShuffleMapStage 280)
18/05/31 14:47:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 275)
18/05/31 14:47:24 INFO DAGScheduler: Submitting ShuffleMapStage 275 (MapPartitionsRDD[182] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:24 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 5.9 KB, free 354.7 MB)
18/05/31 14:47:24 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.7 MB)
18/05/31 14:47:24 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:24 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 275 (MapPartitionsRDD[182] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:24 INFO TaskSchedulerImpl: Adding task set 275.0 with 1 tasks
18/05/31 14:47:24 INFO TaskSetManager: Starting task 0.0 in stage 275.0 (TID 192, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:24 INFO Executor: Running task 0.0 in stage 275.0 (TID 192)
18/05/31 14:47:24 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:24 INFO MemoryStore: Block rdd_182_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:47:24 INFO BlockManagerInfo: Added rdd_182_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:24 INFO Executor: Finished task 0.0 in stage 275.0 (TID 192). 1708 bytes result sent to driver
18/05/31 14:47:24 INFO CheckpointWriter: Checkpoint for time 1527767130000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000', took 6100 bytes and 22 ms
18/05/31 14:47:24 INFO DStreamGraph: Clearing checkpoint data for time 1527767130000 ms
18/05/31 14:47:24 INFO DStreamGraph: Cleared checkpoint data for time 1527767130000 ms
18/05/31 14:47:24 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:24 INFO TaskSetManager: Finished task 0.0 in stage 275.0 (TID 192) in 15 ms on localhost (executor driver) (1/1)
18/05/31 14:47:24 INFO TaskSchedulerImpl: Removed TaskSet 275.0, whose tasks have all completed, from pool 
18/05/31 14:47:24 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766930000: 
18/05/31 14:47:24 INFO InputInfoTracker: remove old batch metadata: 1527766920000 ms
18/05/31 14:47:24 INFO DAGScheduler: ShuffleMapStage 275 (mapToPair at AnomalyDetector.java:64) finished in 0.016 s
18/05/31 14:47:24 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:24 INFO DAGScheduler: running: Set()
18/05/31 14:47:24 INFO DAGScheduler: waiting: Set(ResultStage 281)
18/05/31 14:47:24 INFO DAGScheduler: failed: Set()
18/05/31 14:47:24 INFO DAGScheduler: Submitting ResultStage 281 (MapPartitionsRDD[185] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:24 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 9.2 KB, free 354.6 MB)
18/05/31 14:47:24 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.6 MB)
18/05/31 14:47:24 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 10.66.169.34:53539 (size: 4.5 KB, free: 354.7 MB)
18/05/31 14:47:24 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 281 (MapPartitionsRDD[185] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:24 INFO TaskSchedulerImpl: Adding task set 281.0 with 4 tasks
18/05/31 14:47:24 INFO TaskSetManager: Starting task 0.0 in stage 281.0 (TID 193, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:24 INFO TaskSetManager: Starting task 1.0 in stage 281.0 (TID 194, localhost, executor driver, partition 1, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:24 INFO TaskSetManager: Starting task 2.0 in stage 281.0 (TID 195, localhost, executor driver, partition 2, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:24 INFO TaskSetManager: Starting task 3.0 in stage 281.0 (TID 196, localhost, executor driver, partition 3, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:24 INFO Executor: Running task 1.0 in stage 281.0 (TID 194)
18/05/31 14:47:24 INFO Executor: Running task 2.0 in stage 281.0 (TID 195)
18/05/31 14:47:24 INFO Executor: Running task 3.0 in stage 281.0 (TID 196)
18/05/31 14:47:24 INFO BlockManager: Found block rdd_179_2 locally
18/05/31 14:47:24 INFO BlockManager: Found block rdd_179_3 locally
18/05/31 14:47:24 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:24 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
18/05/31 14:47:24 INFO BlockManager: Found block rdd_179_1 locally
18/05/31 14:47:24 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:24 INFO MemoryStore: Block rdd_184_1 stored as values in memory (estimated size 13.9 KB, free 354.6 MB)
18/05/31 14:47:24 INFO MemoryStore: Block rdd_184_3 stored as values in memory (estimated size 13.9 KB, free 354.6 MB)
18/05/31 14:47:24 INFO BlockManagerInfo: Added rdd_184_1 in memory on 10.66.169.34:53539 (size: 13.9 KB, free: 354.7 MB)
18/05/31 14:47:24 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:24 INFO BlockManagerInfo: Added rdd_184_3 in memory on 10.66.169.34:53539 (size: 13.9 KB, free: 354.6 MB)
18/05/31 14:47:24 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:24 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-141
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:24 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:24 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:24 WARN Executor: 1 block locks were not released by TID = 194:
[rdd_179_1]
18/05/31 14:47:24 INFO Executor: Finished task 1.0 in stage 281.0 (TID 194). 2359 bytes result sent to driver
18/05/31 14:47:24 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-142
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:24 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:24 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:24 WARN Executor: 1 block locks were not released by TID = 196:
[rdd_179_3]
18/05/31 14:47:24 INFO Executor: Finished task 3.0 in stage 281.0 (TID 196). 2359 bytes result sent to driver
18/05/31 14:47:24 INFO TaskSetManager: Finished task 1.0 in stage 281.0 (TID 194) in 11 ms on localhost (executor driver) (1/4)
18/05/31 14:47:24 INFO TaskSetManager: Finished task 3.0 in stage 281.0 (TID 196) in 12 ms on localhost (executor driver) (2/4)
18/05/31 14:47:24 INFO Executor: Running task 0.0 in stage 281.0 (TID 193)
18/05/31 14:47:24 INFO BlockManager: Found block rdd_179_0 locally
18/05/31 14:47:24 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:24 INFO MemoryStore: Block rdd_184_0 stored as values in memory (estimated size 13.9 KB, free 354.6 MB)
18/05/31 14:47:24 INFO BlockManagerInfo: Added rdd_184_0 in memory on 10.66.169.34:53539 (size: 13.9 KB, free: 354.6 MB)
18/05/31 14:47:24 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:24 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-143
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:24 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:24 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:24 WARN Executor: 1 block locks were not released by TID = 193:
[rdd_179_0]
18/05/31 14:47:24 INFO Executor: Finished task 0.0 in stage 281.0 (TID 193). 2359 bytes result sent to driver
18/05/31 14:47:24 INFO TaskSetManager: Finished task 0.0 in stage 281.0 (TID 193) in 22 ms on localhost (executor driver) (3/4)
18/05/31 14:47:25 INFO MemoryStore: 6 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:25 INFO BlockManager: Dropping block rdd_169_1 from memory
18/05/31 14:47:25 INFO BlockManagerInfo: Removed rdd_169_1 on 10.66.169.34:53539 in memory (size: 11.6 KB, free: 354.6 MB)
18/05/31 14:47:25 INFO BlockManager: Dropping block rdd_169_0 from memory
18/05/31 14:47:25 INFO BlockManagerInfo: Removed rdd_169_0 on 10.66.169.34:53539 in memory (size: 11.6 KB, free: 354.6 MB)
18/05/31 14:47:25 INFO BlockManager: Dropping block rdd_177_0 from memory
18/05/31 14:47:25 INFO BlockManagerInfo: Removed rdd_177_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.6 MB)
18/05/31 14:47:25 INFO BlockManager: Dropping block broadcast_93_piece0 from memory
18/05/31 14:47:25 INFO BlockManager: Writing block broadcast_93_piece0 to disk
18/05/31 14:47:25 INFO BlockManagerInfo: Added broadcast_93_piece0 on disk on 10.66.169.34:53539 (size: 4.5 KB)
18/05/31 14:47:25 INFO BlockManager: Dropping block broadcast_93 from memory
18/05/31 14:47:25 INFO BlockManager: Writing block broadcast_93 to disk
18/05/31 14:47:25 INFO BlockManager: Dropping block rdd_174_2 from memory
18/05/31 14:47:25 INFO BlockManagerInfo: Removed rdd_174_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:47:25 INFO MemoryStore: After dropping 6 blocks, free memory is 633.4 MB
18/05/31 14:47:25 INFO MemoryStore: Block rdd_184_2 stored as values in memory (estimated size 278.8 MB, free 354.6 MB)
18/05/31 14:47:25 INFO BlockManagerInfo: Added rdd_184_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:25 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:25 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-144
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:25 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:25 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:25 WARN Executor: 1 block locks were not released by TID = 195:
[rdd_179_2]
18/05/31 14:47:25 INFO Executor: Finished task 2.0 in stage 281.0 (TID 195). 2760 bytes result sent to driver
18/05/31 14:47:25 INFO TaskSetManager: Finished task 2.0 in stage 281.0 (TID 195) in 1740 ms on localhost (executor driver) (4/4)
18/05/31 14:47:25 INFO TaskSchedulerImpl: Removed TaskSet 281.0, whose tasks have all completed, from pool 
18/05/31 14:47:25 INFO DAGScheduler: ResultStage 281 (foreachPartition at AnomalyDetector.java:69) finished in 1.742 s
18/05/31 14:47:25 INFO DAGScheduler: Job 43 finished: foreachPartition at AnomalyDetector.java:69, took 1.768534 s
18/05/31 14:47:25 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 127.1 KB, free 354.5 MB)
18/05/31 14:47:25 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.5 MB)
18/05/31 14:47:25 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:47:25 INFO SparkContext: Created broadcast 96 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:25 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:25 INFO DAGScheduler: Got job 44 (foreachPartition at AnomalyDetector.java:69) with 1 output partitions
18/05/31 14:47:25 INFO DAGScheduler: Final stage: ResultStage 282 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:25 INFO DAGScheduler: Parents of final stage: List()
18/05/31 14:47:25 INFO DAGScheduler: Missing parents: List()
18/05/31 14:47:25 INFO DAGScheduler: Submitting ResultStage 282 (MapPartitionsRDD[182] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:25 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 6.1 KB, free 354.5 MB)
18/05/31 14:47:25 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.5 MB)
18/05/31 14:47:25 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.6 MB)
18/05/31 14:47:25 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 282 (MapPartitionsRDD[182] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:25 INFO TaskSchedulerImpl: Adding task set 282.0 with 1 tasks
18/05/31 14:47:25 INFO TaskSetManager: Starting task 0.0 in stage 282.0 (TID 197, localhost, executor driver, partition 0, PROCESS_LOCAL, 6166 bytes)
18/05/31 14:47:25 INFO Executor: Running task 0.0 in stage 282.0 (TID 197)
18/05/31 14:47:25 INFO BlockManager: Found block rdd_182_0 locally
18/05/31 14:47:25 INFO Executor: Finished task 0.0 in stage 282.0 (TID 197). 1004 bytes result sent to driver
18/05/31 14:47:25 INFO TaskSetManager: Finished task 0.0 in stage 282.0 (TID 197) in 11 ms on localhost (executor driver) (1/1)
18/05/31 14:47:25 INFO TaskSchedulerImpl: Removed TaskSet 282.0, whose tasks have all completed, from pool 
18/05/31 14:47:25 INFO DAGScheduler: ResultStage 282 (foreachPartition at AnomalyDetector.java:69) finished in 0.011 s
18/05/31 14:47:25 INFO DAGScheduler: Job 44 finished: foreachPartition at AnomalyDetector.java:69, took 0.014517 s
18/05/31 14:47:25 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 127.1 KB, free 354.4 MB)
18/05/31 14:47:25 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.4 MB)
18/05/31 14:47:25 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:47:25 INFO SparkContext: Created broadcast 98 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:25 INFO ReliableRDDCheckpointData: Done checkpointing RDD 182 to file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-182, new parent is RDD 244
18/05/31 14:47:25 INFO JobScheduler: Finished job streaming job 1527767140000 ms.0 from job set of time 1527767140000 ms
18/05/31 14:47:25 INFO JobScheduler: Total delay: 105.983 s for time 1527767140000 ms (execution: 1.815 s)
18/05/31 14:47:25 INFO JobScheduler: Starting job streaming job 1527767150000 ms.0 from job set of time 1527767150000 ms
18/05/31 14:47:25 INFO MapPartitionsRDD: Removing RDD 180 from persistence list
18/05/31 14:47:25 INFO BlockManager: Removing RDD 180
18/05/31 14:47:25 INFO MapWithStateRDD: Removing RDD 84 from persistence list
18/05/31 14:47:25 INFO BlockManager: Removing RDD 84
18/05/31 14:47:25 INFO MapPartitionsRDD: Removing RDD 82 from persistence list
18/05/31 14:47:25 INFO BlockManager: Removing RDD 82
18/05/31 14:47:25 INFO KafkaRDD: Removing RDD 81 from persistence list
18/05/31 14:47:25 INFO BlockManager: Removing RDD 81
18/05/31 14:47:25 INFO JobGenerator: Checkpointing graph for time 1527767140000 ms
18/05/31 14:47:25 INFO DStreamGraph: Updating checkpoint data for time 1527767140000 ms
18/05/31 14:47:25 INFO DStreamGraph: Updated checkpoint data for time 1527767140000 ms
18/05/31 14:47:25 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:25 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 37 is 149 bytes
18/05/31 14:47:25 INFO CheckpointWriter: Submitted checkpoint of time 1527767140000 ms to writer queue
18/05/31 14:47:25 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 149 bytes
18/05/31 14:47:25 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 149 bytes
18/05/31 14:47:25 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 149 bytes
18/05/31 14:47:25 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 149 bytes
18/05/31 14:47:25 INFO DAGScheduler: Registering RDD 187 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:25 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 149 bytes
18/05/31 14:47:25 INFO DAGScheduler: Got job 45 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:25 INFO DAGScheduler: Final stage: ResultStage 290 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 287, ShuffleMapStage 284, ShuffleMapStage 288, ShuffleMapStage 285, ShuffleMapStage 289, ShuffleMapStage 286, ShuffleMapStage 283)
18/05/31 14:47:25 INFO CheckpointWriter: Saving checkpoint for time 1527767140000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000'
18/05/31 14:47:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 288)
18/05/31 14:47:25 INFO DAGScheduler: Submitting ShuffleMapStage 288 (MapPartitionsRDD[187] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:25 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 4.6 KB, free 354.3 MB)
18/05/31 14:47:25 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.3 MB)
18/05/31 14:47:25 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:47:25 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 288 (MapPartitionsRDD[187] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:25 INFO TaskSchedulerImpl: Adding task set 288.0 with 1 tasks
18/05/31 14:47:25 INFO TaskSetManager: Starting task 0.0 in stage 288.0 (TID 198, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:25 INFO Executor: Running task 0.0 in stage 288.0 (TID 198)
18/05/31 14:47:26 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:26 INFO MemoryStore: Block rdd_187_0 stored as bytes in memory (estimated size 4.0 B, free 354.3 MB)
18/05/31 14:47:26 INFO BlockManagerInfo: Added rdd_187_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.6 MB)
18/05/31 14:47:26 INFO Executor: Finished task 0.0 in stage 288.0 (TID 198). 1708 bytes result sent to driver
18/05/31 14:47:26 INFO TaskSetManager: Finished task 0.0 in stage 288.0 (TID 198) in 5 ms on localhost (executor driver) (1/1)
18/05/31 14:47:26 INFO TaskSchedulerImpl: Removed TaskSet 288.0, whose tasks have all completed, from pool 
18/05/31 14:47:26 INFO DAGScheduler: ShuffleMapStage 288 (mapToPair at AnomalyDetector.java:64) finished in 0.005 s
18/05/31 14:47:26 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:26 INFO DAGScheduler: running: Set()
18/05/31 14:47:26 INFO DAGScheduler: waiting: Set(ResultStage 290)
18/05/31 14:47:26 INFO DAGScheduler: failed: Set()
18/05/31 14:47:26 INFO DAGScheduler: Submitting ResultStage 290 (MapPartitionsRDD[190] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:26 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 9.4 KB, free 354.3 MB)
18/05/31 14:47:26 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 4.6 KB, free 354.3 MB)
18/05/31 14:47:26 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 10.66.169.34:53539 (size: 4.6 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 290 (MapPartitionsRDD[190] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:26 INFO TaskSchedulerImpl: Adding task set 290.0 with 4 tasks
18/05/31 14:47:26 INFO CheckpointWriter: Checkpoint for time 1527767140000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000', took 6100 bytes and 19 ms
18/05/31 14:47:26 INFO DStreamGraph: Clearing checkpoint data for time 1527767140000 ms
18/05/31 14:47:26 INFO DStreamGraph: Cleared checkpoint data for time 1527767140000 ms
18/05/31 14:47:26 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:26 INFO TaskSetManager: Starting task 0.0 in stage 290.0 (TID 199, localhost, executor driver, partition 0, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:26 INFO TaskSetManager: Starting task 1.0 in stage 290.0 (TID 200, localhost, executor driver, partition 1, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:26 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766940000: 
18/05/31 14:47:26 INFO TaskSetManager: Starting task 2.0 in stage 290.0 (TID 201, localhost, executor driver, partition 2, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:26 INFO InputInfoTracker: remove old batch metadata: 1527766930000 ms
18/05/31 14:47:26 INFO TaskSetManager: Starting task 3.0 in stage 290.0 (TID 202, localhost, executor driver, partition 3, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:26 INFO Executor: Running task 0.0 in stage 290.0 (TID 199)
18/05/31 14:47:26 INFO Executor: Running task 2.0 in stage 290.0 (TID 201)
18/05/31 14:47:26 INFO Executor: Running task 1.0 in stage 290.0 (TID 200)
18/05/31 14:47:26 INFO Executor: Running task 3.0 in stage 290.0 (TID 202)
18/05/31 14:47:26 INFO BlockManager: Found block rdd_184_0 locally
18/05/31 14:47:26 INFO BlockManager: Found block rdd_184_2 locally
18/05/31 14:47:26 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:26 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:26 INFO MemoryStore: Block rdd_189_0 stored as values in memory (estimated size 14.7 KB, free 354.3 MB)
18/05/31 14:47:26 INFO BlockManager: Found block rdd_184_3 locally
18/05/31 14:47:26 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:26 INFO BlockManagerInfo: Added rdd_189_0 in memory on 10.66.169.34:53539 (size: 14.7 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO MemoryStore: Block rdd_189_3 stored as values in memory (estimated size 14.7 KB, free 354.3 MB)
18/05/31 14:47:26 INFO BlockManager: Found block rdd_184_1 locally
18/05/31 14:47:26 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:26 INFO MemoryStore: Block rdd_189_1 stored as values in memory (estimated size 14.7 KB, free 354.3 MB)
18/05/31 14:47:26 INFO BlockManagerInfo: Added rdd_189_3 in memory on 10.66.169.34:53539 (size: 14.7 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO BlockManagerInfo: Added rdd_189_1 in memory on 10.66.169.34:53539 (size: 14.7 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:26 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:26 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:26 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-147
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:26 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:26 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:26 WARN Executor: 1 block locks were not released by TID = 200:
[rdd_184_1]
18/05/31 14:47:26 INFO Executor: Finished task 1.0 in stage 290.0 (TID 200). 2359 bytes result sent to driver
18/05/31 14:47:26 INFO TaskSetManager: Finished task 1.0 in stage 290.0 (TID 200) in 12 ms on localhost (executor driver) (1/4)
18/05/31 14:47:26 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-145
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:26 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:26 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:26 WARN Executor: 1 block locks were not released by TID = 199:
[rdd_184_0]
18/05/31 14:47:26 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-146
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:26 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:26 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:26 INFO Executor: Finished task 0.0 in stage 290.0 (TID 199). 2359 bytes result sent to driver
18/05/31 14:47:26 INFO TaskSetManager: Finished task 0.0 in stage 290.0 (TID 199) in 15 ms on localhost (executor driver) (2/4)
18/05/31 14:47:26 WARN Executor: 1 block locks were not released by TID = 202:
[rdd_184_3]
18/05/31 14:47:26 INFO Executor: Finished task 3.0 in stage 290.0 (TID 202). 2359 bytes result sent to driver
18/05/31 14:47:26 INFO TaskSetManager: Finished task 3.0 in stage 290.0 (TID 202) in 17 ms on localhost (executor driver) (3/4)
18/05/31 14:47:26 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 10.66.169.34:53539 on disk (size: 4.5 KB)
18/05/31 14:47:26 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 10.66.169.34:53539 in memory (size: 4.5 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 10.66.169.34:53539 in memory (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO MemoryStore: 4 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:26 INFO BlockManager: Dropping block rdd_174_0 from memory
18/05/31 14:47:26 INFO BlockManagerInfo: Removed rdd_174_0 on 10.66.169.34:53539 in memory (size: 12.4 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO BlockManager: Dropping block rdd_174_3 from memory
18/05/31 14:47:26 INFO BlockManagerInfo: Removed rdd_174_3 on 10.66.169.34:53539 in memory (size: 12.4 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO BlockManager: Dropping block rdd_174_1 from memory
18/05/31 14:47:26 INFO BlockManagerInfo: Removed rdd_174_1 on 10.66.169.34:53539 in memory (size: 12.4 KB, free: 354.6 MB)
18/05/31 14:47:26 INFO BlockManager: Dropping block rdd_179_2 from memory
18/05/31 14:47:26 INFO BlockManagerInfo: Removed rdd_179_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:47:26 INFO MemoryStore: After dropping 4 blocks, free memory is 633.3 MB
18/05/31 14:47:27 INFO MemoryStore: Block rdd_189_2 stored as values in memory (estimated size 278.8 MB, free 354.5 MB)
18/05/31 14:47:27 INFO BlockManagerInfo: Added rdd_189_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.6 MB)
18/05/31 14:47:27 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:27 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-148
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:27 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:27 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:27 WARN Executor: 1 block locks were not released by TID = 201:
[rdd_184_2]
18/05/31 14:47:27 INFO Executor: Finished task 2.0 in stage 290.0 (TID 201). 2626 bytes result sent to driver
18/05/31 14:47:27 INFO TaskSetManager: Finished task 2.0 in stage 290.0 (TID 201) in 1715 ms on localhost (executor driver) (4/4)
18/05/31 14:47:27 INFO TaskSchedulerImpl: Removed TaskSet 290.0, whose tasks have all completed, from pool 
18/05/31 14:47:27 INFO DAGScheduler: ResultStage 290 (foreachPartition at AnomalyDetector.java:69) finished in 1.716 s
18/05/31 14:47:27 INFO DAGScheduler: Job 45 finished: foreachPartition at AnomalyDetector.java:69, took 1.736506 s
18/05/31 14:47:27 INFO JobScheduler: Finished job streaming job 1527767150000 ms.0 from job set of time 1527767150000 ms
18/05/31 14:47:27 INFO JobScheduler: Total delay: 97.723 s for time 1527767150000 ms (execution: 1.739 s)
18/05/31 14:47:27 INFO JobScheduler: Starting job streaming job 1527767160000 ms.0 from job set of time 1527767160000 ms
18/05/31 14:47:27 INFO MapPartitionsRDD: Removing RDD 185 from persistence list
18/05/31 14:47:27 INFO BlockManager: Removing RDD 185
18/05/31 14:47:27 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:27 INFO MapWithStateRDD: Removing RDD 89 from persistence list
18/05/31 14:47:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 37 is 149 bytes
18/05/31 14:47:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 149 bytes
18/05/31 14:47:27 INFO BlockManager: Removing RDD 89
18/05/31 14:47:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 149 bytes
18/05/31 14:47:27 INFO MapPartitionsRDD: Removing RDD 87 from persistence list
18/05/31 14:47:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 149 bytes
18/05/31 14:47:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 149 bytes
18/05/31 14:47:27 INFO KafkaRDD: Removing RDD 86 from persistence list
18/05/31 14:47:27 INFO BlockManager: Removing RDD 87
18/05/31 14:47:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 38 is 149 bytes
18/05/31 14:47:27 INFO BlockManager: Removing RDD 86
18/05/31 14:47:27 INFO JobGenerator: Checkpointing graph for time 1527767150000 ms
18/05/31 14:47:27 INFO DStreamGraph: Updating checkpoint data for time 1527767150000 ms
18/05/31 14:47:27 INFO DStreamGraph: Updated checkpoint data for time 1527767150000 ms
18/05/31 14:47:27 INFO CheckpointWriter: Submitted checkpoint of time 1527767150000 ms to writer queue
18/05/31 14:47:27 INFO CheckpointWriter: Saving checkpoint for time 1527767150000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000'
18/05/31 14:47:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 149 bytes
18/05/31 14:47:27 INFO DAGScheduler: Registering RDD 192 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:27 INFO DAGScheduler: Got job 46 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:27 INFO DAGScheduler: Final stage: ResultStage 299 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 291, ShuffleMapStage 292, ShuffleMapStage 296, ShuffleMapStage 293, ShuffleMapStage 297, ShuffleMapStage 294, ShuffleMapStage 298, ShuffleMapStage 295)
18/05/31 14:47:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 298)
18/05/31 14:47:27 INFO DAGScheduler: Submitting ShuffleMapStage 298 (MapPartitionsRDD[192] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:27 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 4.6 KB, free 354.5 MB)
18/05/31 14:47:27 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.5 MB)
18/05/31 14:47:27 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:47:27 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 298 (MapPartitionsRDD[192] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:27 INFO TaskSchedulerImpl: Adding task set 298.0 with 1 tasks
18/05/31 14:47:27 INFO TaskSetManager: Starting task 0.0 in stage 298.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:27 INFO Executor: Running task 0.0 in stage 298.0 (TID 203)
18/05/31 14:47:27 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:27 INFO MemoryStore: Block rdd_192_0 stored as bytes in memory (estimated size 4.0 B, free 354.5 MB)
18/05/31 14:47:27 INFO BlockManagerInfo: Added rdd_192_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.6 MB)
18/05/31 14:47:27 INFO Executor: Finished task 0.0 in stage 298.0 (TID 203). 1708 bytes result sent to driver
18/05/31 14:47:27 INFO TaskSetManager: Finished task 0.0 in stage 298.0 (TID 203) in 4 ms on localhost (executor driver) (1/1)
18/05/31 14:47:27 INFO TaskSchedulerImpl: Removed TaskSet 298.0, whose tasks have all completed, from pool 
18/05/31 14:47:27 INFO DAGScheduler: ShuffleMapStage 298 (mapToPair at AnomalyDetector.java:64) finished in 0.004 s
18/05/31 14:47:27 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:27 INFO DAGScheduler: running: Set()
18/05/31 14:47:27 INFO DAGScheduler: waiting: Set(ResultStage 299)
18/05/31 14:47:27 INFO DAGScheduler: failed: Set()
18/05/31 14:47:27 INFO DAGScheduler: Submitting ResultStage 299 (MapPartitionsRDD[195] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:27 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 9.7 KB, free 354.5 MB)
18/05/31 14:47:27 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 4.6 KB, free 354.5 MB)
18/05/31 14:47:27 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 10.66.169.34:53539 (size: 4.6 KB, free: 354.6 MB)
18/05/31 14:47:27 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 299 (MapPartitionsRDD[195] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:27 INFO TaskSchedulerImpl: Adding task set 299.0 with 4 tasks
18/05/31 14:47:27 INFO TaskSetManager: Starting task 0.0 in stage 299.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:27 INFO TaskSetManager: Starting task 1.0 in stage 299.0 (TID 205, localhost, executor driver, partition 1, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:27 INFO TaskSetManager: Starting task 2.0 in stage 299.0 (TID 206, localhost, executor driver, partition 2, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:27 INFO TaskSetManager: Starting task 3.0 in stage 299.0 (TID 207, localhost, executor driver, partition 3, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:27 INFO CheckpointWriter: Checkpoint for time 1527767150000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000', took 6091 bytes and 15 ms
18/05/31 14:47:27 INFO DStreamGraph: Clearing checkpoint data for time 1527767150000 ms
18/05/31 14:47:27 INFO Executor: Running task 0.0 in stage 299.0 (TID 204)
18/05/31 14:47:27 INFO Executor: Running task 2.0 in stage 299.0 (TID 206)
18/05/31 14:47:27 INFO DStreamGraph: Cleared checkpoint data for time 1527767150000 ms
18/05/31 14:47:27 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:27 INFO Executor: Running task 3.0 in stage 299.0 (TID 207)
18/05/31 14:47:27 INFO Executor: Running task 1.0 in stage 299.0 (TID 205)
18/05/31 14:47:27 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766950000: 
18/05/31 14:47:27 INFO BlockManager: Found block rdd_189_2 locally
18/05/31 14:47:27 INFO InputInfoTracker: remove old batch metadata: 1527766940000 ms
18/05/31 14:47:27 INFO BlockManager: Found block rdd_189_3 locally
18/05/31 14:47:27 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:27 INFO MemoryStore: Block rdd_194_3 stored as values in memory (estimated size 15.5 KB, free 354.5 MB)
18/05/31 14:47:27 INFO BlockManagerInfo: Added rdd_194_3 in memory on 10.66.169.34:53539 (size: 15.5 KB, free: 354.6 MB)
18/05/31 14:47:27 INFO BlockManager: Found block rdd_189_1 locally
18/05/31 14:47:27 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/05/31 14:47:27 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:27 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:27 INFO MemoryStore: Block rdd_194_1 stored as values in memory (estimated size 15.5 KB, free 354.4 MB)
18/05/31 14:47:27 INFO BlockManager: Found block rdd_189_0 locally
18/05/31 14:47:27 INFO BlockManagerInfo: Added rdd_194_1 in memory on 10.66.169.34:53539 (size: 15.5 KB, free: 354.6 MB)
18/05/31 14:47:27 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:27 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:27 INFO MemoryStore: Block rdd_194_0 stored as values in memory (estimated size 15.5 KB, free 354.4 MB)
18/05/31 14:47:27 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-149
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:27 INFO BlockManagerInfo: Added rdd_194_0 in memory on 10.66.169.34:53539 (size: 15.5 KB, free: 354.6 MB)
18/05/31 14:47:27 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:27 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:27 WARN Executor: 1 block locks were not released by TID = 207:
[rdd_189_3]
18/05/31 14:47:27 INFO Executor: Finished task 3.0 in stage 299.0 (TID 207). 2359 bytes result sent to driver
18/05/31 14:47:27 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:27 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-150
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:27 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:27 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:27 WARN Executor: 1 block locks were not released by TID = 205:
[rdd_189_1]
18/05/31 14:47:27 INFO Executor: Finished task 1.0 in stage 299.0 (TID 205). 2359 bytes result sent to driver
18/05/31 14:47:27 INFO TaskSetManager: Finished task 3.0 in stage 299.0 (TID 207) in 9 ms on localhost (executor driver) (1/4)
18/05/31 14:47:27 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-151
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:27 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:27 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:27 WARN Executor: 1 block locks were not released by TID = 204:
[rdd_189_0]
18/05/31 14:47:27 INFO Executor: Finished task 0.0 in stage 299.0 (TID 204). 2359 bytes result sent to driver
18/05/31 14:47:27 INFO TaskSetManager: Finished task 1.0 in stage 299.0 (TID 205) in 12 ms on localhost (executor driver) (2/4)
18/05/31 14:47:27 INFO TaskSetManager: Finished task 0.0 in stage 299.0 (TID 204) in 12 ms on localhost (executor driver) (3/4)
18/05/31 14:47:28 INFO MemoryStore: 12 blocks selected for dropping (279.0 MB bytes)
18/05/31 14:47:28 INFO BlockManager: Dropping block rdd_179_3 from memory
18/05/31 14:47:28 INFO BlockManagerInfo: Removed rdd_179_3 on 10.66.169.34:53539 in memory (size: 13.2 KB, free: 354.6 MB)
18/05/31 14:47:28 INFO BlockManager: Dropping block rdd_179_1 from memory
18/05/31 14:47:28 INFO BlockManagerInfo: Removed rdd_179_1 on 10.66.169.34:53539 in memory (size: 13.2 KB, free: 354.6 MB)
18/05/31 14:47:28 INFO BlockManager: Dropping block rdd_179_0 from memory
18/05/31 14:47:28 INFO BlockManagerInfo: Removed rdd_179_0 on 10.66.169.34:53539 in memory (size: 13.2 KB, free: 354.6 MB)
18/05/31 14:47:28 INFO BlockManager: Dropping block rdd_182_0 from memory
18/05/31 14:47:28 INFO BlockManagerInfo: Removed rdd_182_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.6 MB)
18/05/31 14:47:28 INFO BlockManager: Dropping block broadcast_98 from memory
18/05/31 14:47:28 INFO BlockManager: Writing block broadcast_98 to disk
18/05/31 14:47:28 INFO BlockManager: Dropping block broadcast_98_piece0 from memory
18/05/31 14:47:28 INFO BlockManager: Writing block broadcast_98_piece0 to disk
18/05/31 14:47:28 INFO BlockManagerInfo: Added broadcast_98_piece0 on disk on 10.66.169.34:53539 (size: 14.3 KB)
18/05/31 14:47:28 INFO BlockManager: Dropping block rdd_187_0 from memory
18/05/31 14:47:28 INFO BlockManagerInfo: Removed rdd_187_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.6 MB)
18/05/31 14:47:28 INFO BlockManager: Dropping block broadcast_100_piece0 from memory
18/05/31 14:47:28 INFO BlockManager: Writing block broadcast_100_piece0 to disk
18/05/31 14:47:28 INFO BlockManagerInfo: Added broadcast_100_piece0 on disk on 10.66.169.34:53539 (size: 4.6 KB)
18/05/31 14:47:28 INFO BlockManager: Dropping block broadcast_100 from memory
18/05/31 14:47:28 INFO BlockManager: Writing block broadcast_100 to disk
18/05/31 14:47:28 INFO BlockManager: Dropping block rdd_184_0 from memory
18/05/31 14:47:28 INFO BlockManagerInfo: Removed rdd_184_0 on 10.66.169.34:53539 in memory (size: 13.9 KB, free: 354.7 MB)
18/05/31 14:47:28 INFO BlockManager: Dropping block rdd_184_3 from memory
18/05/31 14:47:28 INFO BlockManagerInfo: Removed rdd_184_3 on 10.66.169.34:53539 in memory (size: 13.9 KB, free: 354.7 MB)
18/05/31 14:47:28 INFO BlockManager: Dropping block rdd_184_2 from memory
18/05/31 14:47:28 INFO BlockManagerInfo: Removed rdd_184_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:47:28 INFO MemoryStore: After dropping 12 blocks, free memory is 633.4 MB
18/05/31 14:47:29 INFO MemoryStore: Block rdd_194_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:29 INFO BlockManagerInfo: Added rdd_194_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:29 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:29 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-152
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:29 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:29 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:29 WARN Executor: 1 block locks were not released by TID = 206:
[rdd_189_2]
18/05/31 14:47:29 INFO Executor: Finished task 2.0 in stage 299.0 (TID 206). 3056 bytes result sent to driver
18/05/31 14:47:29 INFO TaskSetManager: Finished task 2.0 in stage 299.0 (TID 206) in 1673 ms on localhost (executor driver) (4/4)
18/05/31 14:47:29 INFO TaskSchedulerImpl: Removed TaskSet 299.0, whose tasks have all completed, from pool 
18/05/31 14:47:29 INFO DAGScheduler: ResultStage 299 (foreachPartition at AnomalyDetector.java:69) finished in 1.673 s
18/05/31 14:47:29 INFO DAGScheduler: Job 46 finished: foreachPartition at AnomalyDetector.java:69, took 1.692296 s
18/05/31 14:47:29 INFO JobScheduler: Finished job streaming job 1527767160000 ms.0 from job set of time 1527767160000 ms
18/05/31 14:47:29 INFO JobScheduler: Total delay: 89.420 s for time 1527767160000 ms (execution: 1.696 s)
18/05/31 14:47:29 INFO JobScheduler: Starting job streaming job 1527767170000 ms.0 from job set of time 1527767170000 ms
18/05/31 14:47:29 INFO MapPartitionsRDD: Removing RDD 190 from persistence list
18/05/31 14:47:29 INFO BlockManager: Removing RDD 190
18/05/31 14:47:29 INFO MapWithStateRDD: Removing RDD 94 from persistence list
18/05/31 14:47:29 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:29 INFO BlockManager: Removing RDD 94
18/05/31 14:47:29 INFO MapPartitionsRDD: Removing RDD 92 from persistence list
18/05/31 14:47:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 37 is 149 bytes
18/05/31 14:47:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 149 bytes
18/05/31 14:47:29 INFO DAGScheduler: Registering RDD 197 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:29 INFO BlockManager: Removing RDD 92
18/05/31 14:47:29 INFO KafkaRDD: Removing RDD 91 from persistence list
18/05/31 14:47:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 149 bytes
18/05/31 14:47:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 149 bytes
18/05/31 14:47:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 149 bytes
18/05/31 14:47:29 INFO BlockManager: Removing RDD 91
18/05/31 14:47:29 INFO JobGenerator: Checkpointing graph for time 1527767160000 ms
18/05/31 14:47:29 INFO DStreamGraph: Updating checkpoint data for time 1527767160000 ms
18/05/31 14:47:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 38 is 149 bytes
18/05/31 14:47:29 INFO DStreamGraph: Updated checkpoint data for time 1527767160000 ms
18/05/31 14:47:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 149 bytes
18/05/31 14:47:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 39 is 149 bytes
18/05/31 14:47:29 INFO CheckpointWriter: Submitted checkpoint of time 1527767160000 ms to writer queue
18/05/31 14:47:29 INFO DAGScheduler: Got job 47 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:29 INFO DAGScheduler: Final stage: ResultStage 309 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 305, ShuffleMapStage 302, ShuffleMapStage 306, ShuffleMapStage 303, ShuffleMapStage 300, ShuffleMapStage 307, ShuffleMapStage 304, ShuffleMapStage 308, ShuffleMapStage 301)
18/05/31 14:47:29 INFO CheckpointWriter: Saving checkpoint for time 1527767160000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000'
18/05/31 14:47:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 302)
18/05/31 14:47:29 INFO DAGScheduler: Submitting ShuffleMapStage 302 (MapPartitionsRDD[197] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:29 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 4.6 KB, free 354.6 MB)
18/05/31 14:47:29 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.6 MB)
18/05/31 14:47:29 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:29 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 302 (MapPartitionsRDD[197] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:29 INFO TaskSchedulerImpl: Adding task set 302.0 with 1 tasks
18/05/31 14:47:29 INFO TaskSetManager: Starting task 0.0 in stage 302.0 (TID 208, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:29 INFO Executor: Running task 0.0 in stage 302.0 (TID 208)
18/05/31 14:47:29 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:29 INFO MemoryStore: Block rdd_197_0 stored as bytes in memory (estimated size 4.0 B, free 354.6 MB)
18/05/31 14:47:29 INFO BlockManagerInfo: Added rdd_197_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:29 INFO Executor: Finished task 0.0 in stage 302.0 (TID 208). 1708 bytes result sent to driver
18/05/31 14:47:29 INFO TaskSetManager: Finished task 0.0 in stage 302.0 (TID 208) in 5 ms on localhost (executor driver) (1/1)
18/05/31 14:47:29 INFO TaskSchedulerImpl: Removed TaskSet 302.0, whose tasks have all completed, from pool 
18/05/31 14:47:29 INFO DAGScheduler: ShuffleMapStage 302 (mapToPair at AnomalyDetector.java:64) finished in 0.007 s
18/05/31 14:47:29 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:29 INFO DAGScheduler: running: Set()
18/05/31 14:47:29 INFO DAGScheduler: waiting: Set(ResultStage 309)
18/05/31 14:47:29 INFO DAGScheduler: failed: Set()
18/05/31 14:47:29 INFO DAGScheduler: Submitting ResultStage 309 (MapPartitionsRDD[200] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:29 INFO CheckpointWriter: Checkpoint for time 1527767160000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767240000', took 6059 bytes and 20 ms
18/05/31 14:47:29 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 10.0 KB, free 354.6 MB)
18/05/31 14:47:29 INFO DStreamGraph: Clearing checkpoint data for time 1527767160000 ms
18/05/31 14:47:29 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 4.7 KB, free 354.6 MB)
18/05/31 14:47:29 INFO DStreamCheckpointData: Deleted checkpoint file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-92' for time 1527766960000 ms
18/05/31 14:47:29 INFO DStreamGraph: Cleared checkpoint data for time 1527767160000 ms
18/05/31 14:47:29 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 10.66.169.34:53539 (size: 4.7 KB, free: 354.7 MB)
18/05/31 14:47:29 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:29 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:29 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766960000: 
18/05/31 14:47:29 INFO InputInfoTracker: remove old batch metadata: 1527766950000 ms
18/05/31 14:47:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 309 (MapPartitionsRDD[200] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:29 INFO TaskSchedulerImpl: Adding task set 309.0 with 4 tasks
18/05/31 14:47:29 INFO TaskSetManager: Starting task 0.0 in stage 309.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:29 INFO TaskSetManager: Starting task 1.0 in stage 309.0 (TID 210, localhost, executor driver, partition 1, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:29 INFO TaskSetManager: Starting task 2.0 in stage 309.0 (TID 211, localhost, executor driver, partition 2, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:29 INFO TaskSetManager: Starting task 3.0 in stage 309.0 (TID 212, localhost, executor driver, partition 3, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:29 INFO Executor: Running task 2.0 in stage 309.0 (TID 211)
18/05/31 14:47:29 INFO Executor: Running task 3.0 in stage 309.0 (TID 212)
18/05/31 14:47:29 INFO Executor: Running task 1.0 in stage 309.0 (TID 210)
18/05/31 14:47:29 INFO BlockManager: Found block rdd_194_2 locally
18/05/31 14:47:29 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:29 INFO BlockManager: Found block rdd_194_3 locally
18/05/31 14:47:29 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:29 INFO MemoryStore: Block rdd_199_3 stored as values in memory (estimated size 16.2 KB, free 354.6 MB)
18/05/31 14:47:29 INFO BlockManagerInfo: Added rdd_199_3 in memory on 10.66.169.34:53539 (size: 16.2 KB, free: 354.6 MB)
18/05/31 14:47:29 INFO BlockManager: Found block rdd_194_1 locally
18/05/31 14:47:29 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:29 INFO MemoryStore: Block rdd_199_1 stored as values in memory (estimated size 16.2 KB, free 354.6 MB)
18/05/31 14:47:29 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:29 INFO BlockManagerInfo: Added rdd_199_1 in memory on 10.66.169.34:53539 (size: 16.2 KB, free: 354.6 MB)
18/05/31 14:47:29 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-153
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:29 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:29 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:29 WARN Executor: 1 block locks were not released by TID = 212:
[rdd_194_3]
18/05/31 14:47:29 INFO Executor: Finished task 3.0 in stage 309.0 (TID 212). 2359 bytes result sent to driver
18/05/31 14:47:29 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:29 INFO TaskSetManager: Finished task 3.0 in stage 309.0 (TID 212) in 10 ms on localhost (executor driver) (1/4)
18/05/31 14:47:29 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-154
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:29 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:29 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:29 WARN Executor: 1 block locks were not released by TID = 210:
[rdd_194_1]
18/05/31 14:47:29 INFO Executor: Finished task 1.0 in stage 309.0 (TID 210). 2359 bytes result sent to driver
18/05/31 14:47:29 INFO TaskSetManager: Finished task 1.0 in stage 309.0 (TID 210) in 13 ms on localhost (executor driver) (2/4)
18/05/31 14:47:29 INFO Executor: Running task 0.0 in stage 309.0 (TID 209)
18/05/31 14:47:29 INFO BlockManager: Found block rdd_194_0 locally
18/05/31 14:47:29 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
18/05/31 14:47:29 INFO MemoryStore: Block rdd_199_0 stored as values in memory (estimated size 16.2 KB, free 354.6 MB)
18/05/31 14:47:29 INFO BlockManagerInfo: Added rdd_199_0 in memory on 10.66.169.34:53539 (size: 16.2 KB, free: 354.6 MB)
18/05/31 14:47:29 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:29 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-155
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:29 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:29 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:29 WARN Executor: 1 block locks were not released by TID = 209:
[rdd_194_0]
18/05/31 14:47:29 INFO Executor: Finished task 0.0 in stage 309.0 (TID 209). 2359 bytes result sent to driver
18/05/31 14:47:29 INFO TaskSetManager: Finished task 0.0 in stage 309.0 (TID 209) in 27 ms on localhost (executor driver) (3/4)
18/05/31 14:47:30 INFO JobScheduler: Added jobs for time 1527767250000 ms
18/05/31 14:47:30 INFO JobGenerator: Checkpointing graph for time 1527767250000 ms
18/05/31 14:47:30 INFO DStreamGraph: Updating checkpoint data for time 1527767250000 ms
18/05/31 14:47:30 INFO DStreamGraph: Updated checkpoint data for time 1527767250000 ms
18/05/31 14:47:30 INFO CheckpointWriter: Submitted checkpoint of time 1527767250000 ms to writer queue
18/05/31 14:47:30 INFO CheckpointWriter: Saving checkpoint for time 1527767250000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767250000'
18/05/31 14:47:30 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 10.66.169.34:53539 on disk (size: 4.6 KB)
18/05/31 14:47:30 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:47:30 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 10.66.169.34:53539 in memory (size: 4.6 KB, free: 354.6 MB)
18/05/31 14:47:30 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:47:30 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000.bk
18/05/31 14:47:30 INFO CheckpointWriter: Checkpoint for time 1527767250000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767250000', took 6076 bytes and 52 ms
18/05/31 14:47:30 INFO MemoryStore: 3 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:30 INFO BlockManager: Dropping block rdd_184_1 from memory
18/05/31 14:47:30 INFO BlockManagerInfo: Removed rdd_184_1 on 10.66.169.34:53539 in memory (size: 13.9 KB, free: 354.6 MB)
18/05/31 14:47:30 INFO BlockManager: Dropping block rdd_192_0 from memory
18/05/31 14:47:30 INFO BlockManagerInfo: Removed rdd_192_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.6 MB)
18/05/31 14:47:30 INFO BlockManager: Dropping block rdd_189_2 from memory
18/05/31 14:47:30 INFO BlockManagerInfo: Removed rdd_189_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:47:30 INFO MemoryStore: After dropping 3 blocks, free memory is 633.4 MB
18/05/31 14:47:32 INFO MemoryStore: Block rdd_199_2 stored as values in memory (estimated size 278.8 MB, free 354.6 MB)
18/05/31 14:47:32 INFO BlockManagerInfo: Added rdd_199_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.6 MB)
18/05/31 14:47:32 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:32 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-156
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:32 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:32 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:32 WARN Executor: 1 block locks were not released by TID = 211:
[rdd_194_2]
18/05/31 14:47:32 INFO Executor: Finished task 2.0 in stage 309.0 (TID 211). 2666 bytes result sent to driver
18/05/31 14:47:32 INFO TaskSetManager: Finished task 2.0 in stage 309.0 (TID 211) in 2731 ms on localhost (executor driver) (4/4)
18/05/31 14:47:32 INFO TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool 
18/05/31 14:47:32 INFO DAGScheduler: ResultStage 309 (foreachPartition at AnomalyDetector.java:69) finished in 2.731 s
18/05/31 14:47:32 INFO DAGScheduler: Job 47 finished: foreachPartition at AnomalyDetector.java:69, took 2.760215 s
18/05/31 14:47:32 INFO JobScheduler: Finished job streaming job 1527767170000 ms.0 from job set of time 1527767170000 ms
18/05/31 14:47:32 INFO JobScheduler: Total delay: 82.184 s for time 1527767170000 ms (execution: 2.764 s)
18/05/31 14:47:32 INFO JobScheduler: Starting job streaming job 1527767180000 ms.0 from job set of time 1527767180000 ms
18/05/31 14:47:32 INFO MapPartitionsRDD: Removing RDD 195 from persistence list
18/05/31 14:47:32 INFO BlockManager: Removing RDD 195
18/05/31 14:47:32 INFO MapWithStateRDD: Removing RDD 99 from persistence list
18/05/31 14:47:32 INFO BlockManager: Removing RDD 99
18/05/31 14:47:32 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:32 INFO MapPartitionsRDD: Removing RDD 97 from persistence list
18/05/31 14:47:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 37 is 149 bytes
18/05/31 14:47:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 149 bytes
18/05/31 14:47:32 INFO KafkaRDD: Removing RDD 96 from persistence list
18/05/31 14:47:32 INFO BlockManager: Removing RDD 97
18/05/31 14:47:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 40 is 149 bytes
18/05/31 14:47:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 149 bytes
18/05/31 14:47:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 149 bytes
18/05/31 14:47:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 149 bytes
18/05/31 14:47:32 INFO DAGScheduler: Registering RDD 202 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 38 is 149 bytes
18/05/31 14:47:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 149 bytes
18/05/31 14:47:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 39 is 149 bytes
18/05/31 14:47:32 INFO DAGScheduler: Got job 48 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:32 INFO DAGScheduler: Final stage: ResultStage 320 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 317, ShuffleMapStage 318, ShuffleMapStage 310, ShuffleMapStage 314, ShuffleMapStage 311, ShuffleMapStage 315, ShuffleMapStage 312, ShuffleMapStage 319, ShuffleMapStage 316, ShuffleMapStage 313)
18/05/31 14:47:32 INFO JobGenerator: Checkpointing graph for time 1527767170000 ms
18/05/31 14:47:32 INFO DStreamGraph: Updating checkpoint data for time 1527767170000 ms
18/05/31 14:47:32 INFO BlockManager: Removing RDD 96
18/05/31 14:47:32 INFO DStreamGraph: Updated checkpoint data for time 1527767170000 ms
18/05/31 14:47:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 316)
18/05/31 14:47:32 INFO CheckpointWriter: Submitted checkpoint of time 1527767170000 ms to writer queue
18/05/31 14:47:32 INFO DAGScheduler: Submitting ShuffleMapStage 316 (MapPartitionsRDD[202] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:32 INFO CheckpointWriter: Saving checkpoint for time 1527767170000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767250000'
18/05/31 14:47:32 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 4.6 KB, free 354.6 MB)
18/05/31 14:47:32 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.6 MB)
18/05/31 14:47:32 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:47:32 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 316 (MapPartitionsRDD[202] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:32 INFO TaskSchedulerImpl: Adding task set 316.0 with 1 tasks
18/05/31 14:47:32 INFO TaskSetManager: Starting task 0.0 in stage 316.0 (TID 213, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:32 INFO Executor: Running task 0.0 in stage 316.0 (TID 213)
18/05/31 14:47:32 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:32 INFO MemoryStore: Block rdd_202_0 stored as bytes in memory (estimated size 4.0 B, free 354.6 MB)
18/05/31 14:47:32 INFO BlockManagerInfo: Added rdd_202_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.6 MB)
18/05/31 14:47:32 INFO Executor: Finished task 0.0 in stage 316.0 (TID 213). 1708 bytes result sent to driver
18/05/31 14:47:32 INFO TaskSetManager: Finished task 0.0 in stage 316.0 (TID 213) in 10 ms on localhost (executor driver) (1/1)
18/05/31 14:47:32 INFO TaskSchedulerImpl: Removed TaskSet 316.0, whose tasks have all completed, from pool 
18/05/31 14:47:32 INFO DAGScheduler: ShuffleMapStage 316 (mapToPair at AnomalyDetector.java:64) finished in 0.010 s
18/05/31 14:47:32 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:32 INFO DAGScheduler: running: Set()
18/05/31 14:47:32 INFO DAGScheduler: waiting: Set(ResultStage 320)
18/05/31 14:47:32 INFO DAGScheduler: failed: Set()
18/05/31 14:47:32 INFO DAGScheduler: Submitting ResultStage 320 (MapPartitionsRDD[205] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:32 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 10.5 KB, free 354.6 MB)
18/05/31 14:47:32 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 4.8 KB, free 354.6 MB)
18/05/31 14:47:32 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 10.66.169.34:53539 (size: 4.8 KB, free: 354.6 MB)
18/05/31 14:47:32 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:32 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 320 (MapPartitionsRDD[205] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:32 INFO TaskSchedulerImpl: Adding task set 320.0 with 4 tasks
18/05/31 14:47:32 INFO TaskSetManager: Starting task 0.0 in stage 320.0 (TID 214, localhost, executor driver, partition 0, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:47:32 INFO TaskSetManager: Starting task 1.0 in stage 320.0 (TID 215, localhost, executor driver, partition 1, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:47:32 INFO TaskSetManager: Starting task 2.0 in stage 320.0 (TID 216, localhost, executor driver, partition 2, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:47:32 INFO TaskSetManager: Starting task 3.0 in stage 320.0 (TID 217, localhost, executor driver, partition 3, PROCESS_LOCAL, 6600 bytes)
18/05/31 14:47:32 INFO Executor: Running task 0.0 in stage 320.0 (TID 214)
18/05/31 14:47:32 INFO Executor: Running task 2.0 in stage 320.0 (TID 216)
18/05/31 14:47:32 INFO Executor: Running task 3.0 in stage 320.0 (TID 217)
18/05/31 14:47:32 INFO BlockManager: Found block rdd_199_3 locally
18/05/31 14:47:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:32 INFO MemoryStore: Block rdd_204_3 stored as values in memory (estimated size 17.0 KB, free 354.6 MB)
18/05/31 14:47:32 INFO BlockManagerInfo: Added rdd_204_3 in memory on 10.66.169.34:53539 (size: 17.0 KB, free: 354.6 MB)
18/05/31 14:47:32 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767200000
18/05/31 14:47:32 INFO BlockManager: Found block rdd_199_0 locally
18/05/31 14:47:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:32 INFO MemoryStore: Block rdd_204_0 stored as values in memory (estimated size 17.0 KB, free 354.6 MB)
18/05/31 14:47:32 INFO CheckpointWriter: Checkpoint for time 1527767170000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767250000', took 6070 bytes and 29 ms
18/05/31 14:47:32 INFO BlockManagerInfo: Added rdd_204_0 in memory on 10.66.169.34:53539 (size: 17.0 KB, free: 354.6 MB)
18/05/31 14:47:32 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:32 INFO DStreamGraph: Clearing checkpoint data for time 1527767170000 ms
18/05/31 14:47:32 INFO DStreamGraph: Cleared checkpoint data for time 1527767170000 ms
18/05/31 14:47:32 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:32 INFO BlockManager: Found block rdd_199_2 locally
18/05/31 14:47:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:32 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:32 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-157
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:32 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:32 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:32 WARN Executor: 1 block locks were not released by TID = 217:
[rdd_199_3]
18/05/31 14:47:32 INFO Executor: Finished task 3.0 in stage 320.0 (TID 217). 2359 bytes result sent to driver
18/05/31 14:47:32 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766970000: 
18/05/31 14:47:32 INFO InputInfoTracker: remove old batch metadata: 1527766960000 ms
18/05/31 14:47:32 INFO TaskSetManager: Finished task 3.0 in stage 320.0 (TID 217) in 27 ms on localhost (executor driver) (1/4)
18/05/31 14:47:32 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-158
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:32 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:32 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:32 WARN Executor: 1 block locks were not released by TID = 214:
[rdd_199_0]
18/05/31 14:47:32 INFO Executor: Finished task 0.0 in stage 320.0 (TID 214). 2359 bytes result sent to driver
18/05/31 14:47:32 INFO TaskSetManager: Finished task 0.0 in stage 320.0 (TID 214) in 40 ms on localhost (executor driver) (2/4)
18/05/31 14:47:32 INFO Executor: Running task 1.0 in stage 320.0 (TID 215)
18/05/31 14:47:32 INFO BlockManager: Found block rdd_199_1 locally
18/05/31 14:47:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:32 INFO MemoryStore: Block rdd_204_1 stored as values in memory (estimated size 17.0 KB, free 354.5 MB)
18/05/31 14:47:32 INFO BlockManagerInfo: Added rdd_204_1 in memory on 10.66.169.34:53539 (size: 17.0 KB, free: 354.6 MB)
18/05/31 14:47:32 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:32 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-159
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:32 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:32 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:32 WARN Executor: 1 block locks were not released by TID = 215:
[rdd_199_1]
18/05/31 14:47:32 INFO Executor: Finished task 1.0 in stage 320.0 (TID 215). 2359 bytes result sent to driver
18/05/31 14:47:32 INFO TaskSetManager: Finished task 1.0 in stage 320.0 (TID 215) in 72 ms on localhost (executor driver) (3/4)
18/05/31 14:47:33 INFO MemoryStore: 6 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:33 INFO BlockManager: Dropping block rdd_189_3 from memory
18/05/31 14:47:33 INFO BlockManagerInfo: Removed rdd_189_3 on 10.66.169.34:53539 in memory (size: 14.7 KB, free: 354.6 MB)
18/05/31 14:47:33 INFO BlockManager: Dropping block rdd_189_1 from memory
18/05/31 14:47:33 INFO BlockManagerInfo: Removed rdd_189_1 on 10.66.169.34:53539 in memory (size: 14.7 KB, free: 354.6 MB)
18/05/31 14:47:33 INFO BlockManager: Dropping block rdd_189_0 from memory
18/05/31 14:47:33 INFO BlockManagerInfo: Removed rdd_189_0 on 10.66.169.34:53539 in memory (size: 14.7 KB, free: 354.6 MB)
18/05/31 14:47:33 INFO BlockManager: Dropping block rdd_197_0 from memory
18/05/31 14:47:33 INFO BlockManagerInfo: Removed rdd_197_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.6 MB)
18/05/31 14:47:33 INFO BlockManager: Dropping block broadcast_104_piece0 from memory
18/05/31 14:47:33 INFO BlockManager: Writing block broadcast_104_piece0 to disk
18/05/31 14:47:33 INFO BlockManagerInfo: Added broadcast_104_piece0 on disk on 10.66.169.34:53539 (size: 4.7 KB)
18/05/31 14:47:33 INFO BlockManager: Dropping block rdd_194_2 from memory
18/05/31 14:47:33 INFO BlockManagerInfo: Removed rdd_194_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:47:33 INFO MemoryStore: After dropping 6 blocks, free memory is 633.4 MB
18/05/31 14:47:34 INFO MemoryStore: Block rdd_204_2 stored as values in memory (estimated size 278.8 MB, free 354.6 MB)
18/05/31 14:47:34 INFO BlockManagerInfo: Added rdd_204_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.6 MB)
18/05/31 14:47:34 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:34 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-160
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:34 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:34 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:34 WARN Executor: 1 block locks were not released by TID = 216:
[rdd_199_2]
18/05/31 14:47:34 INFO Executor: Finished task 2.0 in stage 320.0 (TID 216). 2757 bytes result sent to driver
18/05/31 14:47:34 INFO TaskSetManager: Finished task 2.0 in stage 320.0 (TID 216) in 2295 ms on localhost (executor driver) (4/4)
18/05/31 14:47:34 INFO TaskSchedulerImpl: Removed TaskSet 320.0, whose tasks have all completed, from pool 
18/05/31 14:47:34 INFO DAGScheduler: ResultStage 320 (foreachPartition at AnomalyDetector.java:69) finished in 2.297 s
18/05/31 14:47:34 INFO DAGScheduler: Job 48 finished: foreachPartition at AnomalyDetector.java:69, took 2.326459 s
18/05/31 14:47:34 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 127.1 KB, free 354.5 MB)
18/05/31 14:47:34 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.5 MB)
18/05/31 14:47:34 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:47:34 INFO SparkContext: Created broadcast 107 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:34 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 37 is 149 bytes
18/05/31 14:47:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 149 bytes
18/05/31 14:47:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 40 is 149 bytes
18/05/31 14:47:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 149 bytes
18/05/31 14:47:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 149 bytes
18/05/31 14:47:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 149 bytes
18/05/31 14:47:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 41 is 149 bytes
18/05/31 14:47:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 38 is 149 bytes
18/05/31 14:47:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 149 bytes
18/05/31 14:47:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 39 is 149 bytes
18/05/31 14:47:34 INFO DAGScheduler: Got job 49 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:34 INFO DAGScheduler: Final stage: ResultStage 331 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 324, ShuffleMapStage 321, ShuffleMapStage 328, ShuffleMapStage 325, ShuffleMapStage 322, ShuffleMapStage 329, ShuffleMapStage 326, ShuffleMapStage 323, ShuffleMapStage 330, ShuffleMapStage 327)
18/05/31 14:47:34 INFO DAGScheduler: Missing parents: List()
18/05/31 14:47:34 INFO DAGScheduler: Submitting ResultStage 331 (MapWithStateRDD[204] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:34 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 10.0 KB, free 354.4 MB)
18/05/31 14:47:34 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.4 MB)
18/05/31 14:47:34 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 10.66.169.34:53539 (size: 4.5 KB, free: 354.6 MB)
18/05/31 14:47:34 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 331 (MapWithStateRDD[204] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:34 INFO TaskSchedulerImpl: Adding task set 331.0 with 4 tasks
18/05/31 14:47:34 INFO TaskSetManager: Starting task 0.0 in stage 331.0 (TID 218, localhost, executor driver, partition 0, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:47:34 INFO TaskSetManager: Starting task 1.0 in stage 331.0 (TID 219, localhost, executor driver, partition 1, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:47:34 INFO TaskSetManager: Starting task 2.0 in stage 331.0 (TID 220, localhost, executor driver, partition 2, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:47:34 INFO TaskSetManager: Starting task 3.0 in stage 331.0 (TID 221, localhost, executor driver, partition 3, PROCESS_LOCAL, 6529 bytes)
18/05/31 14:47:34 INFO Executor: Running task 2.0 in stage 331.0 (TID 220)
18/05/31 14:47:34 INFO Executor: Running task 1.0 in stage 331.0 (TID 219)
18/05/31 14:47:34 INFO Executor: Running task 3.0 in stage 331.0 (TID 221)
18/05/31 14:47:34 INFO Executor: Running task 0.0 in stage 331.0 (TID 218)
18/05/31 14:47:34 INFO BlockManager: Found block rdd_204_2 locally
18/05/31 14:47:34 INFO BlockManager: Found block rdd_204_3 locally
18/05/31 14:47:34 INFO BlockManager: Found block rdd_204_1 locally
18/05/31 14:47:34 INFO BlockManager: Found block rdd_204_0 locally
18/05/31 14:47:34 INFO Executor: Finished task 1.0 in stage 331.0 (TID 219). 1085 bytes result sent to driver
18/05/31 14:47:34 INFO Executor: Finished task 3.0 in stage 331.0 (TID 221). 1085 bytes result sent to driver
18/05/31 14:47:34 INFO TaskSetManager: Finished task 1.0 in stage 331.0 (TID 219) in 15 ms on localhost (executor driver) (1/4)
18/05/31 14:47:34 INFO TaskSetManager: Finished task 3.0 in stage 331.0 (TID 221) in 16 ms on localhost (executor driver) (2/4)
18/05/31 14:47:34 INFO Executor: Finished task 0.0 in stage 331.0 (TID 218). 1085 bytes result sent to driver
18/05/31 14:47:34 INFO TaskSetManager: Finished task 0.0 in stage 331.0 (TID 218) in 21 ms on localhost (executor driver) (3/4)
18/05/31 14:47:34 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:47:34 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 10.66.169.34:53539 on disk (size: 4.7 KB)
18/05/31 14:47:34 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 10.66.169.34:53539 in memory (size: 4.8 KB, free: 354.6 MB)
18/05/31 14:47:36 INFO Executor: Finished task 2.0 in stage 331.0 (TID 220). 1158 bytes result sent to driver
18/05/31 14:47:36 INFO TaskSetManager: Finished task 2.0 in stage 331.0 (TID 220) in 1609 ms on localhost (executor driver) (4/4)
18/05/31 14:47:36 INFO TaskSchedulerImpl: Removed TaskSet 331.0, whose tasks have all completed, from pool 
18/05/31 14:47:36 INFO DAGScheduler: ResultStage 331 (foreachPartition at AnomalyDetector.java:69) finished in 1.610 s
18/05/31 14:47:36 INFO DAGScheduler: Job 49 finished: foreachPartition at AnomalyDetector.java:69, took 1.614868 s
18/05/31 14:47:36 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 127.1 KB, free 354.4 MB)
18/05/31 14:47:36 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.3 MB)
18/05/31 14:47:36 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.6 MB)
18/05/31 14:47:36 INFO SparkContext: Created broadcast 109 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:36 INFO ReliableRDDCheckpointData: Done checkpointing RDD 204 to file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-204, new parent is RDD 250
18/05/31 14:47:36 INFO JobScheduler: Finished job streaming job 1527767180000 ms.0 from job set of time 1527767180000 ms
18/05/31 14:47:36 INFO JobScheduler: Total delay: 76.161 s for time 1527767180000 ms (execution: 3.976 s)
18/05/31 14:47:36 INFO MapPartitionsRDD: Removing RDD 200 from persistence list
18/05/31 14:47:36 INFO JobScheduler: Starting job streaming job 1527767190000 ms.0 from job set of time 1527767190000 ms
18/05/31 14:47:36 INFO BlockManager: Removing RDD 200
18/05/31 14:47:36 INFO MapWithStateRDD: Removing RDD 104 from persistence list
18/05/31 14:47:36 INFO BlockManager: Removing RDD 104
18/05/31 14:47:36 INFO MapPartitionsRDD: Removing RDD 102 from persistence list
18/05/31 14:47:36 INFO BlockManager: Removing RDD 102
18/05/31 14:47:36 INFO KafkaRDD: Removing RDD 101 from persistence list
18/05/31 14:47:36 INFO BlockManager: Removing RDD 101
18/05/31 14:47:36 INFO JobGenerator: Checkpointing graph for time 1527767180000 ms
18/05/31 14:47:36 INFO DStreamGraph: Updating checkpoint data for time 1527767180000 ms
18/05/31 14:47:36 INFO DStreamGraph: Updated checkpoint data for time 1527767180000 ms
18/05/31 14:47:36 INFO CheckpointWriter: Submitted checkpoint of time 1527767180000 ms to writer queue
18/05/31 14:47:36 INFO CheckpointWriter: Saving checkpoint for time 1527767180000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767250000'
18/05/31 14:47:36 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:36 INFO DAGScheduler: Registering RDD 208 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:36 INFO DAGScheduler: Got job 50 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:36 INFO DAGScheduler: Final stage: ResultStage 333 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 332)
18/05/31 14:47:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 332)
18/05/31 14:47:36 INFO DAGScheduler: Submitting ShuffleMapStage 332 (MapPartitionsRDD[208] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:36 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 4.6 KB, free 354.3 MB)
18/05/31 14:47:36 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.3 MB)
18/05/31 14:47:36 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.6 MB)
18/05/31 14:47:36 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 332 (MapPartitionsRDD[208] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:36 INFO TaskSchedulerImpl: Adding task set 332.0 with 1 tasks
18/05/31 14:47:36 INFO TaskSetManager: Starting task 0.0 in stage 332.0 (TID 222, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:36 INFO Executor: Running task 0.0 in stage 332.0 (TID 222)
18/05/31 14:47:36 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:36 INFO MemoryStore: Block rdd_208_0 stored as bytes in memory (estimated size 4.0 B, free 354.3 MB)
18/05/31 14:47:36 INFO BlockManagerInfo: Added rdd_208_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.6 MB)
18/05/31 14:47:36 INFO Executor: Finished task 0.0 in stage 332.0 (TID 222). 1708 bytes result sent to driver
18/05/31 14:47:36 INFO TaskSetManager: Finished task 0.0 in stage 332.0 (TID 222) in 4 ms on localhost (executor driver) (1/1)
18/05/31 14:47:36 INFO TaskSchedulerImpl: Removed TaskSet 332.0, whose tasks have all completed, from pool 
18/05/31 14:47:36 INFO DAGScheduler: ShuffleMapStage 332 (mapToPair at AnomalyDetector.java:64) finished in 0.004 s
18/05/31 14:47:36 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:36 INFO DAGScheduler: running: Set()
18/05/31 14:47:36 INFO DAGScheduler: waiting: Set(ResultStage 333)
18/05/31 14:47:36 INFO DAGScheduler: failed: Set()
18/05/31 14:47:36 INFO DAGScheduler: Submitting ResultStage 333 (MapPartitionsRDD[211] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:36 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 7.8 KB, free 354.3 MB)
18/05/31 14:47:36 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 4.2 KB, free 354.3 MB)
18/05/31 14:47:36 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 10.66.169.34:53539 (size: 4.2 KB, free: 354.6 MB)
18/05/31 14:47:36 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 333 (MapPartitionsRDD[211] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:36 INFO TaskSchedulerImpl: Adding task set 333.0 with 4 tasks
18/05/31 14:47:36 INFO TaskSetManager: Starting task 0.0 in stage 333.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:47:36 INFO TaskSetManager: Starting task 1.0 in stage 333.0 (TID 224, localhost, executor driver, partition 1, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:47:36 INFO TaskSetManager: Starting task 2.0 in stage 333.0 (TID 225, localhost, executor driver, partition 2, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:47:36 INFO TaskSetManager: Starting task 3.0 in stage 333.0 (TID 226, localhost, executor driver, partition 3, PROCESS_LOCAL, 6375 bytes)
18/05/31 14:47:36 INFO Executor: Running task 1.0 in stage 333.0 (TID 224)
18/05/31 14:47:36 INFO Executor: Running task 0.0 in stage 333.0 (TID 223)
18/05/31 14:47:36 INFO Executor: Running task 3.0 in stage 333.0 (TID 226)
18/05/31 14:47:36 INFO Executor: Running task 2.0 in stage 333.0 (TID 225)
18/05/31 14:47:36 INFO BlockManager: Found block rdd_204_1 locally
18/05/31 14:47:36 INFO CheckpointWriter: Checkpoint for time 1527767180000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767250000', took 6070 bytes and 15 ms
18/05/31 14:47:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:36 INFO BlockManager: Found block rdd_204_3 locally
18/05/31 14:47:36 INFO DStreamGraph: Clearing checkpoint data for time 1527767180000 ms
18/05/31 14:47:36 INFO MemoryStore: Block rdd_210_1 stored as values in memory (estimated size 2.5 KB, free 354.3 MB)
18/05/31 14:47:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:36 INFO MemoryStore: Block rdd_210_3 stored as values in memory (estimated size 2.5 KB, free 354.3 MB)
18/05/31 14:47:36 INFO BlockManagerInfo: Added rdd_210_1 in memory on 10.66.169.34:53539 (size: 2.5 KB, free: 354.6 MB)
18/05/31 14:47:36 INFO BlockManagerInfo: Added rdd_210_3 in memory on 10.66.169.34:53539 (size: 2.5 KB, free: 354.6 MB)
18/05/31 14:47:36 INFO BlockManager: Found block rdd_204_2 locally
18/05/31 14:47:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:36 INFO BlockManager: Found block rdd_204_0 locally
18/05/31 14:47:36 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:36 INFO DStreamCheckpointData: Deleted checkpoint file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-104' for time 1527766980000 ms
18/05/31 14:47:36 INFO MemoryStore: Block rdd_210_0 stored as values in memory (estimated size 2.5 KB, free 354.3 MB)
18/05/31 14:47:36 INFO DStreamGraph: Cleared checkpoint data for time 1527767180000 ms
18/05/31 14:47:36 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:36 INFO BlockManagerInfo: Added rdd_210_0 in memory on 10.66.169.34:53539 (size: 2.5 KB, free: 354.6 MB)
18/05/31 14:47:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-161
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:36 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:36 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:36 WARN Executor: 1 block locks were not released by TID = 224:
[rdd_204_1]
18/05/31 14:47:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:36 INFO Executor: Finished task 1.0 in stage 333.0 (TID 224). 2359 bytes result sent to driver
18/05/31 14:47:36 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766980000: 
18/05/31 14:47:36 INFO InputInfoTracker: remove old batch metadata: 1527766970000 ms
18/05/31 14:47:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-162
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:36 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:36 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:36 WARN Executor: 1 block locks were not released by TID = 226:
[rdd_204_3]
18/05/31 14:47:36 INFO Executor: Finished task 3.0 in stage 333.0 (TID 226). 2359 bytes result sent to driver
18/05/31 14:47:36 INFO TaskSetManager: Finished task 1.0 in stage 333.0 (TID 224) in 11 ms on localhost (executor driver) (1/4)
18/05/31 14:47:36 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-163
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:36 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:36 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:36 WARN Executor: 1 block locks were not released by TID = 223:
[rdd_204_0]
18/05/31 14:47:36 INFO Executor: Finished task 0.0 in stage 333.0 (TID 223). 2359 bytes result sent to driver
18/05/31 14:47:36 INFO TaskSetManager: Finished task 3.0 in stage 333.0 (TID 226) in 12 ms on localhost (executor driver) (2/4)
18/05/31 14:47:36 INFO TaskSetManager: Finished task 0.0 in stage 333.0 (TID 223) in 14 ms on localhost (executor driver) (3/4)
18/05/31 14:47:37 INFO MemoryStore: 7 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:37 INFO BlockManager: Dropping block rdd_194_3 from memory
18/05/31 14:47:37 INFO BlockManagerInfo: Removed rdd_194_3 on 10.66.169.34:53539 in memory (size: 15.5 KB, free: 354.6 MB)
18/05/31 14:47:37 INFO BlockManager: Dropping block rdd_194_1 from memory
18/05/31 14:47:37 INFO BlockManagerInfo: Removed rdd_194_1 on 10.66.169.34:53539 in memory (size: 15.5 KB, free: 354.6 MB)
18/05/31 14:47:37 INFO BlockManager: Dropping block rdd_194_0 from memory
18/05/31 14:47:37 INFO BlockManagerInfo: Removed rdd_194_0 on 10.66.169.34:53539 in memory (size: 15.5 KB, free: 354.6 MB)
18/05/31 14:47:37 INFO BlockManager: Dropping block rdd_202_0 from memory
18/05/31 14:47:37 INFO BlockManagerInfo: Removed rdd_202_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.6 MB)
18/05/31 14:47:37 INFO BlockManager: Dropping block rdd_199_3 from memory
18/05/31 14:47:37 INFO BlockManagerInfo: Removed rdd_199_3 on 10.66.169.34:53539 in memory (size: 16.2 KB, free: 354.6 MB)
18/05/31 14:47:37 INFO BlockManager: Dropping block rdd_199_0 from memory
18/05/31 14:47:37 INFO BlockManagerInfo: Removed rdd_199_0 on 10.66.169.34:53539 in memory (size: 16.2 KB, free: 354.7 MB)
18/05/31 14:47:37 INFO BlockManager: Dropping block rdd_199_2 from memory
18/05/31 14:47:37 INFO BlockManagerInfo: Removed rdd_199_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.4 MB)
18/05/31 14:47:37 INFO MemoryStore: After dropping 7 blocks, free memory is 633.2 MB
18/05/31 14:47:37 INFO MemoryStore: Block rdd_210_2 stored as values in memory (estimated size 278.8 MB, free 354.4 MB)
18/05/31 14:47:37 INFO BlockManagerInfo: Added rdd_210_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:37 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:37 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-164
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:37 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:37 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:37 WARN Executor: 1 block locks were not released by TID = 225:
[rdd_204_2]
18/05/31 14:47:37 INFO Executor: Finished task 2.0 in stage 333.0 (TID 225). 2694 bytes result sent to driver
18/05/31 14:47:37 INFO TaskSetManager: Finished task 2.0 in stage 333.0 (TID 225) in 1742 ms on localhost (executor driver) (4/4)
18/05/31 14:47:37 INFO TaskSchedulerImpl: Removed TaskSet 333.0, whose tasks have all completed, from pool 
18/05/31 14:47:37 INFO DAGScheduler: ResultStage 333 (foreachPartition at AnomalyDetector.java:69) finished in 1.742 s
18/05/31 14:47:37 INFO DAGScheduler: Job 50 finished: foreachPartition at AnomalyDetector.java:69, took 1.755730 s
18/05/31 14:47:37 INFO JobScheduler: Finished job streaming job 1527767190000 ms.0 from job set of time 1527767190000 ms
18/05/31 14:47:37 INFO JobScheduler: Total delay: 67.921 s for time 1527767190000 ms (execution: 1.760 s)
18/05/31 14:47:37 INFO JobScheduler: Starting job streaming job 1527767200000 ms.0 from job set of time 1527767200000 ms
18/05/31 14:47:37 INFO MapPartitionsRDD: Removing RDD 205 from persistence list
18/05/31 14:47:37 INFO BlockManager: Removing RDD 205
18/05/31 14:47:37 INFO MapWithStateRDD: Removing RDD 109 from persistence list
18/05/31 14:47:37 INFO MapPartitionsRDD: Removing RDD 107 from persistence list
18/05/31 14:47:37 INFO BlockManager: Removing RDD 109
18/05/31 14:47:37 INFO KafkaRDD: Removing RDD 106 from persistence list
18/05/31 14:47:37 INFO BlockManager: Removing RDD 107
18/05/31 14:47:37 INFO BlockManager: Removing RDD 106
18/05/31 14:47:37 INFO JobGenerator: Checkpointing graph for time 1527767190000 ms
18/05/31 14:47:37 INFO DStreamGraph: Updating checkpoint data for time 1527767190000 ms
18/05/31 14:47:37 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:37 INFO DStreamGraph: Updated checkpoint data for time 1527767190000 ms
18/05/31 14:47:37 INFO CheckpointWriter: Submitted checkpoint of time 1527767190000 ms to writer queue
18/05/31 14:47:37 INFO DAGScheduler: Registering RDD 215 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:37 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 149 bytes
18/05/31 14:47:37 INFO CheckpointWriter: Saving checkpoint for time 1527767190000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767250000'
18/05/31 14:47:37 INFO DAGScheduler: Got job 51 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:37 INFO DAGScheduler: Final stage: ResultStage 336 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 335, ShuffleMapStage 334)
18/05/31 14:47:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 334)
18/05/31 14:47:37 INFO DAGScheduler: Submitting ShuffleMapStage 334 (MapPartitionsRDD[215] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:37 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 5.9 KB, free 354.4 MB)
18/05/31 14:47:37 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.4 MB)
18/05/31 14:47:37 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:37 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 334 (MapPartitionsRDD[215] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:37 INFO TaskSchedulerImpl: Adding task set 334.0 with 1 tasks
18/05/31 14:47:37 INFO TaskSetManager: Starting task 0.0 in stage 334.0 (TID 227, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:37 INFO Executor: Running task 0.0 in stage 334.0 (TID 227)
18/05/31 14:47:37 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:37 INFO MemoryStore: Block rdd_215_0 stored as bytes in memory (estimated size 4.0 B, free 354.4 MB)
18/05/31 14:47:37 INFO BlockManagerInfo: Added rdd_215_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:37 INFO CheckpointWriter: Checkpoint for time 1527767190000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767250000', took 6064 bytes and 17 ms
18/05/31 14:47:37 INFO DStreamGraph: Clearing checkpoint data for time 1527767190000 ms
18/05/31 14:47:37 INFO Executor: Finished task 0.0 in stage 334.0 (TID 227). 1708 bytes result sent to driver
18/05/31 14:47:37 INFO DStreamGraph: Cleared checkpoint data for time 1527767190000 ms
18/05/31 14:47:37 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:37 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527766990000: 
18/05/31 14:47:37 INFO InputInfoTracker: remove old batch metadata: 1527766980000 ms
18/05/31 14:47:37 INFO TaskSetManager: Finished task 0.0 in stage 334.0 (TID 227) in 13 ms on localhost (executor driver) (1/1)
18/05/31 14:47:37 INFO TaskSchedulerImpl: Removed TaskSet 334.0, whose tasks have all completed, from pool 
18/05/31 14:47:37 INFO DAGScheduler: ShuffleMapStage 334 (mapToPair at AnomalyDetector.java:64) finished in 0.013 s
18/05/31 14:47:37 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:37 INFO DAGScheduler: running: Set()
18/05/31 14:47:37 INFO DAGScheduler: waiting: Set(ResultStage 336)
18/05/31 14:47:37 INFO DAGScheduler: failed: Set()
18/05/31 14:47:37 INFO DAGScheduler: Submitting ResultStage 336 (MapPartitionsRDD[218] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:37 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 8.1 KB, free 354.4 MB)
18/05/31 14:47:37 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 4.3 KB, free 354.4 MB)
18/05/31 14:47:37 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 10.66.169.34:53539 (size: 4.3 KB, free: 354.7 MB)
18/05/31 14:47:37 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 336 (MapPartitionsRDD[218] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:37 INFO TaskSchedulerImpl: Adding task set 336.0 with 4 tasks
18/05/31 14:47:37 INFO TaskSetManager: Starting task 0.0 in stage 336.0 (TID 228, localhost, executor driver, partition 0, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:47:37 INFO TaskSetManager: Starting task 1.0 in stage 336.0 (TID 229, localhost, executor driver, partition 1, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:47:37 INFO TaskSetManager: Starting task 2.0 in stage 336.0 (TID 230, localhost, executor driver, partition 2, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:47:37 INFO TaskSetManager: Starting task 3.0 in stage 336.0 (TID 231, localhost, executor driver, partition 3, PROCESS_LOCAL, 6400 bytes)
18/05/31 14:47:37 INFO Executor: Running task 2.0 in stage 336.0 (TID 230)
18/05/31 14:47:37 INFO Executor: Running task 1.0 in stage 336.0 (TID 229)
18/05/31 14:47:37 INFO Executor: Running task 3.0 in stage 336.0 (TID 231)
18/05/31 14:47:37 INFO BlockManager: Found block rdd_210_2 locally
18/05/31 14:47:37 INFO BlockManager: Found block rdd_210_1 locally
18/05/31 14:47:37 INFO BlockManager: Found block rdd_210_3 locally
18/05/31 14:47:37 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:37 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:37 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:37 INFO MemoryStore: Block rdd_217_3 stored as values in memory (estimated size 3.2 KB, free 354.4 MB)
18/05/31 14:47:37 INFO MemoryStore: Block rdd_217_1 stored as values in memory (estimated size 3.2 KB, free 354.4 MB)
18/05/31 14:47:37 INFO BlockManagerInfo: Added rdd_217_3 in memory on 10.66.169.34:53539 (size: 3.2 KB, free: 354.7 MB)
18/05/31 14:47:37 INFO BlockManagerInfo: Added rdd_217_1 in memory on 10.66.169.34:53539 (size: 3.2 KB, free: 354.7 MB)
18/05/31 14:47:37 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:37 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:37 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-165
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:37 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-166
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:37 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:37 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:37 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:37 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:37 WARN Executor: 1 block locks were not released by TID = 229:
[rdd_210_1]
18/05/31 14:47:37 WARN Executor: 1 block locks were not released by TID = 231:
[rdd_210_3]
18/05/31 14:47:37 INFO Executor: Finished task 3.0 in stage 336.0 (TID 231). 2359 bytes result sent to driver
18/05/31 14:47:37 INFO Executor: Finished task 1.0 in stage 336.0 (TID 229). 2359 bytes result sent to driver
18/05/31 14:47:37 INFO TaskSetManager: Finished task 1.0 in stage 336.0 (TID 229) in 7 ms on localhost (executor driver) (1/4)
18/05/31 14:47:37 INFO TaskSetManager: Finished task 3.0 in stage 336.0 (TID 231) in 7 ms on localhost (executor driver) (2/4)
18/05/31 14:47:37 INFO Executor: Running task 0.0 in stage 336.0 (TID 228)
18/05/31 14:47:37 INFO BlockManager: Found block rdd_210_0 locally
18/05/31 14:47:37 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:37 INFO MemoryStore: Block rdd_217_0 stored as values in memory (estimated size 3.2 KB, free 354.4 MB)
18/05/31 14:47:37 INFO BlockManagerInfo: Added rdd_217_0 in memory on 10.66.169.34:53539 (size: 3.2 KB, free: 354.7 MB)
18/05/31 14:47:37 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:37 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-167
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:37 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:37 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:37 WARN Executor: 1 block locks were not released by TID = 228:
[rdd_210_0]
18/05/31 14:47:37 INFO Executor: Finished task 0.0 in stage 336.0 (TID 228). 2359 bytes result sent to driver
18/05/31 14:47:37 INFO TaskSetManager: Finished task 0.0 in stage 336.0 (TID 228) in 22 ms on localhost (executor driver) (3/4)
18/05/31 14:47:38 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 10.66.169.34:53539 in memory (size: 4.2 KB, free: 354.7 MB)
18/05/31 14:47:38 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:38 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 10.66.169.34:53539 in memory (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:38 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 10.66.169.34:53539 in memory (size: 4.5 KB, free: 354.7 MB)
18/05/31 14:47:38 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:38 INFO MemoryStore: 7 blocks selected for dropping (279.0 MB bytes)
18/05/31 14:47:38 INFO BlockManager: Dropping block rdd_199_1 from memory
18/05/31 14:47:39 INFO BlockManagerInfo: Removed rdd_199_1 on 10.66.169.34:53539 in memory (size: 16.2 KB, free: 354.7 MB)
18/05/31 14:47:39 INFO BlockManager: Dropping block broadcast_109 from memory
18/05/31 14:47:39 INFO BlockManager: Writing block broadcast_109 to disk
18/05/31 14:47:39 INFO BlockManager: Dropping block broadcast_109_piece0 from memory
18/05/31 14:47:39 INFO BlockManager: Writing block broadcast_109_piece0 to disk
18/05/31 14:47:39 INFO BlockManagerInfo: Added broadcast_109_piece0 on disk on 10.66.169.34:53539 (size: 14.3 KB)
18/05/31 14:47:39 INFO BlockManager: Dropping block rdd_208_0 from memory
18/05/31 14:47:39 INFO BlockManagerInfo: Removed rdd_208_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:39 INFO BlockManager: Dropping block rdd_204_1 from memory
18/05/31 14:47:39 INFO BlockManagerInfo: Removed rdd_204_1 on 10.66.169.34:53539 in memory (size: 17.0 KB, free: 354.7 MB)
18/05/31 14:47:39 INFO BlockManager: Dropping block rdd_204_3 from memory
18/05/31 14:47:39 INFO BlockManagerInfo: Removed rdd_204_3 on 10.66.169.34:53539 in memory (size: 17.0 KB, free: 354.7 MB)
18/05/31 14:47:39 INFO BlockManager: Dropping block rdd_204_2 from memory
18/05/31 14:47:39 INFO BlockManagerInfo: Removed rdd_204_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:39 INFO MemoryStore: After dropping 7 blocks, free memory is 633.5 MB
18/05/31 14:47:39 INFO MemoryStore: Block rdd_217_2 stored as values in memory (estimated size 278.8 MB, free 354.8 MB)
18/05/31 14:47:39 INFO BlockManagerInfo: Added rdd_217_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.8 MB)
18/05/31 14:47:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-168
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:39 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:39 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:39 WARN Executor: 1 block locks were not released by TID = 230:
[rdd_210_2]
18/05/31 14:47:39 INFO Executor: Finished task 2.0 in stage 336.0 (TID 230). 2880 bytes result sent to driver
18/05/31 14:47:39 INFO TaskSetManager: Finished task 2.0 in stage 336.0 (TID 230) in 1899 ms on localhost (executor driver) (4/4)
18/05/31 14:47:39 INFO TaskSchedulerImpl: Removed TaskSet 336.0, whose tasks have all completed, from pool 
18/05/31 14:47:39 INFO DAGScheduler: ResultStage 336 (foreachPartition at AnomalyDetector.java:69) finished in 1.900 s
18/05/31 14:47:39 INFO DAGScheduler: Job 51 finished: foreachPartition at AnomalyDetector.java:69, took 1.924852 s
18/05/31 14:47:39 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 127.1 KB, free 354.6 MB)
18/05/31 14:47:39 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.6 MB)
18/05/31 14:47:39 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:39 INFO SparkContext: Created broadcast 114 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:39 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:39 INFO DAGScheduler: Got job 52 (foreachPartition at AnomalyDetector.java:69) with 1 output partitions
18/05/31 14:47:39 INFO DAGScheduler: Final stage: ResultStage 337 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:39 INFO DAGScheduler: Parents of final stage: List()
18/05/31 14:47:39 INFO DAGScheduler: Missing parents: List()
18/05/31 14:47:39 INFO DAGScheduler: Submitting ResultStage 337 (MapPartitionsRDD[215] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:39 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 6.1 KB, free 354.6 MB)
18/05/31 14:47:39 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.6 MB)
18/05/31 14:47:39 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:39 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 337 (MapPartitionsRDD[215] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:39 INFO TaskSchedulerImpl: Adding task set 337.0 with 1 tasks
18/05/31 14:47:39 INFO TaskSetManager: Starting task 0.0 in stage 337.0 (TID 232, localhost, executor driver, partition 0, PROCESS_LOCAL, 6166 bytes)
18/05/31 14:47:39 INFO Executor: Running task 0.0 in stage 337.0 (TID 232)
18/05/31 14:47:39 INFO BlockManager: Found block rdd_215_0 locally
18/05/31 14:47:39 INFO Executor: Finished task 0.0 in stage 337.0 (TID 232). 1004 bytes result sent to driver
18/05/31 14:47:39 INFO TaskSetManager: Finished task 0.0 in stage 337.0 (TID 232) in 9 ms on localhost (executor driver) (1/1)
18/05/31 14:47:39 INFO TaskSchedulerImpl: Removed TaskSet 337.0, whose tasks have all completed, from pool 
18/05/31 14:47:39 INFO DAGScheduler: ResultStage 337 (foreachPartition at AnomalyDetector.java:69) finished in 0.011 s
18/05/31 14:47:39 INFO DAGScheduler: Job 52 finished: foreachPartition at AnomalyDetector.java:69, took 0.013480 s
18/05/31 14:47:39 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 127.1 KB, free 354.5 MB)
18/05/31 14:47:39 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.5 MB)
18/05/31 14:47:39 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:39 INFO SparkContext: Created broadcast 116 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:39 INFO ReliableRDDCheckpointData: Done checkpointing RDD 215 to file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-215, new parent is RDD 251
18/05/31 14:47:39 INFO JobScheduler: Finished job streaming job 1527767200000 ms.0 from job set of time 1527767200000 ms
18/05/31 14:47:39 INFO JobScheduler: Total delay: 59.887 s for time 1527767200000 ms (execution: 1.965 s)
18/05/31 14:47:39 INFO MapPartitionsRDD: Removing RDD 211 from persistence list
18/05/31 14:47:39 INFO JobScheduler: Starting job streaming job 1527767210000 ms.0 from job set of time 1527767210000 ms
18/05/31 14:47:39 INFO BlockManager: Removing RDD 211
18/05/31 14:47:39 INFO MapWithStateRDD: Removing RDD 114 from persistence list
18/05/31 14:47:39 INFO BlockManager: Removing RDD 114
18/05/31 14:47:39 INFO MapPartitionsRDD: Removing RDD 112 from persistence list
18/05/31 14:47:39 INFO BlockManager: Removing RDD 112
18/05/31 14:47:39 INFO KafkaRDD: Removing RDD 111 from persistence list
18/05/31 14:47:39 INFO BlockManager: Removing RDD 111
18/05/31 14:47:39 INFO JobGenerator: Checkpointing graph for time 1527767200000 ms
18/05/31 14:47:39 INFO DStreamGraph: Updating checkpoint data for time 1527767200000 ms
18/05/31 14:47:39 INFO DStreamGraph: Updated checkpoint data for time 1527767200000 ms
18/05/31 14:47:39 INFO CheckpointWriter: Submitted checkpoint of time 1527767200000 ms to writer queue
18/05/31 14:47:39 INFO CheckpointWriter: Saving checkpoint for time 1527767200000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767250000'
18/05/31 14:47:39 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 149 bytes
18/05/31 14:47:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 149 bytes
18/05/31 14:47:39 INFO DAGScheduler: Registering RDD 221 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:39 INFO DAGScheduler: Got job 53 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:39 INFO DAGScheduler: Final stage: ResultStage 341 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 338, ShuffleMapStage 339, ShuffleMapStage 340)
18/05/31 14:47:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 340)
18/05/31 14:47:39 INFO DAGScheduler: Submitting ShuffleMapStage 340 (MapPartitionsRDD[221] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:39 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 4.6 KB, free 354.5 MB)
18/05/31 14:47:39 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.5 MB)
18/05/31 14:47:39 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:39 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 340 (MapPartitionsRDD[221] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:39 INFO TaskSchedulerImpl: Adding task set 340.0 with 1 tasks
18/05/31 14:47:39 INFO TaskSetManager: Starting task 0.0 in stage 340.0 (TID 233, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:39 INFO Executor: Running task 0.0 in stage 340.0 (TID 233)
18/05/31 14:47:39 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:39 INFO MemoryStore: Block rdd_221_0 stored as bytes in memory (estimated size 4.0 B, free 354.5 MB)
18/05/31 14:47:39 INFO BlockManagerInfo: Added rdd_221_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:39 INFO Executor: Finished task 0.0 in stage 340.0 (TID 233). 1708 bytes result sent to driver
18/05/31 14:47:39 INFO TaskSetManager: Finished task 0.0 in stage 340.0 (TID 233) in 5 ms on localhost (executor driver) (1/1)
18/05/31 14:47:39 INFO TaskSchedulerImpl: Removed TaskSet 340.0, whose tasks have all completed, from pool 
18/05/31 14:47:39 INFO DAGScheduler: ShuffleMapStage 340 (mapToPair at AnomalyDetector.java:64) finished in 0.005 s
18/05/31 14:47:39 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:39 INFO DAGScheduler: running: Set()
18/05/31 14:47:39 INFO DAGScheduler: waiting: Set(ResultStage 341)
18/05/31 14:47:39 INFO DAGScheduler: failed: Set()
18/05/31 14:47:39 INFO DAGScheduler: Submitting ResultStage 341 (MapPartitionsRDD[224] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:39 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 8.4 KB, free 354.5 MB)
18/05/31 14:47:39 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 4.3 KB, free 354.4 MB)
18/05/31 14:47:39 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 10.66.169.34:53539 (size: 4.3 KB, free: 354.7 MB)
18/05/31 14:47:39 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 341 (MapPartitionsRDD[224] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:39 INFO TaskSchedulerImpl: Adding task set 341.0 with 4 tasks
18/05/31 14:47:39 INFO CheckpointWriter: Checkpoint for time 1527767200000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767250000', took 6057 bytes and 16 ms
18/05/31 14:47:39 INFO DStreamGraph: Clearing checkpoint data for time 1527767200000 ms
18/05/31 14:47:39 INFO DStreamGraph: Cleared checkpoint data for time 1527767200000 ms
18/05/31 14:47:39 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:39 INFO TaskSetManager: Starting task 0.0 in stage 341.0 (TID 234, localhost, executor driver, partition 0, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:47:39 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527767000000: 
18/05/31 14:47:39 INFO InputInfoTracker: remove old batch metadata: 1527766990000 ms
18/05/31 14:47:39 INFO TaskSetManager: Starting task 1.0 in stage 341.0 (TID 235, localhost, executor driver, partition 1, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:47:39 INFO TaskSetManager: Starting task 2.0 in stage 341.0 (TID 236, localhost, executor driver, partition 2, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:47:39 INFO TaskSetManager: Starting task 3.0 in stage 341.0 (TID 237, localhost, executor driver, partition 3, PROCESS_LOCAL, 6425 bytes)
18/05/31 14:47:39 INFO Executor: Running task 0.0 in stage 341.0 (TID 234)
18/05/31 14:47:39 INFO Executor: Running task 1.0 in stage 341.0 (TID 235)
18/05/31 14:47:39 INFO Executor: Running task 2.0 in stage 341.0 (TID 236)
18/05/31 14:47:39 INFO Executor: Running task 3.0 in stage 341.0 (TID 237)
18/05/31 14:47:39 INFO BlockManager: Found block rdd_217_1 locally
18/05/31 14:47:39 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:39 INFO BlockManager: Found block rdd_217_0 locally
18/05/31 14:47:39 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:39 INFO BlockManager: Found block rdd_217_3 locally
18/05/31 14:47:39 INFO MemoryStore: Block rdd_223_0 stored as values in memory (estimated size 4.0 KB, free 354.4 MB)
18/05/31 14:47:39 INFO BlockManager: Found block rdd_217_2 locally
18/05/31 14:47:39 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:39 INFO BlockManagerInfo: Added rdd_223_0 in memory on 10.66.169.34:53539 (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:47:39 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:39 INFO MemoryStore: Block rdd_223_1 stored as values in memory (estimated size 4.0 KB, free 354.4 MB)
18/05/31 14:47:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:39 INFO BlockManagerInfo: Added rdd_223_1 in memory on 10.66.169.34:53539 (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:47:39 INFO MemoryStore: Block rdd_223_3 stored as values in memory (estimated size 4.0 KB, free 354.4 MB)
18/05/31 14:47:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:39 INFO BlockManagerInfo: Added rdd_223_3 in memory on 10.66.169.34:53539 (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:47:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-169
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:39 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:39 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:39 WARN Executor: 1 block locks were not released by TID = 234:
[rdd_217_0]
18/05/31 14:47:39 INFO Executor: Finished task 0.0 in stage 341.0 (TID 234). 2359 bytes result sent to driver
18/05/31 14:47:39 INFO TaskSetManager: Finished task 0.0 in stage 341.0 (TID 234) in 8 ms on localhost (executor driver) (1/4)
18/05/31 14:47:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-170
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:39 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:39 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:39 WARN Executor: 1 block locks were not released by TID = 235:
[rdd_217_1]
18/05/31 14:47:39 INFO Executor: Finished task 1.0 in stage 341.0 (TID 235). 2359 bytes result sent to driver
18/05/31 14:47:39 INFO TaskSetManager: Finished task 1.0 in stage 341.0 (TID 235) in 10 ms on localhost (executor driver) (2/4)
18/05/31 14:47:39 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-171
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:39 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:39 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:39 WARN Executor: 1 block locks were not released by TID = 237:
[rdd_217_3]
18/05/31 14:47:39 INFO Executor: Finished task 3.0 in stage 341.0 (TID 237). 2359 bytes result sent to driver
18/05/31 14:47:39 INFO TaskSetManager: Finished task 3.0 in stage 341.0 (TID 237) in 11 ms on localhost (executor driver) (3/4)
18/05/31 14:47:40 INFO MappedDStream: Marking RDD 253 for time 1527767260000 ms for checkpointing
18/05/31 14:47:40 INFO JobScheduler: Added jobs for time 1527767260000 ms
18/05/31 14:47:40 INFO JobGenerator: Checkpointing graph for time 1527767260000 ms
18/05/31 14:47:40 INFO DStreamGraph: Updating checkpoint data for time 1527767260000 ms
18/05/31 14:47:40 INFO DStreamGraph: Updated checkpoint data for time 1527767260000 ms
18/05/31 14:47:40 INFO CheckpointWriter: Submitted checkpoint of time 1527767260000 ms to writer queue
18/05/31 14:47:40 INFO CheckpointWriter: Saving checkpoint for time 1527767260000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000'
18/05/31 14:47:40 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000.bk
18/05/31 14:47:40 INFO CheckpointWriter: Checkpoint for time 1527767260000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000', took 6056 bytes and 12 ms
18/05/31 14:47:41 INFO MemoryStore: 3 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:41 INFO BlockManager: Dropping block rdd_204_0 from memory
18/05/31 14:47:41 INFO BlockManagerInfo: Removed rdd_204_0 on 10.66.169.34:53539 in memory (size: 17.0 KB, free: 354.7 MB)
18/05/31 14:47:41 INFO BlockManager: Dropping block broadcast_113_piece0 from memory
18/05/31 14:47:41 INFO BlockManager: Writing block broadcast_113_piece0 to disk
18/05/31 14:47:41 INFO BlockManagerInfo: Added broadcast_113_piece0 on disk on 10.66.169.34:53539 (size: 4.3 KB)
18/05/31 14:47:41 INFO BlockManager: Dropping block rdd_210_2 from memory
18/05/31 14:47:41 INFO BlockManagerInfo: Removed rdd_210_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:41 INFO MemoryStore: After dropping 3 blocks, free memory is 633.2 MB
18/05/31 14:47:41 INFO MemoryStore: Block rdd_223_2 stored as values in memory (estimated size 278.8 MB, free 354.5 MB)
18/05/31 14:47:41 INFO BlockManagerInfo: Added rdd_223_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-172
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:41 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:41 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:41 WARN Executor: 1 block locks were not released by TID = 236:
[rdd_217_2]
18/05/31 14:47:41 INFO Executor: Finished task 2.0 in stage 341.0 (TID 236). 2616 bytes result sent to driver
18/05/31 14:47:41 INFO TaskSetManager: Finished task 2.0 in stage 341.0 (TID 236) in 2024 ms on localhost (executor driver) (4/4)
18/05/31 14:47:41 INFO TaskSchedulerImpl: Removed TaskSet 341.0, whose tasks have all completed, from pool 
18/05/31 14:47:41 INFO DAGScheduler: ResultStage 341 (foreachPartition at AnomalyDetector.java:69) finished in 2.025 s
18/05/31 14:47:41 INFO DAGScheduler: Job 53 finished: foreachPartition at AnomalyDetector.java:69, took 2.040378 s
18/05/31 14:47:41 INFO JobScheduler: Finished job streaming job 1527767210000 ms.0 from job set of time 1527767210000 ms
18/05/31 14:47:41 INFO JobScheduler: Total delay: 51.930 s for time 1527767210000 ms (execution: 2.043 s)
18/05/31 14:47:41 INFO MapPartitionsRDD: Removing RDD 218 from persistence list
18/05/31 14:47:41 INFO JobScheduler: Starting job streaming job 1527767220000 ms.0 from job set of time 1527767220000 ms
18/05/31 14:47:41 INFO BlockManager: Removing RDD 218
18/05/31 14:47:41 INFO MapWithStateRDD: Removing RDD 119 from persistence list
18/05/31 14:47:41 INFO BlockManager: Removing RDD 119
18/05/31 14:47:41 INFO MapPartitionsRDD: Removing RDD 117 from persistence list
18/05/31 14:47:41 INFO BlockManager: Removing RDD 117
18/05/31 14:47:41 INFO KafkaRDD: Removing RDD 116 from persistence list
18/05/31 14:47:41 INFO BlockManager: Removing RDD 116
18/05/31 14:47:41 INFO JobGenerator: Checkpointing graph for time 1527767210000 ms
18/05/31 14:47:41 INFO DStreamGraph: Updating checkpoint data for time 1527767210000 ms
18/05/31 14:47:41 INFO DStreamGraph: Updated checkpoint data for time 1527767210000 ms
18/05/31 14:47:41 INFO CheckpointWriter: Submitted checkpoint of time 1527767210000 ms to writer queue
18/05/31 14:47:41 INFO CheckpointWriter: Saving checkpoint for time 1527767210000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000'
18/05/31 14:47:41 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:41 INFO DAGScheduler: Registering RDD 227 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 149 bytes
18/05/31 14:47:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 149 bytes
18/05/31 14:47:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 44 is 149 bytes
18/05/31 14:47:41 INFO DAGScheduler: Got job 54 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:41 INFO DAGScheduler: Final stage: ResultStage 346 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 342, ShuffleMapStage 343, ShuffleMapStage 344, ShuffleMapStage 345)
18/05/31 14:47:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 342)
18/05/31 14:47:41 INFO DAGScheduler: Submitting ShuffleMapStage 342 (MapPartitionsRDD[227] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:41 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 4.6 KB, free 354.4 MB)
18/05/31 14:47:41 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.4 MB)
18/05/31 14:47:41 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:41 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 342 (MapPartitionsRDD[227] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:41 INFO TaskSchedulerImpl: Adding task set 342.0 with 1 tasks
18/05/31 14:47:41 INFO TaskSetManager: Starting task 0.0 in stage 342.0 (TID 238, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:41 INFO Executor: Running task 0.0 in stage 342.0 (TID 238)
18/05/31 14:47:41 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:41 INFO MemoryStore: Block rdd_227_0 stored as bytes in memory (estimated size 4.0 B, free 354.4 MB)
18/05/31 14:47:41 INFO BlockManagerInfo: Added rdd_227_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:41 INFO Executor: Finished task 0.0 in stage 342.0 (TID 238). 1708 bytes result sent to driver
18/05/31 14:47:41 INFO TaskSetManager: Finished task 0.0 in stage 342.0 (TID 238) in 5 ms on localhost (executor driver) (1/1)
18/05/31 14:47:41 INFO TaskSchedulerImpl: Removed TaskSet 342.0, whose tasks have all completed, from pool 
18/05/31 14:47:41 INFO DAGScheduler: ShuffleMapStage 342 (mapToPair at AnomalyDetector.java:64) finished in 0.005 s
18/05/31 14:47:41 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:41 INFO DAGScheduler: running: Set()
18/05/31 14:47:41 INFO DAGScheduler: waiting: Set(ResultStage 346)
18/05/31 14:47:41 INFO DAGScheduler: failed: Set()
18/05/31 14:47:41 INFO DAGScheduler: Submitting ResultStage 346 (MapPartitionsRDD[230] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:41 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 8.6 KB, free 354.4 MB)
18/05/31 14:47:41 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767210000
18/05/31 14:47:41 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 4.4 KB, free 354.4 MB)
18/05/31 14:47:41 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 10.66.169.34:53539 (size: 4.4 KB, free: 354.7 MB)
18/05/31 14:47:41 INFO CheckpointWriter: Checkpoint for time 1527767210000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000', took 6060 bytes and 16 ms
18/05/31 14:47:41 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:41 INFO DStreamGraph: Clearing checkpoint data for time 1527767210000 ms
18/05/31 14:47:41 INFO DStreamGraph: Cleared checkpoint data for time 1527767210000 ms
18/05/31 14:47:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 346 (MapPartitionsRDD[230] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:41 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:41 INFO TaskSchedulerImpl: Adding task set 346.0 with 4 tasks
18/05/31 14:47:41 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527767010000: 
18/05/31 14:47:41 INFO InputInfoTracker: remove old batch metadata: 1527767000000 ms
18/05/31 14:47:41 INFO TaskSetManager: Starting task 0.0 in stage 346.0 (TID 239, localhost, executor driver, partition 0, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:47:41 INFO TaskSetManager: Starting task 1.0 in stage 346.0 (TID 240, localhost, executor driver, partition 1, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:47:41 INFO TaskSetManager: Starting task 2.0 in stage 346.0 (TID 241, localhost, executor driver, partition 2, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:47:41 INFO TaskSetManager: Starting task 3.0 in stage 346.0 (TID 242, localhost, executor driver, partition 3, PROCESS_LOCAL, 6450 bytes)
18/05/31 14:47:41 INFO Executor: Running task 0.0 in stage 346.0 (TID 239)
18/05/31 14:47:41 INFO Executor: Running task 1.0 in stage 346.0 (TID 240)
18/05/31 14:47:41 INFO Executor: Running task 2.0 in stage 346.0 (TID 241)
18/05/31 14:47:41 INFO Executor: Running task 3.0 in stage 346.0 (TID 242)
18/05/31 14:47:41 INFO BlockManager: Found block rdd_223_1 locally
18/05/31 14:47:41 INFO BlockManager: Found block rdd_223_2 locally
18/05/31 14:47:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:41 INFO MemoryStore: Block rdd_229_1 stored as values in memory (estimated size 4.8 KB, free 354.4 MB)
18/05/31 14:47:41 INFO BlockManagerInfo: Added rdd_229_1 in memory on 10.66.169.34:53539 (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:47:41 INFO BlockManager: Found block rdd_223_0 locally
18/05/31 14:47:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:41 INFO MemoryStore: Block rdd_229_0 stored as values in memory (estimated size 4.8 KB, free 354.4 MB)
18/05/31 14:47:41 INFO BlockManager: Found block rdd_223_3 locally
18/05/31 14:47:41 INFO BlockManagerInfo: Added rdd_229_0 in memory on 10.66.169.34:53539 (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:47:41 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-173
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:41 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:41 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:41 INFO MemoryStore: Block rdd_229_3 stored as values in memory (estimated size 4.8 KB, free 354.4 MB)
18/05/31 14:47:41 INFO BlockManagerInfo: Added rdd_229_3 in memory on 10.66.169.34:53539 (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:47:41 WARN Executor: 1 block locks were not released by TID = 240:
[rdd_223_1]
18/05/31 14:47:41 INFO Executor: Finished task 1.0 in stage 346.0 (TID 240). 2359 bytes result sent to driver
18/05/31 14:47:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:41 INFO TaskSetManager: Finished task 1.0 in stage 346.0 (TID 240) in 7 ms on localhost (executor driver) (1/4)
18/05/31 14:47:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-174
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:41 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:41 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:41 WARN Executor: 1 block locks were not released by TID = 242:
[rdd_223_3]
18/05/31 14:47:41 INFO Executor: Finished task 3.0 in stage 346.0 (TID 242). 2446 bytes result sent to driver
18/05/31 14:47:41 INFO TaskSetManager: Finished task 3.0 in stage 346.0 (TID 242) in 7 ms on localhost (executor driver) (2/4)
18/05/31 14:47:41 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-175
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:41 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:41 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:41 WARN Executor: 1 block locks were not released by TID = 239:
[rdd_223_0]
18/05/31 14:47:41 INFO Executor: Finished task 0.0 in stage 346.0 (TID 239). 2359 bytes result sent to driver
18/05/31 14:47:41 INFO TaskSetManager: Finished task 0.0 in stage 346.0 (TID 239) in 12 ms on localhost (executor driver) (3/4)
18/05/31 14:47:42 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 10.66.169.34:53539 in memory (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:42 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:42 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:42 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 10.66.169.34:53539 in memory (size: 4.3 KB, free: 354.7 MB)
18/05/31 14:47:42 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:42 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 10.66.169.34:53539 on disk (size: 4.3 KB)
18/05/31 14:47:42 INFO MemoryStore: 11 blocks selected for dropping (278.9 MB bytes)
18/05/31 14:47:42 INFO BlockManager: Dropping block rdd_210_1 from memory
18/05/31 14:47:42 INFO BlockManagerInfo: Removed rdd_210_1 on 10.66.169.34:53539 in memory (size: 2.5 KB, free: 354.7 MB)
18/05/31 14:47:42 INFO BlockManager: Dropping block rdd_210_3 from memory
18/05/31 14:47:42 INFO BlockManagerInfo: Removed rdd_210_3 on 10.66.169.34:53539 in memory (size: 2.5 KB, free: 354.7 MB)
18/05/31 14:47:42 INFO BlockManager: Dropping block rdd_210_0 from memory
18/05/31 14:47:42 INFO BlockManagerInfo: Removed rdd_210_0 on 10.66.169.34:53539 in memory (size: 2.5 KB, free: 354.7 MB)
18/05/31 14:47:42 INFO BlockManager: Dropping block rdd_215_0 from memory
18/05/31 14:47:42 INFO BlockManagerInfo: Removed rdd_215_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:42 INFO BlockManager: Dropping block broadcast_116 from memory
18/05/31 14:47:42 INFO BlockManager: Writing block broadcast_116 to disk
18/05/31 14:47:42 INFO BlockManager: Dropping block broadcast_116_piece0 from memory
18/05/31 14:47:42 INFO BlockManager: Writing block broadcast_116_piece0 to disk
18/05/31 14:47:42 INFO BlockManagerInfo: Added broadcast_116_piece0 on disk on 10.66.169.34:53539 (size: 14.3 KB)
18/05/31 14:47:42 INFO BlockManager: Dropping block rdd_221_0 from memory
18/05/31 14:47:42 INFO BlockManagerInfo: Removed rdd_221_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.8 MB)
18/05/31 14:47:42 INFO BlockManager: Dropping block rdd_217_1 from memory
18/05/31 14:47:42 INFO BlockManagerInfo: Removed rdd_217_1 on 10.66.169.34:53539 in memory (size: 3.2 KB, free: 354.8 MB)
18/05/31 14:47:42 INFO BlockManager: Dropping block rdd_217_0 from memory
18/05/31 14:47:42 INFO BlockManagerInfo: Removed rdd_217_0 on 10.66.169.34:53539 in memory (size: 3.2 KB, free: 354.8 MB)
18/05/31 14:47:42 INFO BlockManager: Dropping block rdd_217_3 from memory
18/05/31 14:47:42 INFO BlockManagerInfo: Removed rdd_217_3 on 10.66.169.34:53539 in memory (size: 3.2 KB, free: 354.8 MB)
18/05/31 14:47:42 INFO BlockManager: Dropping block rdd_217_2 from memory
18/05/31 14:47:42 INFO BlockManagerInfo: Removed rdd_217_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:42 INFO MemoryStore: After dropping 11 blocks, free memory is 633.5 MB
18/05/31 14:47:43 INFO MemoryStore: Block rdd_229_2 stored as values in memory (estimated size 278.8 MB, free 354.8 MB)
18/05/31 14:47:43 INFO BlockManagerInfo: Added rdd_229_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.8 MB)
18/05/31 14:47:43 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:43 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-176
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:43 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:43 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:43 WARN Executor: 1 block locks were not released by TID = 241:
[rdd_223_2]
18/05/31 14:47:43 INFO Executor: Finished task 2.0 in stage 346.0 (TID 241). 3068 bytes result sent to driver
18/05/31 14:47:43 INFO TaskSetManager: Finished task 2.0 in stage 346.0 (TID 241) in 1699 ms on localhost (executor driver) (4/4)
18/05/31 14:47:43 INFO TaskSchedulerImpl: Removed TaskSet 346.0, whose tasks have all completed, from pool 
18/05/31 14:47:43 INFO DAGScheduler: ResultStage 346 (foreachPartition at AnomalyDetector.java:69) finished in 1.700 s
18/05/31 14:47:43 INFO DAGScheduler: Job 54 finished: foreachPartition at AnomalyDetector.java:69, took 1.715558 s
18/05/31 14:47:43 INFO JobScheduler: Finished job streaming job 1527767220000 ms.0 from job set of time 1527767220000 ms
18/05/31 14:47:43 INFO JobScheduler: Total delay: 43.650 s for time 1527767220000 ms (execution: 1.719 s)
18/05/31 14:47:43 INFO MapPartitionsRDD: Removing RDD 224 from persistence list
18/05/31 14:47:43 INFO JobScheduler: Starting job streaming job 1527767230000 ms.0 from job set of time 1527767230000 ms
18/05/31 14:47:43 INFO BlockManager: Removing RDD 224
18/05/31 14:47:43 INFO MapWithStateRDD: Removing RDD 124 from persistence list
18/05/31 14:47:43 INFO BlockManager: Removing RDD 124
18/05/31 14:47:43 INFO MapPartitionsRDD: Removing RDD 122 from persistence list
18/05/31 14:47:43 INFO BlockManager: Removing RDD 122
18/05/31 14:47:43 INFO KafkaRDD: Removing RDD 121 from persistence list
18/05/31 14:47:43 INFO BlockManager: Removing RDD 121
18/05/31 14:47:43 INFO JobGenerator: Checkpointing graph for time 1527767220000 ms
18/05/31 14:47:43 INFO DStreamGraph: Updating checkpoint data for time 1527767220000 ms
18/05/31 14:47:43 INFO DStreamGraph: Updated checkpoint data for time 1527767220000 ms
18/05/31 14:47:43 INFO CheckpointWriter: Submitted checkpoint of time 1527767220000 ms to writer queue
18/05/31 14:47:43 INFO CheckpointWriter: Saving checkpoint for time 1527767220000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000'
18/05/31 14:47:43 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 45 is 149 bytes
18/05/31 14:47:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 149 bytes
18/05/31 14:47:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 149 bytes
18/05/31 14:47:43 INFO DAGScheduler: Registering RDD 233 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 44 is 149 bytes
18/05/31 14:47:43 INFO DAGScheduler: Got job 55 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:43 INFO DAGScheduler: Final stage: ResultStage 352 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 350, ShuffleMapStage 347, ShuffleMapStage 351, ShuffleMapStage 348, ShuffleMapStage 349)
18/05/31 14:47:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 350)
18/05/31 14:47:43 INFO DAGScheduler: Submitting ShuffleMapStage 350 (MapPartitionsRDD[233] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:43 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 4.6 KB, free 354.8 MB)
18/05/31 14:47:43 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.7 MB)
18/05/31 14:47:43 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.8 MB)
18/05/31 14:47:43 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 350 (MapPartitionsRDD[233] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:43 INFO TaskSchedulerImpl: Adding task set 350.0 with 1 tasks
18/05/31 14:47:43 INFO TaskSetManager: Starting task 0.0 in stage 350.0 (TID 243, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:43 INFO Executor: Running task 0.0 in stage 350.0 (TID 243)
18/05/31 14:47:43 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:43 INFO MemoryStore: Block rdd_233_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:47:43 INFO BlockManagerInfo: Added rdd_233_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.8 MB)
18/05/31 14:47:43 INFO Executor: Finished task 0.0 in stage 350.0 (TID 243). 1708 bytes result sent to driver
18/05/31 14:47:43 INFO TaskSetManager: Finished task 0.0 in stage 350.0 (TID 243) in 7 ms on localhost (executor driver) (1/1)
18/05/31 14:47:43 INFO TaskSchedulerImpl: Removed TaskSet 350.0, whose tasks have all completed, from pool 
18/05/31 14:47:43 INFO DAGScheduler: ShuffleMapStage 350 (mapToPair at AnomalyDetector.java:64) finished in 0.007 s
18/05/31 14:47:43 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:43 INFO DAGScheduler: running: Set()
18/05/31 14:47:43 INFO DAGScheduler: waiting: Set(ResultStage 352)
18/05/31 14:47:43 INFO DAGScheduler: failed: Set()
18/05/31 14:47:43 INFO DAGScheduler: Submitting ResultStage 352 (MapPartitionsRDD[236] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:43 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 8.9 KB, free 354.7 MB)
18/05/31 14:47:43 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.7 MB)
18/05/31 14:47:43 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 10.66.169.34:53539 (size: 4.5 KB, free: 354.8 MB)
18/05/31 14:47:43 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 352 (MapPartitionsRDD[236] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:43 INFO TaskSchedulerImpl: Adding task set 352.0 with 4 tasks
18/05/31 14:47:43 INFO TaskSetManager: Starting task 0.0 in stage 352.0 (TID 244, localhost, executor driver, partition 0, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:43 INFO TaskSetManager: Starting task 1.0 in stage 352.0 (TID 245, localhost, executor driver, partition 1, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:43 INFO CheckpointWriter: Checkpoint for time 1527767220000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000', took 6038 bytes and 18 ms
18/05/31 14:47:43 INFO DStreamGraph: Clearing checkpoint data for time 1527767220000 ms
18/05/31 14:47:43 INFO TaskSetManager: Starting task 2.0 in stage 352.0 (TID 246, localhost, executor driver, partition 2, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:43 INFO TaskSetManager: Starting task 3.0 in stage 352.0 (TID 247, localhost, executor driver, partition 3, PROCESS_LOCAL, 6475 bytes)
18/05/31 14:47:43 INFO Executor: Running task 0.0 in stage 352.0 (TID 244)
18/05/31 14:47:43 INFO Executor: Running task 1.0 in stage 352.0 (TID 245)
18/05/31 14:47:43 INFO Executor: Running task 2.0 in stage 352.0 (TID 246)
18/05/31 14:47:43 INFO Executor: Running task 3.0 in stage 352.0 (TID 247)
18/05/31 14:47:43 INFO DStreamCheckpointData: Deleted checkpoint file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-122' for time 1527767020000 ms
18/05/31 14:47:43 INFO DStreamGraph: Cleared checkpoint data for time 1527767220000 ms
18/05/31 14:47:43 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:43 INFO BlockManager: Found block rdd_229_2 locally
18/05/31 14:47:43 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:43 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527767020000: 
18/05/31 14:47:43 INFO InputInfoTracker: remove old batch metadata: 1527767010000 ms
18/05/31 14:47:43 INFO BlockManager: Found block rdd_229_3 locally
18/05/31 14:47:43 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:43 INFO MemoryStore: Block rdd_235_3 stored as values in memory (estimated size 5.5 KB, free 354.7 MB)
18/05/31 14:47:43 INFO BlockManagerInfo: Added rdd_235_3 in memory on 10.66.169.34:53539 (size: 5.5 KB, free: 354.8 MB)
18/05/31 14:47:43 INFO BlockManager: Found block rdd_229_0 locally
18/05/31 14:47:43 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:43 INFO MemoryStore: Block rdd_235_0 stored as values in memory (estimated size 5.5 KB, free 354.7 MB)
18/05/31 14:47:43 INFO BlockManagerInfo: Added rdd_235_0 in memory on 10.66.169.34:53539 (size: 5.5 KB, free: 354.7 MB)
18/05/31 14:47:43 INFO BlockManager: Found block rdd_229_1 locally
18/05/31 14:47:43 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:43 INFO MemoryStore: Block rdd_235_1 stored as values in memory (estimated size 5.5 KB, free 354.7 MB)
18/05/31 14:47:43 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:43 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:43 INFO BlockManagerInfo: Added rdd_235_1 in memory on 10.66.169.34:53539 (size: 5.5 KB, free: 354.7 MB)
18/05/31 14:47:43 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:43 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-178
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:43 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:43 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:43 WARN Executor: 1 block locks were not released by TID = 244:
[rdd_229_0]
18/05/31 14:47:43 INFO Executor: Finished task 0.0 in stage 352.0 (TID 244). 2359 bytes result sent to driver
18/05/31 14:47:43 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-179
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:43 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:43 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:43 WARN Executor: 1 block locks were not released by TID = 245:
[rdd_229_1]
18/05/31 14:47:43 INFO Executor: Finished task 1.0 in stage 352.0 (TID 245). 2359 bytes result sent to driver
18/05/31 14:47:43 INFO TaskSetManager: Finished task 0.0 in stage 352.0 (TID 244) in 25 ms on localhost (executor driver) (1/4)
18/05/31 14:47:43 INFO TaskSetManager: Finished task 1.0 in stage 352.0 (TID 245) in 25 ms on localhost (executor driver) (2/4)
18/05/31 14:47:43 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-177
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:43 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:43 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:43 WARN Executor: 1 block locks were not released by TID = 247:
[rdd_229_3]
18/05/31 14:47:43 INFO Executor: Finished task 3.0 in stage 352.0 (TID 247). 2359 bytes result sent to driver
18/05/31 14:47:43 INFO TaskSetManager: Finished task 3.0 in stage 352.0 (TID 247) in 25 ms on localhost (executor driver) (3/4)
18/05/31 14:47:44 INFO MemoryStore: 5 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:44 INFO BlockManager: Dropping block rdd_227_0 from memory
18/05/31 14:47:44 INFO BlockManagerInfo: Removed rdd_227_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:44 INFO BlockManager: Dropping block broadcast_120_piece0 from memory
18/05/31 14:47:44 INFO BlockManager: Writing block broadcast_120_piece0 to disk
18/05/31 14:47:44 INFO BlockManagerInfo: Added broadcast_120_piece0 on disk on 10.66.169.34:53539 (size: 4.4 KB)
18/05/31 14:47:44 INFO BlockManager: Dropping block rdd_223_1 from memory
18/05/31 14:47:44 INFO BlockManagerInfo: Removed rdd_223_1 on 10.66.169.34:53539 in memory (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:47:44 INFO BlockManager: Dropping block broadcast_120 from memory
18/05/31 14:47:44 INFO BlockManager: Writing block broadcast_120 to disk
18/05/31 14:47:44 INFO BlockManager: Dropping block rdd_223_2 from memory
18/05/31 14:47:44 INFO BlockManagerInfo: Removed rdd_223_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:44 INFO MemoryStore: After dropping 5 blocks, free memory is 633.5 MB
18/05/31 14:47:45 INFO MemoryStore: Block rdd_235_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:45 INFO BlockManagerInfo: Added rdd_235_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:45 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:45 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-180
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:45 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:45 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:45 WARN Executor: 1 block locks were not released by TID = 246:
[rdd_229_2]
18/05/31 14:47:45 INFO Executor: Finished task 2.0 in stage 352.0 (TID 246). 2713 bytes result sent to driver
18/05/31 14:47:45 INFO TaskSetManager: Finished task 2.0 in stage 352.0 (TID 246) in 1726 ms on localhost (executor driver) (4/4)
18/05/31 14:47:45 INFO TaskSchedulerImpl: Removed TaskSet 352.0, whose tasks have all completed, from pool 
18/05/31 14:47:45 INFO DAGScheduler: ResultStage 352 (foreachPartition at AnomalyDetector.java:69) finished in 1.727 s
18/05/31 14:47:45 INFO DAGScheduler: Job 55 finished: foreachPartition at AnomalyDetector.java:69, took 1.743614 s
18/05/31 14:47:45 INFO JobScheduler: Finished job streaming job 1527767230000 ms.0 from job set of time 1527767230000 ms
18/05/31 14:47:45 INFO JobScheduler: Total delay: 35.397 s for time 1527767230000 ms (execution: 1.747 s)
18/05/31 14:47:45 INFO MapPartitionsRDD: Removing RDD 230 from persistence list
18/05/31 14:47:45 INFO JobScheduler: Starting job streaming job 1527767240000 ms.0 from job set of time 1527767240000 ms
18/05/31 14:47:45 INFO BlockManager: Removing RDD 230
18/05/31 14:47:45 INFO MapWithStateRDD: Removing RDD 129 from persistence list
18/05/31 14:47:45 INFO BlockManager: Removing RDD 129
18/05/31 14:47:45 INFO MapPartitionsRDD: Removing RDD 127 from persistence list
18/05/31 14:47:45 INFO KafkaRDD: Removing RDD 126 from persistence list
18/05/31 14:47:45 INFO BlockManager: Removing RDD 127
18/05/31 14:47:45 INFO JobGenerator: Checkpointing graph for time 1527767230000 ms
18/05/31 14:47:45 INFO BlockManager: Removing RDD 126
18/05/31 14:47:45 INFO DStreamGraph: Updating checkpoint data for time 1527767230000 ms
18/05/31 14:47:45 INFO DStreamGraph: Updated checkpoint data for time 1527767230000 ms
18/05/31 14:47:45 INFO CheckpointWriter: Submitted checkpoint of time 1527767230000 ms to writer queue
18/05/31 14:47:45 INFO CheckpointWriter: Saving checkpoint for time 1527767230000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000'
18/05/31 14:47:45 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 45 is 149 bytes
18/05/31 14:47:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 149 bytes
18/05/31 14:47:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 149 bytes
18/05/31 14:47:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 46 is 149 bytes
18/05/31 14:47:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 44 is 149 bytes
18/05/31 14:47:45 INFO DAGScheduler: Registering RDD 240 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:45 INFO DAGScheduler: Got job 56 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:45 INFO DAGScheduler: Final stage: ResultStage 359 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 356, ShuffleMapStage 353, ShuffleMapStage 357, ShuffleMapStage 354, ShuffleMapStage 358, ShuffleMapStage 355)
18/05/31 14:47:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 358)
18/05/31 14:47:45 INFO DAGScheduler: Submitting ShuffleMapStage 358 (MapPartitionsRDD[240] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:45 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:47:45 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.7 MB)
18/05/31 14:47:45 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:45 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 358 (MapPartitionsRDD[240] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:45 INFO TaskSchedulerImpl: Adding task set 358.0 with 1 tasks
18/05/31 14:47:45 INFO TaskSetManager: Starting task 0.0 in stage 358.0 (TID 248, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:45 INFO Executor: Running task 0.0 in stage 358.0 (TID 248)
18/05/31 14:47:45 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:45 INFO MemoryStore: Block rdd_240_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:47:45 INFO BlockManagerInfo: Added rdd_240_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:45 INFO CheckpointWriter: Checkpoint for time 1527767230000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000', took 6020 bytes and 19 ms
18/05/31 14:47:45 INFO DStreamGraph: Clearing checkpoint data for time 1527767230000 ms
18/05/31 14:47:45 INFO Executor: Finished task 0.0 in stage 358.0 (TID 248). 1708 bytes result sent to driver
18/05/31 14:47:45 INFO DStreamGraph: Cleared checkpoint data for time 1527767230000 ms
18/05/31 14:47:45 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:45 INFO TaskSetManager: Finished task 0.0 in stage 358.0 (TID 248) in 4 ms on localhost (executor driver) (1/1)
18/05/31 14:47:45 INFO TaskSchedulerImpl: Removed TaskSet 358.0, whose tasks have all completed, from pool 
18/05/31 14:47:45 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527767030000: 
18/05/31 14:47:45 INFO InputInfoTracker: remove old batch metadata: 1527767020000 ms
18/05/31 14:47:45 INFO DAGScheduler: ShuffleMapStage 358 (mapToPair at AnomalyDetector.java:64) finished in 0.005 s
18/05/31 14:47:45 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:45 INFO DAGScheduler: running: Set()
18/05/31 14:47:45 INFO DAGScheduler: waiting: Set(ResultStage 359)
18/05/31 14:47:45 INFO DAGScheduler: failed: Set()
18/05/31 14:47:45 INFO DAGScheduler: Submitting ResultStage 359 (MapPartitionsRDD[243] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:45 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 9.2 KB, free 354.7 MB)
18/05/31 14:47:45 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.7 MB)
18/05/31 14:47:45 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 10.66.169.34:53539 (size: 4.5 KB, free: 354.7 MB)
18/05/31 14:47:45 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 359 (MapPartitionsRDD[243] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:45 INFO TaskSchedulerImpl: Adding task set 359.0 with 4 tasks
18/05/31 14:47:45 INFO TaskSetManager: Starting task 0.0 in stage 359.0 (TID 249, localhost, executor driver, partition 0, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:45 INFO TaskSetManager: Starting task 1.0 in stage 359.0 (TID 250, localhost, executor driver, partition 1, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:45 INFO TaskSetManager: Starting task 2.0 in stage 359.0 (TID 251, localhost, executor driver, partition 2, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:45 INFO TaskSetManager: Starting task 3.0 in stage 359.0 (TID 252, localhost, executor driver, partition 3, PROCESS_LOCAL, 6500 bytes)
18/05/31 14:47:45 INFO Executor: Running task 1.0 in stage 359.0 (TID 250)
18/05/31 14:47:45 INFO Executor: Running task 2.0 in stage 359.0 (TID 251)
18/05/31 14:47:45 INFO Executor: Running task 3.0 in stage 359.0 (TID 252)
18/05/31 14:47:45 INFO Executor: Running task 0.0 in stage 359.0 (TID 249)
18/05/31 14:47:45 INFO BlockManager: Found block rdd_235_3 locally
18/05/31 14:47:45 INFO BlockManager: Found block rdd_235_2 locally
18/05/31 14:47:45 INFO BlockManager: Found block rdd_235_1 locally
18/05/31 14:47:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:45 INFO MemoryStore: Block rdd_242_1 stored as values in memory (estimated size 6.3 KB, free 354.7 MB)
18/05/31 14:47:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:45 INFO BlockManagerInfo: Added rdd_242_1 in memory on 10.66.169.34:53539 (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:45 INFO MemoryStore: Block rdd_242_3 stored as values in memory (estimated size 6.3 KB, free 354.7 MB)
18/05/31 14:47:45 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:45 INFO BlockManagerInfo: Added rdd_242_3 in memory on 10.66.169.34:53539 (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:45 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:45 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-181
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:45 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:45 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:45 WARN Executor: 1 block locks were not released by TID = 250:
[rdd_235_1]
18/05/31 14:47:45 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-182
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:45 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:45 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:45 WARN Executor: 1 block locks were not released by TID = 252:
[rdd_235_3]
18/05/31 14:47:45 INFO Executor: Finished task 1.0 in stage 359.0 (TID 250). 2359 bytes result sent to driver
18/05/31 14:47:45 INFO Executor: Finished task 3.0 in stage 359.0 (TID 252). 2359 bytes result sent to driver
18/05/31 14:47:45 INFO TaskSetManager: Finished task 1.0 in stage 359.0 (TID 250) in 7 ms on localhost (executor driver) (1/4)
18/05/31 14:47:45 INFO TaskSetManager: Finished task 3.0 in stage 359.0 (TID 252) in 7 ms on localhost (executor driver) (2/4)
18/05/31 14:47:45 INFO BlockManager: Found block rdd_235_0 locally
18/05/31 14:47:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:45 INFO MemoryStore: Block rdd_242_0 stored as values in memory (estimated size 6.3 KB, free 354.7 MB)
18/05/31 14:47:45 INFO BlockManagerInfo: Added rdd_242_0 in memory on 10.66.169.34:53539 (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:45 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:45 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-183
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:45 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:45 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:45 WARN Executor: 1 block locks were not released by TID = 249:
[rdd_235_0]
18/05/31 14:47:45 INFO Executor: Finished task 0.0 in stage 359.0 (TID 249). 2359 bytes result sent to driver
18/05/31 14:47:45 INFO TaskSetManager: Finished task 0.0 in stage 359.0 (TID 249) in 11 ms on localhost (executor driver) (3/4)
18/05/31 14:47:45 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 10.66.169.34:53539 on disk (size: 4.4 KB)
18/05/31 14:47:45 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:45 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 10.66.169.34:53539 in memory (size: 4.5 KB, free: 354.7 MB)
18/05/31 14:47:45 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:46 INFO MemoryStore: 4 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:46 INFO BlockManager: Dropping block rdd_223_0 from memory
18/05/31 14:47:46 INFO BlockManagerInfo: Removed rdd_223_0 on 10.66.169.34:53539 in memory (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:47:46 INFO BlockManager: Dropping block rdd_223_3 from memory
18/05/31 14:47:46 INFO BlockManagerInfo: Removed rdd_223_3 on 10.66.169.34:53539 in memory (size: 4.0 KB, free: 354.7 MB)
18/05/31 14:47:46 INFO BlockManager: Dropping block rdd_233_0 from memory
18/05/31 14:47:46 INFO BlockManagerInfo: Removed rdd_233_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:46 INFO BlockManager: Dropping block rdd_229_2 from memory
18/05/31 14:47:46 INFO BlockManagerInfo: Removed rdd_229_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:46 INFO MemoryStore: After dropping 4 blocks, free memory is 633.5 MB
18/05/31 14:47:47 INFO MemoryStore: Block rdd_242_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:47 INFO BlockManagerInfo: Added rdd_242_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-184
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:47 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:47 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:47 WARN Executor: 1 block locks were not released by TID = 251:
[rdd_235_2]
18/05/31 14:47:47 INFO Executor: Finished task 2.0 in stage 359.0 (TID 251). 2626 bytes result sent to driver
18/05/31 14:47:47 INFO TaskSetManager: Finished task 2.0 in stage 359.0 (TID 251) in 1722 ms on localhost (executor driver) (4/4)
18/05/31 14:47:47 INFO TaskSchedulerImpl: Removed TaskSet 359.0, whose tasks have all completed, from pool 
18/05/31 14:47:47 INFO DAGScheduler: ResultStage 359 (foreachPartition at AnomalyDetector.java:69) finished in 1.723 s
18/05/31 14:47:47 INFO DAGScheduler: Job 56 finished: foreachPartition at AnomalyDetector.java:69, took 1.744265 s
18/05/31 14:47:47 INFO JobScheduler: Finished job streaming job 1527767240000 ms.0 from job set of time 1527767240000 ms
18/05/31 14:47:47 INFO JobScheduler: Total delay: 27.146 s for time 1527767240000 ms (execution: 1.749 s)
18/05/31 14:47:47 INFO MapPartitionsRDD: Removing RDD 236 from persistence list
18/05/31 14:47:47 INFO JobScheduler: Starting job streaming job 1527767250000 ms.0 from job set of time 1527767250000 ms
18/05/31 14:47:47 INFO BlockManager: Removing RDD 236
18/05/31 14:47:47 INFO MapWithStateRDD: Removing RDD 134 from persistence list
18/05/31 14:47:47 INFO BlockManager: Removing RDD 134
18/05/31 14:47:47 INFO MapPartitionsRDD: Removing RDD 132 from persistence list
18/05/31 14:47:47 INFO BlockManager: Removing RDD 132
18/05/31 14:47:47 INFO KafkaRDD: Removing RDD 131 from persistence list
18/05/31 14:47:47 INFO BlockManager: Removing RDD 131
18/05/31 14:47:47 INFO JobGenerator: Checkpointing graph for time 1527767240000 ms
18/05/31 14:47:47 INFO DStreamGraph: Updating checkpoint data for time 1527767240000 ms
18/05/31 14:47:47 INFO DStreamGraph: Updated checkpoint data for time 1527767240000 ms
18/05/31 14:47:47 INFO CheckpointWriter: Submitted checkpoint of time 1527767240000 ms to writer queue
18/05/31 14:47:47 INFO CheckpointWriter: Saving checkpoint for time 1527767240000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000'
18/05/31 14:47:47 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 45 is 149 bytes
18/05/31 14:47:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 149 bytes
18/05/31 14:47:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 149 bytes
18/05/31 14:47:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 46 is 149 bytes
18/05/31 14:47:47 INFO DAGScheduler: Registering RDD 246 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 44 is 149 bytes
18/05/31 14:47:47 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 47 is 149 bytes
18/05/31 14:47:47 INFO DAGScheduler: Got job 57 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:47 INFO DAGScheduler: Final stage: ResultStage 367 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 361, ShuffleMapStage 365, ShuffleMapStage 362, ShuffleMapStage 366, ShuffleMapStage 363, ShuffleMapStage 360, ShuffleMapStage 364)
18/05/31 14:47:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 364)
18/05/31 14:47:47 INFO DAGScheduler: Submitting ShuffleMapStage 364 (MapPartitionsRDD[246] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:47 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:47:47 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.7 MB)
18/05/31 14:47:47 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:47 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 364 (MapPartitionsRDD[246] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:47 INFO TaskSchedulerImpl: Adding task set 364.0 with 1 tasks
18/05/31 14:47:47 INFO TaskSetManager: Starting task 0.0 in stage 364.0 (TID 253, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:47 INFO Executor: Running task 0.0 in stage 364.0 (TID 253)
18/05/31 14:47:47 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:47 INFO MemoryStore: Block rdd_246_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:47:47 INFO BlockManagerInfo: Added rdd_246_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:47 INFO Executor: Finished task 0.0 in stage 364.0 (TID 253). 1708 bytes result sent to driver
18/05/31 14:47:47 INFO TaskSetManager: Finished task 0.0 in stage 364.0 (TID 253) in 4 ms on localhost (executor driver) (1/1)
18/05/31 14:47:47 INFO TaskSchedulerImpl: Removed TaskSet 364.0, whose tasks have all completed, from pool 
18/05/31 14:47:47 INFO DAGScheduler: ShuffleMapStage 364 (mapToPair at AnomalyDetector.java:64) finished in 0.004 s
18/05/31 14:47:47 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:47 INFO DAGScheduler: running: Set()
18/05/31 14:47:47 INFO DAGScheduler: waiting: Set(ResultStage 367)
18/05/31 14:47:47 INFO DAGScheduler: failed: Set()
18/05/31 14:47:47 INFO DAGScheduler: Submitting ResultStage 367 (MapPartitionsRDD[249] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:47 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 9.4 KB, free 354.7 MB)
18/05/31 14:47:47 INFO CheckpointWriter: Checkpoint for time 1527767240000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000', took 6017 bytes and 16 ms
18/05/31 14:47:47 INFO DStreamGraph: Clearing checkpoint data for time 1527767240000 ms
18/05/31 14:47:47 INFO DStreamGraph: Cleared checkpoint data for time 1527767240000 ms
18/05/31 14:47:47 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:47 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527767040000: 
18/05/31 14:47:47 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:47:47 INFO InputInfoTracker: remove old batch metadata: 1527767030000 ms
18/05/31 14:47:47 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 10.66.169.34:53539 (size: 4.6 KB, free: 354.7 MB)
18/05/31 14:47:47 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:47 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 367 (MapPartitionsRDD[249] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:47 INFO TaskSchedulerImpl: Adding task set 367.0 with 4 tasks
18/05/31 14:47:47 INFO TaskSetManager: Starting task 0.0 in stage 367.0 (TID 254, localhost, executor driver, partition 0, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:47 INFO TaskSetManager: Starting task 1.0 in stage 367.0 (TID 255, localhost, executor driver, partition 1, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:47 INFO TaskSetManager: Starting task 2.0 in stage 367.0 (TID 256, localhost, executor driver, partition 2, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:47 INFO TaskSetManager: Starting task 3.0 in stage 367.0 (TID 257, localhost, executor driver, partition 3, PROCESS_LOCAL, 6525 bytes)
18/05/31 14:47:47 INFO Executor: Running task 0.0 in stage 367.0 (TID 254)
18/05/31 14:47:47 INFO Executor: Running task 1.0 in stage 367.0 (TID 255)
18/05/31 14:47:47 INFO Executor: Running task 2.0 in stage 367.0 (TID 256)
18/05/31 14:47:47 INFO Executor: Running task 3.0 in stage 367.0 (TID 257)
18/05/31 14:47:47 INFO BlockManager: Found block rdd_242_1 locally
18/05/31 14:47:47 INFO BlockManager: Found block rdd_242_3 locally
18/05/31 14:47:47 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:47 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:47 INFO BlockManager: Found block rdd_242_2 locally
18/05/31 14:47:47 INFO BlockManager: Found block rdd_242_0 locally
18/05/31 14:47:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:47 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:47 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:47 INFO MemoryStore: Block rdd_248_3 stored as values in memory (estimated size 7.1 KB, free 354.7 MB)
18/05/31 14:47:47 INFO MemoryStore: Block rdd_248_0 stored as values in memory (estimated size 7.1 KB, free 354.7 MB)
18/05/31 14:47:47 INFO MemoryStore: Block rdd_248_1 stored as values in memory (estimated size 7.1 KB, free 354.7 MB)
18/05/31 14:47:47 INFO BlockManagerInfo: Added rdd_248_3 in memory on 10.66.169.34:53539 (size: 7.1 KB, free: 354.7 MB)
18/05/31 14:47:47 INFO BlockManagerInfo: Added rdd_248_0 in memory on 10.66.169.34:53539 (size: 7.1 KB, free: 354.7 MB)
18/05/31 14:47:47 INFO BlockManagerInfo: Added rdd_248_1 in memory on 10.66.169.34:53539 (size: 7.1 KB, free: 354.7 MB)
18/05/31 14:47:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-186
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:47 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:47 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:47 WARN Executor: 1 block locks were not released by TID = 254:
[rdd_242_0]
18/05/31 14:47:47 INFO Executor: Finished task 0.0 in stage 367.0 (TID 254). 2359 bytes result sent to driver
18/05/31 14:47:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-185
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:47 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:47 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:47 WARN Executor: 1 block locks were not released by TID = 257:
[rdd_242_3]
18/05/31 14:47:47 INFO Executor: Finished task 3.0 in stage 367.0 (TID 257). 2359 bytes result sent to driver
18/05/31 14:47:47 INFO TaskSetManager: Finished task 0.0 in stage 367.0 (TID 254) in 8 ms on localhost (executor driver) (1/4)
18/05/31 14:47:47 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-187
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:47 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:47 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:47 INFO TaskSetManager: Finished task 3.0 in stage 367.0 (TID 257) in 7 ms on localhost (executor driver) (2/4)
18/05/31 14:47:47 WARN Executor: 1 block locks were not released by TID = 255:
[rdd_242_1]
18/05/31 14:47:47 INFO Executor: Finished task 1.0 in stage 367.0 (TID 255). 2359 bytes result sent to driver
18/05/31 14:47:47 INFO TaskSetManager: Finished task 1.0 in stage 367.0 (TID 255) in 9 ms on localhost (executor driver) (3/4)
18/05/31 14:47:48 INFO MemoryStore: 6 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:48 INFO BlockManager: Dropping block rdd_229_3 from memory
18/05/31 14:47:48 INFO BlockManagerInfo: Removed rdd_229_3 on 10.66.169.34:53539 in memory (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:47:48 INFO BlockManager: Dropping block rdd_229_0 from memory
18/05/31 14:47:48 INFO BlockManagerInfo: Removed rdd_229_0 on 10.66.169.34:53539 in memory (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:47:48 INFO BlockManager: Dropping block rdd_229_1 from memory
18/05/31 14:47:48 INFO BlockManagerInfo: Removed rdd_229_1 on 10.66.169.34:53539 in memory (size: 4.8 KB, free: 354.7 MB)
18/05/31 14:47:48 INFO BlockManager: Dropping block rdd_240_0 from memory
18/05/31 14:47:48 INFO BlockManagerInfo: Removed rdd_240_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:48 INFO BlockManager: Dropping block broadcast_124_piece0 from memory
18/05/31 14:47:48 INFO BlockManager: Writing block broadcast_124_piece0 to disk
18/05/31 14:47:48 INFO BlockManagerInfo: Added broadcast_124_piece0 on disk on 10.66.169.34:53539 (size: 4.5 KB)
18/05/31 14:47:48 INFO BlockManager: Dropping block rdd_235_2 from memory
18/05/31 14:47:48 INFO BlockManagerInfo: Removed rdd_235_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:48 INFO MemoryStore: After dropping 6 blocks, free memory is 633.5 MB
18/05/31 14:47:48 INFO MemoryStore: Block rdd_248_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:48 INFO BlockManagerInfo: Added rdd_248_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:48 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:48 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-188
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:48 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:48 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:48 WARN Executor: 1 block locks were not released by TID = 256:
[rdd_242_2]
18/05/31 14:47:48 INFO Executor: Finished task 2.0 in stage 367.0 (TID 256). 2757 bytes result sent to driver
18/05/31 14:47:48 INFO TaskSetManager: Finished task 2.0 in stage 367.0 (TID 256) in 1747 ms on localhost (executor driver) (4/4)
18/05/31 14:47:48 INFO TaskSchedulerImpl: Removed TaskSet 367.0, whose tasks have all completed, from pool 
18/05/31 14:47:48 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 10.66.169.34:53539 on disk (size: 4.5 KB)
18/05/31 14:47:48 INFO DAGScheduler: ResultStage 367 (foreachPartition at AnomalyDetector.java:69) finished in 1.749 s
18/05/31 14:47:48 INFO DAGScheduler: Job 57 finished: foreachPartition at AnomalyDetector.java:69, took 1.765016 s
18/05/31 14:47:48 INFO JobScheduler: Finished job streaming job 1527767250000 ms.0 from job set of time 1527767250000 ms
18/05/31 14:47:48 INFO JobScheduler: Total delay: 18.914 s for time 1527767250000 ms (execution: 1.768 s)
18/05/31 14:47:48 INFO JobScheduler: Starting job streaming job 1527767260000 ms.0 from job set of time 1527767260000 ms
18/05/31 14:47:48 INFO MapPartitionsRDD: Removing RDD 243 from persistence list
18/05/31 14:47:48 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:48 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:48 INFO MapWithStateRDD: Removing RDD 139 from persistence list
18/05/31 14:47:48 INFO BlockManager: Removing RDD 243
18/05/31 14:47:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 45 is 149 bytes
18/05/31 14:47:48 INFO BlockManager: Removing RDD 139
18/05/31 14:47:48 INFO MapPartitionsRDD: Removing RDD 137 from persistence list
18/05/31 14:47:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 149 bytes
18/05/31 14:47:48 INFO BlockManager: Removing RDD 137
18/05/31 14:47:48 INFO KafkaRDD: Removing RDD 136 from persistence list
18/05/31 14:47:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 149 bytes
18/05/31 14:47:48 INFO BlockManager: Removing RDD 136
18/05/31 14:47:48 INFO JobGenerator: Checkpointing graph for time 1527767250000 ms
18/05/31 14:47:48 INFO DStreamGraph: Updating checkpoint data for time 1527767250000 ms
18/05/31 14:47:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 46 is 149 bytes
18/05/31 14:47:48 INFO DStreamGraph: Updated checkpoint data for time 1527767250000 ms
18/05/31 14:47:48 INFO CheckpointWriter: Submitted checkpoint of time 1527767250000 ms to writer queue
18/05/31 14:47:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 48 is 149 bytes
18/05/31 14:47:48 INFO CheckpointWriter: Saving checkpoint for time 1527767250000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000'
18/05/31 14:47:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 44 is 149 bytes
18/05/31 14:47:48 INFO DAGScheduler: Registering RDD 253 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:48 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 47 is 149 bytes
18/05/31 14:47:48 INFO DAGScheduler: Got job 58 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:48 INFO DAGScheduler: Final stage: ResultStage 376 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 374, ShuffleMapStage 371, ShuffleMapStage 368, ShuffleMapStage 375, ShuffleMapStage 372, ShuffleMapStage 369, ShuffleMapStage 373, ShuffleMapStage 370)
18/05/31 14:47:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 374)
18/05/31 14:47:48 INFO DAGScheduler: Submitting ShuffleMapStage 374 (MapPartitionsRDD[253] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:48 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 5.9 KB, free 354.7 MB)
18/05/31 14:47:48 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.7 MB)
18/05/31 14:47:48 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:48 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 374 (MapPartitionsRDD[253] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:48 INFO TaskSchedulerImpl: Adding task set 374.0 with 1 tasks
18/05/31 14:47:48 INFO TaskSetManager: Starting task 0.0 in stage 374.0 (TID 258, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:48 INFO Executor: Running task 0.0 in stage 374.0 (TID 258)
18/05/31 14:47:48 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:48 INFO MemoryStore: Block rdd_253_0 stored as bytes in memory (estimated size 4.0 B, free 354.7 MB)
18/05/31 14:47:48 INFO BlockManagerInfo: Added rdd_253_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:48 INFO Executor: Finished task 0.0 in stage 374.0 (TID 258). 1708 bytes result sent to driver
18/05/31 14:47:48 INFO TaskSetManager: Finished task 0.0 in stage 374.0 (TID 258) in 7 ms on localhost (executor driver) (1/1)
18/05/31 14:47:48 INFO TaskSchedulerImpl: Removed TaskSet 374.0, whose tasks have all completed, from pool 
18/05/31 14:47:48 INFO DAGScheduler: ShuffleMapStage 374 (mapToPair at AnomalyDetector.java:64) finished in 0.007 s
18/05/31 14:47:48 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:48 INFO DAGScheduler: running: Set()
18/05/31 14:47:48 INFO DAGScheduler: waiting: Set(ResultStage 376)
18/05/31 14:47:48 INFO DAGScheduler: failed: Set()
18/05/31 14:47:48 INFO DAGScheduler: Submitting ResultStage 376 (MapPartitionsRDD[256] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:48 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 9.7 KB, free 354.7 MB)
18/05/31 14:47:48 INFO CheckpointWriter: Checkpoint for time 1527767250000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767260000', took 6006 bytes and 15 ms
18/05/31 14:47:48 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 4.6 KB, free 354.7 MB)
18/05/31 14:47:48 INFO DStreamGraph: Clearing checkpoint data for time 1527767250000 ms
18/05/31 14:47:48 INFO DStreamGraph: Cleared checkpoint data for time 1527767250000 ms
18/05/31 14:47:48 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:48 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 10.66.169.34:53539 (size: 4.6 KB, free: 354.7 MB)
18/05/31 14:47:48 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 1 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527767050000: file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata/log-1527766980586-1527767040586
18/05/31 14:47:48 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:48 INFO InputInfoTracker: remove old batch metadata: 1527767040000 ms
18/05/31 14:47:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 376 (MapPartitionsRDD[256] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:48 INFO TaskSchedulerImpl: Adding task set 376.0 with 4 tasks
18/05/31 14:47:48 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Cleared log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527767050000
18/05/31 14:47:48 INFO TaskSetManager: Starting task 0.0 in stage 376.0 (TID 259, localhost, executor driver, partition 0, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:48 INFO TaskSetManager: Starting task 1.0 in stage 376.0 (TID 260, localhost, executor driver, partition 1, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:48 INFO TaskSetManager: Starting task 2.0 in stage 376.0 (TID 261, localhost, executor driver, partition 2, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:48 INFO TaskSetManager: Starting task 3.0 in stage 376.0 (TID 262, localhost, executor driver, partition 3, PROCESS_LOCAL, 6550 bytes)
18/05/31 14:47:48 INFO Executor: Running task 3.0 in stage 376.0 (TID 262)
18/05/31 14:47:48 INFO Executor: Running task 1.0 in stage 376.0 (TID 260)
18/05/31 14:47:48 INFO Executor: Running task 0.0 in stage 376.0 (TID 259)
18/05/31 14:47:48 INFO Executor: Running task 2.0 in stage 376.0 (TID 261)
18/05/31 14:47:48 INFO BlockManager: Found block rdd_248_3 locally
18/05/31 14:47:48 INFO BlockManager: Found block rdd_248_2 locally
18/05/31 14:47:48 INFO BlockManager: Found block rdd_248_1 locally
18/05/31 14:47:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:48 INFO MemoryStore: Block rdd_255_3 stored as values in memory (estimated size 7.8 KB, free 354.7 MB)
18/05/31 14:47:48 INFO MemoryStore: Block rdd_255_1 stored as values in memory (estimated size 7.8 KB, free 354.7 MB)
18/05/31 14:47:48 INFO BlockManagerInfo: Added rdd_255_3 in memory on 10.66.169.34:53539 (size: 7.8 KB, free: 354.7 MB)
18/05/31 14:47:48 INFO BlockManagerInfo: Added rdd_255_1 in memory on 10.66.169.34:53539 (size: 7.8 KB, free: 354.7 MB)
18/05/31 14:47:48 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:48 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:48 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-190
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:48 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:48 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:48 WARN Executor: 1 block locks were not released by TID = 260:
[rdd_248_1]
18/05/31 14:47:48 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-189
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:48 INFO Executor: Finished task 1.0 in stage 376.0 (TID 260). 2359 bytes result sent to driver
18/05/31 14:47:48 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:48 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:48 WARN Executor: 1 block locks were not released by TID = 262:
[rdd_248_3]
18/05/31 14:47:48 INFO Executor: Finished task 3.0 in stage 376.0 (TID 262). 2359 bytes result sent to driver
18/05/31 14:47:48 INFO TaskSetManager: Finished task 3.0 in stage 376.0 (TID 262) in 8 ms on localhost (executor driver) (1/4)
18/05/31 14:47:48 INFO TaskSetManager: Finished task 1.0 in stage 376.0 (TID 260) in 10 ms on localhost (executor driver) (2/4)
18/05/31 14:47:48 INFO BlockManager: Found block rdd_248_0 locally
18/05/31 14:47:48 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:48 INFO MemoryStore: Block rdd_255_0 stored as values in memory (estimated size 7.8 KB, free 354.7 MB)
18/05/31 14:47:48 INFO BlockManagerInfo: Added rdd_255_0 in memory on 10.66.169.34:53539 (size: 7.8 KB, free: 354.7 MB)
18/05/31 14:47:48 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:48 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-191
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:48 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:48 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:48 WARN Executor: 1 block locks were not released by TID = 259:
[rdd_248_0]
18/05/31 14:47:48 INFO Executor: Finished task 0.0 in stage 376.0 (TID 259). 2359 bytes result sent to driver
18/05/31 14:47:48 INFO TaskSetManager: Finished task 0.0 in stage 376.0 (TID 259) in 17 ms on localhost (executor driver) (3/4)
18/05/31 14:47:49 INFO MemoryStore: 8 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:49 INFO BlockManager: Dropping block rdd_235_3 from memory
18/05/31 14:47:49 INFO BlockManagerInfo: Removed rdd_235_3 on 10.66.169.34:53539 in memory (size: 5.5 KB, free: 354.7 MB)
18/05/31 14:47:49 INFO BlockManager: Dropping block rdd_235_1 from memory
18/05/31 14:47:49 INFO BlockManagerInfo: Removed rdd_235_1 on 10.66.169.34:53539 in memory (size: 5.5 KB, free: 354.7 MB)
18/05/31 14:47:49 INFO BlockManager: Dropping block rdd_235_0 from memory
18/05/31 14:47:49 INFO BlockManagerInfo: Removed rdd_235_0 on 10.66.169.34:53539 in memory (size: 5.5 KB, free: 354.7 MB)
18/05/31 14:47:49 INFO BlockManager: Dropping block rdd_246_0 from memory
18/05/31 14:47:49 INFO BlockManagerInfo: Removed rdd_246_0 on 10.66.169.34:53539 in memory (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:49 INFO BlockManager: Dropping block broadcast_126_piece0 from memory
18/05/31 14:47:49 INFO BlockManager: Writing block broadcast_126_piece0 to disk
18/05/31 14:47:49 INFO BlockManagerInfo: Added broadcast_126_piece0 on disk on 10.66.169.34:53539 (size: 4.6 KB)
18/05/31 14:47:49 INFO BlockManager: Dropping block broadcast_126 from memory
18/05/31 14:47:49 INFO BlockManager: Writing block broadcast_126 to disk
18/05/31 14:47:49 INFO BlockManager: Dropping block rdd_242_1 from memory
18/05/31 14:47:49 INFO BlockManagerInfo: Removed rdd_242_1 on 10.66.169.34:53539 in memory (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:49 INFO BlockManager: Dropping block rdd_242_2 from memory
18/05/31 14:47:49 INFO BlockManagerInfo: Removed rdd_242_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:49 INFO MemoryStore: After dropping 8 blocks, free memory is 633.5 MB
18/05/31 14:47:50 INFO JobScheduler: Added jobs for time 1527767270000 ms
18/05/31 14:47:50 INFO JobGenerator: Checkpointing graph for time 1527767270000 ms
18/05/31 14:47:50 INFO DStreamGraph: Updating checkpoint data for time 1527767270000 ms
18/05/31 14:47:50 INFO DStreamGraph: Updated checkpoint data for time 1527767270000 ms
18/05/31 14:47:50 INFO CheckpointWriter: Submitted checkpoint of time 1527767270000 ms to writer queue
18/05/31 14:47:50 INFO CheckpointWriter: Saving checkpoint for time 1527767270000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767270000'
18/05/31 14:47:50 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000.bk
18/05/31 14:47:50 INFO CheckpointWriter: Checkpoint for time 1527767270000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767270000', took 6009 bytes and 11 ms
18/05/31 14:47:50 INFO MemoryStore: Block rdd_255_2 stored as values in memory (estimated size 278.8 MB, free 354.7 MB)
18/05/31 14:47:50 INFO BlockManagerInfo: Added rdd_255_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-192
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:50 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:50 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:50 WARN Executor: 1 block locks were not released by TID = 261:
[rdd_248_2]
18/05/31 14:47:50 INFO Executor: Finished task 2.0 in stage 376.0 (TID 261). 2854 bytes result sent to driver
18/05/31 14:47:50 INFO TaskSetManager: Finished task 2.0 in stage 376.0 (TID 261) in 1630 ms on localhost (executor driver) (4/4)
18/05/31 14:47:50 INFO TaskSchedulerImpl: Removed TaskSet 376.0, whose tasks have all completed, from pool 
18/05/31 14:47:50 INFO DAGScheduler: ResultStage 376 (foreachPartition at AnomalyDetector.java:69) finished in 1.631 s
18/05/31 14:47:50 INFO DAGScheduler: Job 58 finished: foreachPartition at AnomalyDetector.java:69, took 1.651466 s
18/05/31 14:47:50 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 127.1 KB, free 354.6 MB)
18/05/31 14:47:50 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.6 MB)
18/05/31 14:47:50 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:50 INFO SparkContext: Created broadcast 129 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:50 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:50 INFO DAGScheduler: Got job 59 (foreachPartition at AnomalyDetector.java:69) with 1 output partitions
18/05/31 14:47:50 INFO DAGScheduler: Final stage: ResultStage 377 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:50 INFO DAGScheduler: Parents of final stage: List()
18/05/31 14:47:50 INFO DAGScheduler: Missing parents: List()
18/05/31 14:47:50 INFO DAGScheduler: Submitting ResultStage 377 (MapPartitionsRDD[253] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:50 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 6.1 KB, free 354.6 MB)
18/05/31 14:47:50 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 3.6 KB, free 354.6 MB)
18/05/31 14:47:50 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 10.66.169.34:53539 (size: 3.6 KB, free: 354.7 MB)
18/05/31 14:47:50 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 377 (MapPartitionsRDD[253] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:50 INFO TaskSchedulerImpl: Adding task set 377.0 with 1 tasks
18/05/31 14:47:50 INFO TaskSetManager: Starting task 0.0 in stage 377.0 (TID 263, localhost, executor driver, partition 0, PROCESS_LOCAL, 6166 bytes)
18/05/31 14:47:50 INFO Executor: Running task 0.0 in stage 377.0 (TID 263)
18/05/31 14:47:50 INFO BlockManager: Found block rdd_253_0 locally
18/05/31 14:47:50 INFO Executor: Finished task 0.0 in stage 377.0 (TID 263). 1004 bytes result sent to driver
18/05/31 14:47:50 INFO TaskSetManager: Finished task 0.0 in stage 377.0 (TID 263) in 11 ms on localhost (executor driver) (1/1)
18/05/31 14:47:50 INFO TaskSchedulerImpl: Removed TaskSet 377.0, whose tasks have all completed, from pool 
18/05/31 14:47:50 INFO DAGScheduler: ResultStage 377 (foreachPartition at AnomalyDetector.java:69) finished in 0.011 s
18/05/31 14:47:50 INFO DAGScheduler: Job 59 finished: foreachPartition at AnomalyDetector.java:69, took 0.014450 s
18/05/31 14:47:50 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 127.1 KB, free 354.4 MB)
18/05/31 14:47:50 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 14.3 KB, free 354.4 MB)
18/05/31 14:47:50 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 10.66.169.34:53539 (size: 14.3 KB, free: 354.7 MB)
18/05/31 14:47:50 INFO SparkContext: Created broadcast 131 from foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:50 INFO ReliableRDDCheckpointData: Done checkpointing RDD 253 to file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/34a26ffe-2461-4d92-b963-1fff0ad90d8c/rdd-253, new parent is RDD 262
18/05/31 14:47:50 INFO JobScheduler: Finished job streaming job 1527767260000 ms.0 from job set of time 1527767260000 ms
18/05/31 14:47:50 INFO JobScheduler: Total delay: 10.606 s for time 1527767260000 ms (execution: 1.690 s)
18/05/31 14:47:50 INFO MapPartitionsRDD: Removing RDD 249 from persistence list
18/05/31 14:47:50 INFO JobScheduler: Starting job streaming job 1527767270000 ms.0 from job set of time 1527767270000 ms
18/05/31 14:47:50 INFO BlockManager: Removing RDD 249
18/05/31 14:47:50 INFO MapWithStateRDD: Removing RDD 144 from persistence list
18/05/31 14:47:50 INFO BlockManager: Removing RDD 144
18/05/31 14:47:50 INFO MapPartitionsRDD: Removing RDD 142 from persistence list
18/05/31 14:47:50 INFO BlockManager: Removing RDD 142
18/05/31 14:47:50 INFO KafkaRDD: Removing RDD 141 from persistence list
18/05/31 14:47:50 INFO BlockManager: Removing RDD 141
18/05/31 14:47:50 INFO JobGenerator: Checkpointing graph for time 1527767260000 ms
18/05/31 14:47:50 INFO DStreamGraph: Updating checkpoint data for time 1527767260000 ms
18/05/31 14:47:50 INFO DStreamGraph: Updated checkpoint data for time 1527767260000 ms
18/05/31 14:47:50 INFO CheckpointWriter: Submitted checkpoint of time 1527767260000 ms to writer queue
18/05/31 14:47:50 INFO CheckpointWriter: Saving checkpoint for time 1527767260000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767270000'
18/05/31 14:47:50 INFO SparkContext: Starting job: foreachPartition at AnomalyDetector.java:69
18/05/31 14:47:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 45 is 149 bytes
18/05/31 14:47:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 149 bytes
18/05/31 14:47:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 149 bytes
18/05/31 14:47:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 46 is 149 bytes
18/05/31 14:47:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 48 is 149 bytes
18/05/31 14:47:50 INFO DAGScheduler: Registering RDD 258 (mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 44 is 149 bytes
18/05/31 14:47:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 49 is 149 bytes
18/05/31 14:47:50 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 47 is 149 bytes
18/05/31 14:47:50 INFO DAGScheduler: Got job 60 (foreachPartition at AnomalyDetector.java:69) with 4 output partitions
18/05/31 14:47:50 INFO DAGScheduler: Final stage: ResultStage 387 (foreachPartition at AnomalyDetector.java:69)
18/05/31 14:47:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 386, ShuffleMapStage 383, ShuffleMapStage 379, ShuffleMapStage 380, ShuffleMapStage 384, ShuffleMapStage 381, ShuffleMapStage 378, ShuffleMapStage 385, ShuffleMapStage 382)
18/05/31 14:47:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 383)
18/05/31 14:47:50 INFO DAGScheduler: Submitting ShuffleMapStage 383 (MapPartitionsRDD[258] at mapToPair at AnomalyDetector.java:64), which has no missing parents
18/05/31 14:47:50 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 4.6 KB, free 354.4 MB)
18/05/31 14:47:50 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 2.8 KB, free 354.4 MB)
18/05/31 14:47:50 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 10.66.169.34:53539 (size: 2.8 KB, free: 354.7 MB)
18/05/31 14:47:50 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 383 (MapPartitionsRDD[258] at mapToPair at AnomalyDetector.java:64)
18/05/31 14:47:50 INFO TaskSchedulerImpl: Adding task set 383.0 with 1 tasks
18/05/31 14:47:50 INFO TaskSetManager: Starting task 0.0 in stage 383.0 (TID 264, localhost, executor driver, partition 0, PROCESS_LOCAL, 6226 bytes)
18/05/31 14:47:50 INFO Executor: Running task 0.0 in stage 383.0 (TID 264)
18/05/31 14:47:50 INFO KafkaRDD: Beginning offset 81681 is the same as ending offset skipping monitoring20 0
18/05/31 14:47:50 INFO MemoryStore: Block rdd_258_0 stored as bytes in memory (estimated size 4.0 B, free 354.4 MB)
18/05/31 14:47:50 INFO BlockManagerInfo: Added rdd_258_0 in memory on 10.66.169.34:53539 (size: 4.0 B, free: 354.7 MB)
18/05/31 14:47:50 INFO Executor: Finished task 0.0 in stage 383.0 (TID 264). 1621 bytes result sent to driver
18/05/31 14:47:50 INFO TaskSetManager: Finished task 0.0 in stage 383.0 (TID 264) in 3 ms on localhost (executor driver) (1/1)
18/05/31 14:47:50 INFO TaskSchedulerImpl: Removed TaskSet 383.0, whose tasks have all completed, from pool 
18/05/31 14:47:50 INFO DAGScheduler: ShuffleMapStage 383 (mapToPair at AnomalyDetector.java:64) finished in 0.004 s
18/05/31 14:47:50 INFO DAGScheduler: looking for newly runnable stages
18/05/31 14:47:50 INFO DAGScheduler: running: Set()
18/05/31 14:47:50 INFO DAGScheduler: waiting: Set(ResultStage 387)
18/05/31 14:47:50 INFO DAGScheduler: failed: Set()
18/05/31 14:47:50 INFO DAGScheduler: Submitting ResultStage 387 (MapPartitionsRDD[261] at mapWithState at AnomalyDetector.java:68), which has no missing parents
18/05/31 14:47:50 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 10.0 KB, free 354.4 MB)
18/05/31 14:47:50 INFO CheckpointWriter: Deleting file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767220000
18/05/31 14:47:50 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 4.7 KB, free 354.4 MB)
18/05/31 14:47:50 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 10.66.169.34:53539 (size: 4.7 KB, free: 354.7 MB)
18/05/31 14:47:50 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:996
18/05/31 14:47:50 INFO CheckpointWriter: Checkpoint for time 1527767260000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767270000', took 6018 bytes and 13 ms
18/05/31 14:47:50 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 387 (MapPartitionsRDD[261] at mapWithState at AnomalyDetector.java:68)
18/05/31 14:47:50 INFO DStreamGraph: Clearing checkpoint data for time 1527767260000 ms
18/05/31 14:47:50 INFO TaskSchedulerImpl: Adding task set 387.0 with 4 tasks
18/05/31 14:47:50 INFO DStreamGraph: Cleared checkpoint data for time 1527767260000 ms
18/05/31 14:47:50 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:50 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527767060000: 
18/05/31 14:47:50 INFO InputInfoTracker: remove old batch metadata: 1527767050000 ms
18/05/31 14:47:50 INFO TaskSetManager: Starting task 0.0 in stage 387.0 (TID 265, localhost, executor driver, partition 0, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:50 INFO TaskSetManager: Starting task 1.0 in stage 387.0 (TID 266, localhost, executor driver, partition 1, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:50 INFO TaskSetManager: Starting task 2.0 in stage 387.0 (TID 267, localhost, executor driver, partition 2, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:50 INFO TaskSetManager: Starting task 3.0 in stage 387.0 (TID 268, localhost, executor driver, partition 3, PROCESS_LOCAL, 6575 bytes)
18/05/31 14:47:50 INFO Executor: Running task 0.0 in stage 387.0 (TID 265)
18/05/31 14:47:50 INFO Executor: Running task 1.0 in stage 387.0 (TID 266)
18/05/31 14:47:50 INFO Executor: Running task 2.0 in stage 387.0 (TID 267)
18/05/31 14:47:50 INFO Executor: Running task 3.0 in stage 387.0 (TID 268)
18/05/31 14:47:50 INFO BlockManager: Found block rdd_255_3 locally
18/05/31 14:47:50 INFO BlockManager: Found block rdd_255_1 locally
18/05/31 14:47:50 INFO BlockManager: Found block rdd_255_0 locally
18/05/31 14:47:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:50 INFO MemoryStore: Block rdd_260_0 stored as values in memory (estimated size 8.6 KB, free 354.4 MB)
18/05/31 14:47:50 INFO BlockManager: Found block rdd_255_2 locally
18/05/31 14:47:50 INFO BlockManagerInfo: Added rdd_260_0 in memory on 10.66.169.34:53539 (size: 8.6 KB, free: 354.7 MB)
18/05/31 14:47:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
18/05/31 14:47:50 INFO MemoryStore: Block rdd_260_3 stored as values in memory (estimated size 8.6 KB, free 354.4 MB)
18/05/31 14:47:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:50 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
18/05/31 14:47:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
18/05/31 14:47:50 INFO MemoryStore: Block rdd_260_1 stored as values in memory (estimated size 8.6 KB, free 354.4 MB)
18/05/31 14:47:50 INFO BlockManagerInfo: Added rdd_260_3 in memory on 10.66.169.34:53539 (size: 8.6 KB, free: 354.7 MB)
18/05/31 14:47:50 INFO BlockManagerInfo: Added rdd_260_1 in memory on 10.66.169.34:53539 (size: 8.6 KB, free: 354.7 MB)
18/05/31 14:47:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-193
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:50 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:50 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:50 WARN Executor: 1 block locks were not released by TID = 265:
[rdd_255_0]
18/05/31 14:47:50 INFO Executor: Finished task 0.0 in stage 387.0 (TID 265). 2359 bytes result sent to driver
18/05/31 14:47:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:50 INFO TaskSetManager: Finished task 0.0 in stage 387.0 (TID 265) in 15 ms on localhost (executor driver) (1/4)
18/05/31 14:47:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-194
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:50 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:50 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:50 WARN Executor: 1 block locks were not released by TID = 268:
[rdd_255_3]
18/05/31 14:47:50 INFO Executor: Finished task 3.0 in stage 387.0 (TID 268). 2359 bytes result sent to driver
18/05/31 14:47:50 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-195
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:50 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:50 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:50 INFO TaskSetManager: Finished task 3.0 in stage 387.0 (TID 268) in 17 ms on localhost (executor driver) (2/4)
18/05/31 14:47:50 WARN Executor: 1 block locks were not released by TID = 266:
[rdd_255_1]
18/05/31 14:47:50 INFO Executor: Finished task 1.0 in stage 387.0 (TID 266). 2359 bytes result sent to driver
18/05/31 14:47:50 INFO TaskSetManager: Finished task 1.0 in stage 387.0 (TID 266) in 19 ms on localhost (executor driver) (3/4)
18/05/31 14:47:51 INFO MemoryStore: 8 blocks selected for dropping (278.8 MB bytes)
18/05/31 14:47:51 INFO BlockManager: Dropping block rdd_242_3 from memory
18/05/31 14:47:51 INFO BlockManagerInfo: Removed rdd_242_3 on 10.66.169.34:53539 in memory (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:51 INFO BlockManager: Dropping block rdd_242_0 from memory
18/05/31 14:47:51 INFO BlockManagerInfo: Removed rdd_242_0 on 10.66.169.34:53539 in memory (size: 6.3 KB, free: 354.7 MB)
18/05/31 14:47:51 INFO BlockManager: Dropping block broadcast_127_piece0 from memory
18/05/31 14:47:51 INFO BlockManager: Writing block broadcast_127_piece0 to disk
18/05/31 14:47:51 INFO BlockManagerInfo: Added broadcast_127_piece0 on disk on 10.66.169.34:53539 (size: 3.6 KB)
18/05/31 14:47:51 INFO BlockManager: Dropping block broadcast_127 from memory
18/05/31 14:47:51 INFO BlockManager: Writing block broadcast_127 to disk
18/05/31 14:47:51 INFO BlockManager: Dropping block broadcast_128_piece0 from memory
18/05/31 14:47:51 INFO BlockManager: Writing block broadcast_128_piece0 to disk
18/05/31 14:47:51 INFO BlockManagerInfo: Added broadcast_128_piece0 on disk on 10.66.169.34:53539 (size: 4.6 KB)
18/05/31 14:47:51 INFO BlockManager: Dropping block rdd_248_3 from memory
18/05/31 14:47:51 INFO BlockManagerInfo: Removed rdd_248_3 on 10.66.169.34:53539 in memory (size: 7.1 KB, free: 354.7 MB)
18/05/31 14:47:51 INFO BlockManager: Dropping block rdd_248_1 from memory
18/05/31 14:47:51 INFO BlockManagerInfo: Removed rdd_248_1 on 10.66.169.34:53539 in memory (size: 7.1 KB, free: 354.7 MB)
18/05/31 14:47:51 INFO BlockManager: Dropping block rdd_248_2 from memory
18/05/31 14:47:51 INFO BlockManagerInfo: Removed rdd_248_2 on 10.66.169.34:53539 in memory (size: 278.8 MB, free: 633.5 MB)
18/05/31 14:47:51 INFO MemoryStore: After dropping 8 blocks, free memory is 633.2 MB
18/05/31 14:47:52 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 10.66.169.34:53539 in memory (size: 2.8 KB, free: 633.5 MB)
18/05/31 14:47:52 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 10.66.169.34:53539 in memory (size: 14.3 KB, free: 633.5 MB)
18/05/31 14:47:52 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 10.66.169.34:53539 on disk (size: 4.6 KB)
18/05/31 14:47:52 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 10.66.169.34:53539 on disk (size: 3.6 KB)
18/05/31 14:47:52 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 10.66.169.34:53539 on disk (size: 4.6 KB)
18/05/31 14:47:52 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 10.66.169.34:53539 in memory (size: 3.6 KB, free: 633.5 MB)
18/05/31 14:47:52 INFO MemoryStore: Block rdd_260_2 stored as values in memory (estimated size 278.8 MB, free 354.6 MB)
18/05/31 14:47:52 INFO BlockManagerInfo: Added rdd_260_2 in memory on 10.66.169.34:53539 (size: 278.8 MB, free: 354.7 MB)
18/05/31 14:47:52 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:52 INFO ProducerConfig: ProducerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	sasl.mechanism = GSSAPI
	max.block.ms = 60000
	interceptor.classes = null
	ssl.truststore.password = null
	client.id = producer-196
	ssl.endpoint.identification.algorithm = null
	request.timeout.ms = 30000
	acks = all
	receive.buffer.bytes = 32768
	ssl.truststore.type = JKS
	retries = 0
	ssl.truststore.location = null
	ssl.keystore.password = null
	send.buffer.bytes = 131072
	compression.type = none
	metadata.fetch.timeout.ms = 60000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	buffer.memory = 33554432
	timeout.ms = 30000
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	block.on.buffer.full = false
	ssl.key.password = null
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	max.in.flight.requests.per.connection = 5
	metrics.num.samples = 2
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	batch.size = 100
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	max.request.size = 1048576
	value.serializer = class com.epam.bdcc.serde.KafkaJsonMonitoringRecordSerDe
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	partitioner.class = class com.epam.bdcc.kafka.MonitoringRecordPartitioner
	linger.ms = 1

18/05/31 14:47:52 INFO AppInfoParser: Kafka version : 0.10.0.1
18/05/31 14:47:52 INFO AppInfoParser: Kafka commitId : a7a17cdec9eaa6c5
18/05/31 14:47:52 WARN Executor: 1 block locks were not released by TID = 267:
[rdd_255_2]
18/05/31 14:47:52 INFO Executor: Finished task 2.0 in stage 387.0 (TID 267). 2936 bytes result sent to driver
18/05/31 14:47:52 INFO TaskSetManager: Finished task 2.0 in stage 387.0 (TID 267) in 1721 ms on localhost (executor driver) (4/4)
18/05/31 14:47:52 INFO TaskSchedulerImpl: Removed TaskSet 387.0, whose tasks have all completed, from pool 
18/05/31 14:47:52 INFO DAGScheduler: ResultStage 387 (foreachPartition at AnomalyDetector.java:69) finished in 1.722 s
18/05/31 14:47:52 INFO DAGScheduler: Job 60 finished: foreachPartition at AnomalyDetector.java:69, took 1.735915 s
18/05/31 14:47:52 INFO JobScheduler: Finished job streaming job 1527767270000 ms.0 from job set of time 1527767270000 ms
18/05/31 14:47:52 INFO JobScheduler: Total delay: 2.345 s for time 1527767270000 ms (execution: 1.739 s)
18/05/31 14:47:52 INFO MapPartitionsRDD: Removing RDD 256 from persistence list
18/05/31 14:47:52 INFO BlockManager: Removing RDD 256
18/05/31 14:47:52 INFO MapWithStateRDD: Removing RDD 149 from persistence list
18/05/31 14:47:52 INFO BlockManager: Removing RDD 149
18/05/31 14:47:52 INFO MapPartitionsRDD: Removing RDD 147 from persistence list
18/05/31 14:47:52 INFO BlockManager: Removing RDD 147
18/05/31 14:47:52 INFO KafkaRDD: Removing RDD 146 from persistence list
18/05/31 14:47:52 INFO BlockManager: Removing RDD 146
18/05/31 14:47:52 INFO JobGenerator: Checkpointing graph for time 1527767270000 ms
18/05/31 14:47:52 INFO DStreamGraph: Updating checkpoint data for time 1527767270000 ms
18/05/31 14:47:52 INFO DStreamGraph: Updated checkpoint data for time 1527767270000 ms
18/05/31 14:47:52 INFO CheckpointWriter: Submitted checkpoint of time 1527767270000 ms to writer queue
18/05/31 14:47:52 INFO CheckpointWriter: Saving checkpoint for time 1527767270000 ms to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767270000'
18/05/31 14:47:52 INFO CheckpointWriter: Checkpoint for time 1527767270000 ms saved to file 'file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/checkpoint-1527767270000', took 6004 bytes and 12 ms
18/05/31 14:47:52 INFO DStreamGraph: Clearing checkpoint data for time 1527767270000 ms
18/05/31 14:47:52 INFO DStreamGraph: Cleared checkpoint data for time 1527767270000 ms
18/05/31 14:47:52 INFO ReceivedBlockTracker: Deleting batches: 
18/05/31 14:47:52 INFO FileBasedWriteAheadLog_ReceivedBlockTracker: Attempting to clear 0 old log files in file:/Users/Yelena/Documents/Work/Spark_Streaming/bigdata-training-master-33ed2ba160dfb3f0a225c8acac7f158e8adeb149/dev/homeworks/spark-streaming/homework2/checkpoint/receivedBlockMetadata older than 1527767070000: 
18/05/31 14:47:52 INFO InputInfoTracker: remove old batch metadata: 1527767060000 ms